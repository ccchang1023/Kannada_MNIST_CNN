{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "import imgaug\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se_Net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Sq_Ex_Block(nn.Module):\n",
    "    def __init__(self, in_ch, r=16):\n",
    "        super(Sq_Ex_Block, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(in_ch, in_ch//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch//r, in_ch),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "#         print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "        return x.mul(se_weight)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "class SE_Net3(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(SE_Net3,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c4 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(64,1e-3,0.01)        \n",
    "        \n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c7 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.bn7 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c8 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn8 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.c9 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn9 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.c10 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn10 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        \n",
    "        self.se1 = Sq_Ex_Block(in_ch=256,r=16)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn11 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.leaky_relu(self.c1(x),0.05))\n",
    "        x = self.bn2(F.leaky_relu(self.c2(x),0.05))\n",
    "        x = self.bn3(F.leaky_relu(self.c3(x),0.05))\n",
    "        x = self.bn4(F.leaky_relu(self.c4(x),0.05))\n",
    "        x = self.d1(self.m1(x))\n",
    "        \n",
    "        x = self.bn5(F.leaky_relu(self.c5(x),0.05))\n",
    "        x = self.bn6(F.leaky_relu(self.c6(x),0.05))\n",
    "        x = self.bn7(F.leaky_relu(self.c7(x),0.05))\n",
    "        x = self.bn8(F.leaky_relu(self.c8(x),0.05))\n",
    "        x = self.d2(self.m2(x))\n",
    "        \n",
    "        x = self.bn9(F.leaky_relu(self.c9(x),0.05))\n",
    "        x = self.bn10(F.leaky_relu(self.c10(x),0.05))\n",
    "        x = self.se1(x)\n",
    "        x = self.d3(self.m3(x))\n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn11(F.leaky_relu(self.fc1(x),0.05))\n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet-pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Kmnist_resnet(nn.Module):\n",
    "    def __init__(self,pretrained=False):\n",
    "        super().__init__()\n",
    "        self.docker = nn.Conv2d(1,3,kernel_size=1)\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "         \n",
    "    def forward(self,x):\n",
    "        x = self.docker(x)\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze and Excitation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Seq_Ex_Block(nn.Module):\n",
    "    def __init__(self, in_ch, r=16):\n",
    "        super(Seq_Ex_Block, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(in_ch, in_ch//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch//r, in_ch),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "#         print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "        return x.mul(se_weight)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "class SE_Net2(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(SE_Net2,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.se1 = Seq_Ex_Block(in_ch=64,r=8)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.se2 = Seq_Ex_Block(in_ch=128,r=8)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.se3 = Seq_Ex_Block(in_ch=256,r=8)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.leaky_relu(self.c1(x),0.1))\n",
    "        x = self.bn2(F.leaky_relu(self.c2(x),0.1))\n",
    "        x = self.bn3(F.leaky_relu(self.c3(x),0.1))\n",
    "        x = self.se1(x)\n",
    "        x = self.d1(self.m1(x))\n",
    "        \n",
    "        x = self.bn4(F.leaky_relu(self.c4(x),0.1))\n",
    "        x = self.bn5(F.leaky_relu(self.c5(x),0.1))\n",
    "        x = self.bn6(F.leaky_relu(self.c6(x),0.1))\n",
    "        x = self.se2(x)\n",
    "        x = self.d2(self.m2(x))\n",
    "        \n",
    "        x = self.bn7(F.leaky_relu(self.c7(x),0.1))\n",
    "        x = self.se3(x)\n",
    "        x = self.d3(self.m3(x))\n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn8(F.relu(self.fc1(x),0.1))\n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE_Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class SEBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(SEBasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def se_resnet18(num_classes=10):\n",
    "    model = models.ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "def se_resnet34(num_classes=10):\n",
    "    model = models.ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.bn9 = nn.BatchNorm1d(128,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(128,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.relu(self.c1(x)))\n",
    "        x = self.bn2(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        x = self.bn6(F.relu(self.c6(x)))\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.bn7(F.relu(self.c7(x)))\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)        \n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        \n",
    "        x = self.bn8(self.fc1(x))\n",
    "        x = self.bn9(self.fc2(x))\n",
    "        \n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in')\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv model by Chris Deotte (replace max pooling with average pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class convNet_avp(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet_avp,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,2,2)  #Use strides 2 instead of maxpooling\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,2,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)        \n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,4,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(256,10)\n",
    "#         self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.relu(self.c1(x)))\n",
    "        x = self.bn2(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        x = self.bn6(F.relu(self.c6(x)))\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.bn7(F.relu(self.c7(x)))\n",
    "        x = self.d3(x)\n",
    "\n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn8(self.fc1(x))\n",
    "        return self.out(x)\n",
    "    \n",
    "#     def init_linear_weights(self):\n",
    "#         nn.init.kaiming_normal_(self.out.weight, mode='fan_in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnet native old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet_native(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet_native,self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.c2 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c3 = nn.Conv2d(64,128,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(128,0.1)\n",
    "        self.c4 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(128,0.1)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.bn5 = nn.BatchNorm2d(256,0.1)\n",
    "        self.c6 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn6 = nn.BatchNorm2d(256,0.1)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(256*3*3,256)  #layer for binary entropy\n",
    "        self.d4 = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.bn1(self.c1(x)),negative_slope=0.1)\n",
    "        x = F.leaky_relu(self.bn2(self.c2(x)),0.1)\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn3(self.c3(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn4(self.c4(x)),0.1)\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn5(self.c5(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn6(self.c6(x)),0.1)\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        x = x.view(-1, 256*3*3) #reshape\n",
    "        x_b = F.leaky_relu(self.fc(x),0.1)\n",
    "        x_b = self.d4(x_b)\n",
    "        return self.out(x_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = convNet(in_channels=1)\n",
    "# model = SE_Net2(in_channels=1)\n",
    "# model = convNet_avp(in_channels=1)\n",
    "# model = Kmnist_resnet(pretrained=True)\n",
    "# model = se_resnet34(num_classes=10)\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\\\n",
    "model = SE_Net3(in_channels=1)\n",
    "model.cuda()\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "# from imgaug.augmentables.segmaps import SegmentationMapOnImage\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "#         iaa.Scale((640, 480)),\n",
    "#         iaa.Fliplr(0.5),\n",
    "            \n",
    "#         iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.6))),\n",
    "#         iaa.Sometimes(0.1, iaa.AverageBlur(1.2)),\n",
    "        iaa.Sometimes(1, iaa.Affine(rotate=(-20, 20),order=[0, 1],translate_px={\"x\":(-2, 2),\"y\":(-2,2)},mode='symmetric')),\n",
    "        iaa.Sometimes(0.2,iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.25))),\n",
    "#         iaa.Sometimes(0.1, iaa.SaltAndPepper(0.05,False)),\n",
    "        iaa.Invert(0.5),\n",
    "#         iaa.Add((-5, 5)), # change brightness of images (by -10 to 10 of original value)\n",
    "#         iaa.AdditiveGaussianNoise(-1,1)\n",
    "#         iaa.Sometimes(0.2,iaa.GammaContrast(2))\n",
    "            \n",
    "#         iaa.AddToHueAndSaturation(from_colorspace=\"GRAY\",value=(-20, 20))  #Hue-> color, saturation -> saido\n",
    "    ])\n",
    "    def __call__(self, img, mask=None):\n",
    "        img = np.array(img)        \n",
    "        return self.aug.augment_image(image=img)\n",
    "#         return self.aug(image=img, segmentation_maps=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trans and Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "#         transforms.ColorJitter(0.2,0.2,0.2,0.5),\n",
    "        transforms.RandomAffine(degrees=20,translate=(0.25,0.25),scale=[0.65,1.1],shear=15), #baseline(?)\n",
    "#         transforms.RandomAffine(degrees=35,translate=(0.2,0.2),scale=[0.6,1.1],shear=15), #Try 1\n",
    "#         transforms.RandomAffine(degrees=15,translate=(0.1,0.1),scale=(0.9,1.1),shear=5),  #for Se_res18\n",
    "#         transforms.Resize((224,224)), #For resnet\n",
    "#         transforms.RandomAffine(degrees=2,translate=(0.05,0.05)), #For 01 classifier\n",
    "#         transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),  #Used in Chris Deotte avgpool\n",
    "#         transforms.RandomAffine(degrees=10,translate=(0.2,0.2),scale=[0.9,1.1]), #For native distinguisher\n",
    "#         ImgAugTransform(),\n",
    "#         lambda x: Image.fromarray(x),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1  \n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "#         transforms.Normalize(mean=[0.11156191],std=[0.2794967]) #dig distribution\n",
    "    ])\n",
    "\n",
    "trans_val = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n",
    "\n",
    "trans_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "])\n",
    "\n",
    "# global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "# global_dig_aug_data = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")\n",
    "# global_dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# global_data_large = pd.read_csv(\"./dataset/train_large.csv\")\n",
    "# global_data_train_test_psuedo = pd.read_csv(\"./dataset/train_test_psuedo_aug.csv\")\n",
    "# global_data_train_test_psuedo = pd.read_csv(\"./dataset/train_test_psuedo_65k.csv\")\n",
    "# global_critic01_data = pd.read_csv(\"./dataset/critic01_20k.csv\")\n",
    "# global_critic01_data = pd.read_csv(\"./dataset/critic01_20k_hard.csv\")\n",
    "# global_data = pd.read_csv(\"./dataset/train_digtop1_69548.csv\")\n",
    "# global_data = pd.read_csv(\"./dataset/train_psuedo_digtop1_74367.csv\")\n",
    "# global_data = pd.read_csv(\"./dataset/train_pseu_dig_75k_acc9906.csv\")\n",
    "global_data = pd.read_csv(\"./dataset/train_pseu_dig_75k_acc9910.csv\")\n",
    "\n",
    "class KMnistDataset(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None,indices=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = global_data\n",
    "#         print(\"data shape:\", np.shape(self.data))\n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        self.indices = indices\n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_val\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        idx = self.indices[idx]\n",
    "#         print(idx)\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class KMnistDataset_binary_aid(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None,indices=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = global_data_large\n",
    "        \n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        self.indices = indices\n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_val\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        idx = self.indices[idx]\n",
    "#         print(idx)\n",
    "        img = self.data.iloc[idx, 2:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        native_label = self.data.iloc[idx, 0]  #(num,)\n",
    "        label = self.data.iloc[idx, 1]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "#         native_label = torch.as_tensor(native_label, dtype=torch.uint8).unsqueeze(0)    #value: 0~9, shape(1,1) for BCE loss\n",
    "        native_label = torch.as_tensor(native_label, dtype=torch.uint8)    #value: 0~9, shape(1) for CSE loss\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, native_label, label\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_len=None):\n",
    "        self.data = pd.read_csv(\"./dataset/test.csv\")\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        self.transform = trans_test\n",
    "        if data_len == None:\n",
    "            self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        return img, torch.Tensor([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get kfold dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_dataset_loader(k=5,val_rate=0.1,indices_len=None, batch_size=None,num_workers=None, binary_aid=False):\n",
    "    ###Return [list of train dataset_loader, list of val dataset_loader]\n",
    "    train_loader_list = []\n",
    "    val_loader_list = []\n",
    "    indices = np.arange(indices_len)\n",
    "    val_len = indices_len//k\n",
    "    idx = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "#         np.random.shuffle(indices)  #Random cross validation\n",
    "        ind = np.concatenate([indices[:idx],indices[idx+val_len:],indices[idx:idx+val_len]])\n",
    "        idx += val_len\n",
    "#         print(ind)\n",
    "        \n",
    "        if binary_aid == True:\n",
    "            train_dataset = KMnistDataset_binary_aid(data_len=None,is_validate=False, validate_rate=val_rate,indices=ind)\n",
    "            val_dataset = KMnistDataset_binary_aid(data_len=None,is_validate=True, validate_rate=val_rate, indices=ind)\n",
    "        else:\n",
    "            train_dataset = KMnistDataset(data_len=None,is_validate=False, validate_rate=val_rate,indices=ind)\n",
    "            val_dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=val_rate, indices=ind)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        \n",
    "        train_loader_list.append(train_loader)\n",
    "        val_loader_list.append(val_loader)\n",
    "        \n",
    "    return train_loader_list, val_loader_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(native_net=False):\n",
    "    #Basic cnn\n",
    "    if native_net == True:\n",
    "        model = convNet_native(in_channels=1)\n",
    "    else:\n",
    "#         model = convNet(in_channels=1)\n",
    "        model = SE_Net3(in_channels=1)\n",
    "#         model.out = nn.Linear(256,2)   #For critic cases classification\n",
    "        #pretrained model\n",
    "#         model = Kmnist_resnet(pretrained=True)  #remember to resize image to (224,224)\n",
    "#         model = se_resnet18(num_classes=10)\n",
    "#         model = se_resnet34(num_classes=10)\n",
    "#         model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "    #     summary(model, input_size=(1, 28, 28))\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        model.cuda()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train distribution: mean=[0.08229437],std=[0.23876116]\n",
    "# dig augmented distribution: mean=[0.09549136],std=[0.24336776]\n",
    "# train large distribution: mean=[0.08889286],std=[0.24106438]\n",
    "\n",
    "def get_dataset_mean_std(dataloader):\n",
    "    print(\"Calculate distribution:\")\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in dataloader:\n",
    "        img = data[0].to(device)\n",
    "        batch_samples = img.size(0)\n",
    "        img = img.contiguous().view(batch_samples, img.size(1), -1)\n",
    "        mean += img.mean(2).sum(0)\n",
    "        std += img.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "        if nb_samples%5120 == 0:\n",
    "            print(\"Finished:\", nb_samples)\n",
    "            \n",
    "    print(\"num of samples:\",nb_samples)\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "#     print(\"Average mean:\",mean)\n",
    "#     print(\"Average std:\", std)\n",
    "    return mean.cpu().numpy(), std.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get train and val loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation rate: 0.19998935093977957\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "num_workers = 8\n",
    "k = 5\n",
    "indices_len = 75124\n",
    "# indices_len = 75035\n",
    "# indices_len = 74367\n",
    "# indices_len = 60000\n",
    "# indices_len = 10240\n",
    "vr = (indices_len//k)/indices_len\n",
    "print(\"validation rate:\",vr)\n",
    "\n",
    "# indices_len = 10240  ################Temp Revised Caution##############\n",
    "# indices_len = 120000\n",
    "\n",
    "###Single dataset\n",
    "# indices = np.arange(indices_len)\n",
    "# train_dataset = KMnistDataset(data_len=None,is_validate=False,validate_rate=vr,indices=indices)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# mean, std = get_dataset_mean_std(train_loader)\n",
    "# print(\"train distribution: mean={},std={}\".format(mean, std))\n",
    "\n",
    "# indices = np.arange(10240)\n",
    "# dig_val_dataset = DigValDataset(data_len=None,indices=indices)\n",
    "# dig_val_loader = DataLoader(dig_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# mean, std = get_dataset_mean_std(dig_val_loader)\n",
    "# print(\"validate distribution:\",mean, std)\n",
    "\n",
    "# test_dataset = TestDataset(data_len=None)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# mean, std = get_dataset_mean_std(test_loader)\n",
    "# print(\"test distribution:\",mean, std)\n",
    "\n",
    "###K-fold dataset\n",
    "train_loaders, val_loaders = get_kfold_dataset_loader(k, vr, indices_len, batch_size, num_workers, binary_aid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train native classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    epochs = 120\n",
    "    period = 40\n",
    "    ensemble_models = []\n",
    "    lr = 1e-3\n",
    "    val_period = 1\n",
    "    \n",
    "    criterion_b = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Fold:\",len(train_loaders))\n",
    "    \n",
    "    for fold in range(len(train_loaders)):\n",
    "        train_loader = train_loaders[fold]\n",
    "        val_loader = val_loaders[fold]\n",
    "        \n",
    "        model = get_model(native_net=True)\n",
    "        torch.cuda.empty_cache()    #Need further check\n",
    "            \n",
    "        max_acc_b = 0\n",
    "        min_loss_b = 10000\n",
    "        best_model_dict = None\n",
    "        data_num = 0\n",
    "        loss_avg_b = 0\n",
    "\n",
    "#         optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "#         optimizer = torch.optim.RMSprop(model.parameters(),lr=lr,alpha=0.9)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=lr,betas=(0.9,0.99))\n",
    "#         optimizer = torch.optim.Adagrad(model.parameters(),lr=lr)\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=period,T_mult=1,eta_min=1e-5) #original \n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15)\n",
    "        \n",
    "        tmp_count = 0\n",
    "        for ep in range(0,epochs+1):\n",
    "            model.train()\n",
    "            for idx, data in enumerate(train_loader):\n",
    "                img, target_b, target = data\n",
    "                img, target_b, target = img.to(device), target_b.to(device,dtype=torch.long), target.to(device,dtype=torch.long)\n",
    "                pred_b = model(img)\n",
    "                  \n",
    "                loss_b = criterion_b(pred_b,target_b) \n",
    "                loss_avg_b += loss_b.item()\n",
    "                \n",
    "                data_num += img.size(0)\n",
    "                optimizer.zero_grad()\n",
    "                loss_b.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            ###Cosine annealing\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "            ###Evaluate Train Loss \n",
    "#             if ep%2 == 0:\n",
    "#                 loss_avg /= data_num\n",
    "#                 print(\"Ep:{}, loss:{}, lr:{}\".format(ep, loss_avg,optimizer.param_groups[0]['lr']))\n",
    "#                 loss_avg = 0\n",
    "#                 data_num = 0\n",
    "\n",
    "            ###Validation\n",
    "            if ep!=0 and ep%val_period == 0:\n",
    "                model.eval()\n",
    "                acc_b = 0\n",
    "                val_loss_b = 0\n",
    "                data_num  = 0\n",
    "                with torch.no_grad():\n",
    "                    for idx, data in enumerate(val_loader):\n",
    "                        img, target_b, target = data\n",
    "                        img, target_b, target = img.to(device), target_b.to(device,dtype=torch.long), target.to(device,dtype=torch.long)\n",
    "                        pred_b = model(img)\n",
    "\n",
    "                        val_loss_b += criterion_b(pred_b,target_b).item()\n",
    "                        \n",
    "                        # print(pred) \n",
    "                        ########\n",
    "                        _,pred_native_class = torch.max(pred_b.data, 1)\n",
    "                        \n",
    "                        acc_b += (pred_native_class == target_b).sum().item()\n",
    "                        data_num += img.size(0)\n",
    "\n",
    "                acc_b /= data_num\n",
    "                val_loss_b /= data_num\n",
    "\n",
    "                ###Plateau\n",
    "                lr_scheduler.step(val_loss_b)\n",
    "                if optimizer.param_groups[0]['lr'] < 1e-4:\n",
    "                    break                    \n",
    "\n",
    "                if acc_b >= max_acc_b:\n",
    "                    max_acc_b = acc_b\n",
    "                    best_model_dict = model.state_dict()\n",
    "                    \n",
    "                if val_loss_b <= min_loss:\n",
    "                    min_loss_b = val_loss_b\n",
    "#                     best_model_dict = model.state_dict()\n",
    "                \n",
    "                print(\"Episode:{}, Validation Loss:{},Acc_b:{:.3f}%,lr:{}\"\n",
    "                      .format(ep,val_loss_b,acc_b*100,optimizer.param_groups[0]['lr']))\n",
    "            \n",
    "            if ep!=0 and ep%10 == 0:\n",
    "                torch.save(best_model_dict, \"./Kmnist_saved_model/tmp_Fold{}_acc_b{:.3f}\".format(fold,max_acc_b*1e2))\n",
    "            \n",
    "        ###K-Fold ensemble: Saved k best model for k dataloader\n",
    "        print(\"===================Best Fold:{} Saved, Acc:{}==================\".format(fold,max_acc_b))\n",
    "        torch.save(best_model_dict, \"./Kmnist_saved_model/Fold{}_loss{:.4f}_acc_b{:.3f}\".format(fold,min_loss_b*1e3,max_acc_b*1e2))\n",
    "        print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.007346390693967208,Acc:10.1305%,lr:0.001\n",
      "Episode:2, Validation Loss:0.007867180945647284,Acc:13.9377%,lr:0.001\n",
      "Episode:3, Validation Loss:0.008289514194789151,Acc:19.8948%,lr:0.001\n",
      "Episode:4, Validation Loss:0.01141124011609501,Acc:18.3040%,lr:0.001\n",
      "Episode:5, Validation Loss:0.006083090687458254,Acc:28.9870%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0047469576453756344,Acc:37.9859%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00226056747162304,Acc:62.7995%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00017262340242616412,Acc:95.4872%,lr:0.001\n",
      "Episode:9, Validation Loss:5.6557966415057233e-05,Acc:98.2761%,lr:0.001\n",
      "Episode:10, Validation Loss:4.378600190844906e-05,Acc:98.7420%,lr:0.001\n",
      "Episode:11, Validation Loss:5.9512356064094904e-05,Acc:98.5423%,lr:0.001\n",
      "Episode:12, Validation Loss:3.607603433691719e-05,Acc:99.0216%,lr:0.001\n",
      "Episode:13, Validation Loss:2.9245766955383194e-05,Acc:99.1613%,lr:0.001\n",
      "Episode:14, Validation Loss:4.777265216706914e-05,Acc:98.5956%,lr:0.001\n",
      "Episode:15, Validation Loss:2.4987591348223474e-05,Acc:99.2612%,lr:0.001\n",
      "Episode:16, Validation Loss:2.7448260517943656e-05,Acc:99.3211%,lr:0.001\n",
      "Episode:17, Validation Loss:3.0136965049075656e-05,Acc:99.2412%,lr:0.001\n",
      "Episode:18, Validation Loss:2.5519388440214853e-05,Acc:99.3477%,lr:0.001\n",
      "Episode:19, Validation Loss:2.9527140370668313e-05,Acc:99.1480%,lr:0.001\n",
      "Episode:20, Validation Loss:2.8259320796047822e-05,Acc:99.1747%,lr:0.001\n",
      "Episode:21, Validation Loss:2.7420744566441266e-05,Acc:99.2479%,lr:0.001\n",
      "Episode:22, Validation Loss:2.7791617746406392e-05,Acc:99.2346%,lr:0.001\n",
      "Episode:23, Validation Loss:2.2703190287029622e-05,Acc:99.3477%,lr:0.001\n",
      "Episode:24, Validation Loss:2.97145221751338e-05,Acc:99.0415%,lr:0.001\n",
      "Episode:25, Validation Loss:3.658511457197106e-05,Acc:99.0149%,lr:0.001\n",
      "Episode:26, Validation Loss:2.4501598044372977e-05,Acc:99.3211%,lr:0.001\n",
      "Episode:27, Validation Loss:2.401371767171148e-05,Acc:99.3277%,lr:0.001\n",
      "Episode:28, Validation Loss:2.7626031797470503e-05,Acc:99.2878%,lr:0.001\n",
      "Episode:29, Validation Loss:2.3619349796971637e-05,Acc:99.2878%,lr:0.001\n",
      "Episode:30, Validation Loss:2.009303373987841e-05,Acc:99.4476%,lr:0.001\n",
      "Episode:31, Validation Loss:2.6345775557902102e-05,Acc:99.3211%,lr:0.001\n",
      "Episode:32, Validation Loss:2.1948970874614767e-05,Acc:99.3477%,lr:0.001\n",
      "Episode:33, Validation Loss:1.9489322012663285e-05,Acc:99.4010%,lr:0.001\n",
      "Episode:34, Validation Loss:2.8235705532689e-05,Acc:99.2212%,lr:0.001\n",
      "Episode:35, Validation Loss:1.842548476985365e-05,Acc:99.4675%,lr:0.001\n",
      "Episode:36, Validation Loss:1.7544731107977822e-05,Acc:99.4875%,lr:0.001\n",
      "Episode:37, Validation Loss:1.991947563498998e-05,Acc:99.4542%,lr:0.001\n",
      "Episode:38, Validation Loss:1.648397918114155e-05,Acc:99.5274%,lr:0.001\n",
      "Episode:39, Validation Loss:2.1282957640652077e-05,Acc:99.3544%,lr:0.001\n",
      "Episode:40, Validation Loss:1.8185598074524993e-05,Acc:99.4742%,lr:0.001\n",
      "Episode:41, Validation Loss:1.8396585100133038e-05,Acc:99.4875%,lr:0.001\n",
      "Episode:42, Validation Loss:1.7172294224764165e-05,Acc:99.4675%,lr:0.001\n",
      "Episode:43, Validation Loss:1.8166956993631217e-05,Acc:99.4409%,lr:0.001\n",
      "Episode:44, Validation Loss:2.1790372293553573e-05,Acc:99.3011%,lr:0.001\n",
      "Episode:45, Validation Loss:1.690133232514238e-05,Acc:99.4542%,lr:0.001\n",
      "Episode:46, Validation Loss:1.4974773056602801e-05,Acc:99.5940%,lr:0.001\n",
      "Episode:47, Validation Loss:2.1207653912413108e-05,Acc:99.3943%,lr:0.001\n",
      "Episode:48, Validation Loss:1.9156028882573587e-05,Acc:99.4076%,lr:0.001\n",
      "Episode:49, Validation Loss:1.728171938921189e-05,Acc:99.4675%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8792355909677773e-05,Acc:99.4409%,lr:0.001\n",
      "Episode:51, Validation Loss:2.0278703253488112e-05,Acc:99.4409%,lr:0.001\n",
      "Episode:52, Validation Loss:1.8638691838128497e-05,Acc:99.4476%,lr:0.001\n",
      "Episode:53, Validation Loss:1.5189980044643592e-05,Acc:99.4941%,lr:0.001\n",
      "Episode:54, Validation Loss:1.534807344643683e-05,Acc:99.5341%,lr:0.001\n",
      "Episode:55, Validation Loss:1.7772942766075095e-05,Acc:99.4742%,lr:0.001\n",
      "Episode:56, Validation Loss:2.031826189891718e-05,Acc:99.3943%,lr:0.001\n",
      "Episode:57, Validation Loss:1.731342942274401e-05,Acc:99.5474%,lr:0.001\n",
      "Episode:58, Validation Loss:2.3407677607065318e-05,Acc:99.3344%,lr:0.001\n",
      "Episode:59, Validation Loss:1.837157046633621e-05,Acc:99.4476%,lr:0.001\n",
      "Episode:60, Validation Loss:2.702089962356102e-05,Acc:99.2545%,lr:0.001\n",
      "Episode:61, Validation Loss:1.7977700859092026e-05,Acc:99.4875%,lr:0.001\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:62, Validation Loss:1.5531839526142365e-05,Acc:99.5407%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.2578295251945702e-05,Acc:99.6406%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.1886804202458444e-05,Acc:99.6406%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.1382269743964853e-05,Acc:99.6805%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.1236959370597007e-05,Acc:99.6938%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.1576145638923009e-05,Acc:99.6805%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.1372234563455303e-05,Acc:99.6938%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.1406258924906881e-05,Acc:99.6938%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.1596850643214136e-05,Acc:99.6872%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.1614095081185429e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.1267509187211672e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.1757228804178957e-05,Acc:99.6739%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.1678853273566284e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.175948523438245e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.083239718961219e-05,Acc:99.6938%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.1545628552494672e-05,Acc:99.7204%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.1173062887155828e-05,Acc:99.7271%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.1379684276206377e-05,Acc:99.7338%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.0731044386318142e-05,Acc:99.7271%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.1088335344813868e-05,Acc:99.7204%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.1023917812923479e-05,Acc:99.7338%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0789343883919195e-05,Acc:99.7271%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.1334695984213687e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.0979314875482514e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.0677544665160858e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.102524261060741e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0946880965528334e-05,Acc:99.7404%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.1043388864394431e-05,Acc:99.7338%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0514528314802196e-05,Acc:99.7604%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0722398038118428e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.1268548339633102e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.0671954808054498e-05,Acc:99.7204%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.1316061536141764e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0494440317915651e-05,Acc:99.7204%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.1075671335247853e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0802237655673894e-05,Acc:99.7005%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.1428340394704487e-05,Acc:99.6739%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.133204744265864e-05,Acc:99.6938%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.1287368165777403e-05,Acc:99.7071%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.1309529787338119e-05,Acc:99.7005%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.1475609385589966e-05,Acc:99.6605%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0909225661019944e-05,Acc:99.7404%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.1261170906043503e-05,Acc:99.7338%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.0607263780743503e-05,Acc:99.7537%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.0835871827432586e-05,Acc:99.7271%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0966478536526362e-05,Acc:99.7271%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.091419841773824e-05,Acc:99.7138%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.1070637364402668e-05,Acc:99.7204%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.1182885848360654e-05,Acc:99.7071%,lr:0.0001\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:111, Validation Loss:1.0759928682769418e-05,Acc:99.7404%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.0742557353337114e-05,Acc:99.7471%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.0799694061477661e-05,Acc:99.7537%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.0799507629592468e-05,Acc:99.7537%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.0859071299645958e-05,Acc:99.7537%,lr:1e-05\n",
      "Episode:116, Validation Loss:1.091443403788641e-05,Acc:99.7338%,lr:1e-05\n",
      "Episode:117, Validation Loss:1.0925133337432378e-05,Acc:99.7338%,lr:1e-05\n",
      "Episode:118, Validation Loss:1.0945549318061088e-05,Acc:99.7404%,lr:1e-05\n",
      "Episode:119, Validation Loss:1.0954297669142628e-05,Acc:99.7404%,lr:1e-05\n",
      "Episode:120, Validation Loss:1.0935087808277914e-05,Acc:99.7338%,lr:1e-05\n",
      "Episode:121, Validation Loss:1.0832278232741804e-05,Acc:99.7404%,lr:1e-05\n",
      "Episode:122, Validation Loss:1.0898946243892716e-05,Acc:99.7471%,lr:1e-05\n",
      "Episode:123, Validation Loss:1.0951897083544614e-05,Acc:99.7471%,lr:1e-05\n",
      "Episode:124, Validation Loss:1.0953438067828584e-05,Acc:99.7471%,lr:1e-05\n",
      "Episode:125, Validation Loss:1.1056923850254017e-05,Acc:99.7471%,lr:1e-05\n",
      "Episode:126, Validation Loss:1.1080362878916378e-05,Acc:99.7338%,lr:1e-05\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:1.0514528314802196e-05 Acc:0.9976038338658147==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.004936767938418891,Acc:9.8842%,lr:0.001\n",
      "Episode:2, Validation Loss:0.009542873809639765,Acc:19.1960%,lr:0.001\n",
      "Episode:3, Validation Loss:0.010227437153918802,Acc:17.2524%,lr:0.001\n",
      "Episode:4, Validation Loss:0.01658362842088563,Acc:13.7913%,lr:0.001\n",
      "Episode:5, Validation Loss:0.004620594941516019,Acc:27.3496%,lr:0.001\n",
      "Episode:6, Validation Loss:0.006864615840018113,Acc:30.4979%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0018432325305649266,Acc:68.1376%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00013899846702687148,Acc:96.4324%,lr:0.001\n",
      "Episode:9, Validation Loss:9.897064280728944e-05,Acc:97.6970%,lr:0.001\n",
      "Episode:10, Validation Loss:7.622621862239604e-05,Acc:98.1629%,lr:0.001\n",
      "Episode:11, Validation Loss:5.2211490282203696e-05,Acc:98.6688%,lr:0.001\n",
      "Episode:12, Validation Loss:3.7491493521176905e-05,Acc:98.9151%,lr:0.001\n",
      "Episode:13, Validation Loss:4.540619311935573e-05,Acc:98.9483%,lr:0.001\n",
      "Episode:14, Validation Loss:5.983863262949597e-05,Acc:98.5423%,lr:0.001\n",
      "Episode:15, Validation Loss:4.7131040588783e-05,Acc:98.7354%,lr:0.001\n",
      "Episode:16, Validation Loss:3.219455831681197e-05,Acc:99.0548%,lr:0.001\n",
      "Episode:17, Validation Loss:3.319313993659644e-05,Acc:99.1081%,lr:0.001\n",
      "Episode:18, Validation Loss:2.594511356914894e-05,Acc:99.2612%,lr:0.001\n",
      "Episode:19, Validation Loss:5.1004316829367126e-05,Acc:98.7021%,lr:0.001\n",
      "Episode:20, Validation Loss:3.613330261668744e-05,Acc:99.1547%,lr:0.001\n",
      "Episode:21, Validation Loss:5.3377652935548836e-05,Acc:98.6888%,lr:0.001\n",
      "Episode:22, Validation Loss:3.2124764107949276e-05,Acc:99.1014%,lr:0.001\n",
      "Episode:23, Validation Loss:2.9565706138456433e-05,Acc:99.2013%,lr:0.001\n",
      "Episode:24, Validation Loss:2.69026479399163e-05,Acc:99.2945%,lr:0.001\n",
      "Episode:25, Validation Loss:2.309714903444036e-05,Acc:99.3277%,lr:0.001\n",
      "Episode:26, Validation Loss:3.444248040755209e-05,Acc:99.0948%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6878267608452053e-05,Acc:99.2878%,lr:0.001\n",
      "Episode:28, Validation Loss:2.6919987623969586e-05,Acc:99.2878%,lr:0.001\n",
      "Episode:29, Validation Loss:3.0248738759364913e-05,Acc:99.1747%,lr:0.001\n",
      "Episode:30, Validation Loss:2.317019704534921e-05,Acc:99.3743%,lr:0.001\n",
      "Episode:31, Validation Loss:3.2749292822564625e-05,Acc:99.1147%,lr:0.001\n",
      "Episode:32, Validation Loss:2.3725529992804168e-05,Acc:99.2678%,lr:0.001\n",
      "Episode:33, Validation Loss:2.3941347448411174e-05,Acc:99.3411%,lr:0.001\n",
      "Episode:34, Validation Loss:2.3703801674278366e-05,Acc:99.2878%,lr:0.001\n",
      "Episode:35, Validation Loss:2.2420750196211842e-05,Acc:99.3477%,lr:0.001\n",
      "Episode:36, Validation Loss:3.381996856669125e-05,Acc:99.0216%,lr:0.001\n",
      "Episode:37, Validation Loss:2.8650147673754266e-05,Acc:99.2212%,lr:0.001\n",
      "Episode:38, Validation Loss:2.2273342859315366e-05,Acc:99.3344%,lr:0.001\n",
      "Episode:39, Validation Loss:2.0855786649538037e-05,Acc:99.4276%,lr:0.001\n",
      "Episode:40, Validation Loss:2.3299524301704698e-05,Acc:99.3277%,lr:0.001\n",
      "Episode:41, Validation Loss:1.9355451645274054e-05,Acc:99.4476%,lr:0.001\n",
      "Episode:42, Validation Loss:2.053943579209149e-05,Acc:99.3743%,lr:0.001\n",
      "Episode:43, Validation Loss:1.9963577267474814e-05,Acc:99.4476%,lr:0.001\n",
      "Episode:44, Validation Loss:1.997384084641529e-05,Acc:99.3677%,lr:0.001\n",
      "Episode:45, Validation Loss:2.821905814166775e-05,Acc:99.2346%,lr:0.001\n",
      "Episode:46, Validation Loss:3.271323209182142e-05,Acc:99.1480%,lr:0.001\n",
      "Episode:47, Validation Loss:2.097858798405487e-05,Acc:99.3943%,lr:0.001\n",
      "Episode:48, Validation Loss:2.1214646332390424e-05,Acc:99.4276%,lr:0.001\n",
      "Episode:49, Validation Loss:2.22096211848239e-05,Acc:99.4010%,lr:0.001\n",
      "Episode:50, Validation Loss:2.189278039740075e-05,Acc:99.4143%,lr:0.001\n",
      "Episode:51, Validation Loss:2.0497246922853702e-05,Acc:99.4609%,lr:0.001\n",
      "Episode:52, Validation Loss:2.0256171371694556e-05,Acc:99.4409%,lr:0.001\n",
      "Episode:53, Validation Loss:2.155631278017665e-05,Acc:99.4342%,lr:0.001\n",
      "Episode:54, Validation Loss:2.4597374380182344e-05,Acc:99.3810%,lr:0.001\n",
      "Episode:55, Validation Loss:3.644738966724077e-05,Acc:98.9816%,lr:0.001\n",
      "Episode:56, Validation Loss:2.1957320140583463e-05,Acc:99.3743%,lr:0.001\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:57, Validation Loss:2.172602409634767e-05,Acc:99.4143%,lr:0.0001\n",
      "Episode:58, Validation Loss:1.601530811144386e-05,Acc:99.5474%,lr:0.0001\n",
      "Episode:59, Validation Loss:1.4796796748493982e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:60, Validation Loss:1.4234576204442544e-05,Acc:99.5674%,lr:0.0001\n",
      "Episode:61, Validation Loss:1.4714994559538599e-05,Acc:99.5407%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.4608784887941675e-05,Acc:99.5873%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.4450079189907042e-05,Acc:99.5674%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.4064782845844239e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.4623324343383201e-05,Acc:99.5873%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.3695494445383993e-05,Acc:99.5540%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.3636369037484558e-05,Acc:99.5807%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.3318213990505654e-05,Acc:99.6206%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.3190380141884882e-05,Acc:99.6339%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.3240782304243428e-05,Acc:99.6339%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.3690470361782593e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.3937116336499969e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.4021583649065023e-05,Acc:99.6006%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.3526951931605435e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.2869784960332818e-05,Acc:99.6273%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.3138813299401658e-05,Acc:99.6006%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.3614745635323076e-05,Acc:99.6140%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.4264958712775201e-05,Acc:99.5740%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.2941452352472912e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.3445244182875187e-05,Acc:99.6006%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.2944631085853084e-05,Acc:99.6605%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.350936915773077e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.3296328529892082e-05,Acc:99.6339%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.3412912430775305e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.3304147418068683e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.259300124080687e-05,Acc:99.6273%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.3393700307312485e-05,Acc:99.6206%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.3201455466639691e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.328293918716276e-05,Acc:99.6140%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.3014662464588675e-05,Acc:99.6406%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.2525862702232993e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.3684878923957007e-05,Acc:99.6006%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.3390898404998013e-05,Acc:99.6140%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.2744184853945472e-05,Acc:99.6406%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.2707308596059585e-05,Acc:99.6273%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.3244550428933466e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.3181471704238583e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.3127270112750423e-05,Acc:99.6339%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.3738544372677073e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.3195638977788604e-05,Acc:99.5540%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.2825121459649347e-05,Acc:99.6073%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.2600462576493431e-05,Acc:99.6472%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.2734789585772034e-05,Acc:99.6206%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.3117977932266121e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.3073021254657953e-05,Acc:99.5940%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.3293078943097188e-05,Acc:99.6339%,lr:0.0001\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:107, Validation Loss:1.2654588417436718e-05,Acc:99.6339%,lr:1e-05\n",
      "Episode:108, Validation Loss:1.2677135703494104e-05,Acc:99.6140%,lr:1e-05\n",
      "Episode:109, Validation Loss:1.2690576838023953e-05,Acc:99.6006%,lr:1e-05\n",
      "Episode:110, Validation Loss:1.268712312148743e-05,Acc:99.5940%,lr:1e-05\n",
      "Episode:111, Validation Loss:1.2764264079390036e-05,Acc:99.6006%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.2850682371414016e-05,Acc:99.6273%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.2867218864133484e-05,Acc:99.6140%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.280961094669109e-05,Acc:99.6339%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.2674583492828364e-05,Acc:99.6206%,lr:1e-05\n",
      "Episode:116, Validation Loss:1.2623899714491619e-05,Acc:99.6273%,lr:1e-05\n",
      "Episode:117, Validation Loss:1.2819811575812971e-05,Acc:99.6006%,lr:1e-05\n",
      "Episode:118, Validation Loss:1.2739905196116073e-05,Acc:99.6073%,lr:1e-05\n",
      "Episode:119, Validation Loss:1.2725898288081264e-05,Acc:99.6339%,lr:1e-05\n",
      "Episode:120, Validation Loss:1.2713508176864289e-05,Acc:99.6140%,lr:1e-05\n",
      "Episode:121, Validation Loss:1.27702826833406e-05,Acc:99.6273%,lr:1e-05\n",
      "Episode:122, Validation Loss:1.2769168090319244e-05,Acc:99.6339%,lr:1e-05\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:1.2944631085853084e-05 Acc:0.9966054313099042==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.002890687638197463,Acc:27.7290%,lr:0.001\n",
      "Episode:2, Validation Loss:0.010974586708223223,Acc:10.1504%,lr:0.001\n",
      "Episode:3, Validation Loss:0.02430427861543763,Acc:10.1504%,lr:0.001\n",
      "Episode:4, Validation Loss:0.030546331557983787,Acc:10.1504%,lr:0.001\n",
      "Episode:5, Validation Loss:0.014349694640491717,Acc:12.9992%,lr:0.001\n",
      "Episode:6, Validation Loss:0.015603287913167058,Acc:19.4356%,lr:0.001\n",
      "Episode:7, Validation Loss:0.002873450438308513,Acc:52.4694%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0002139794111600953,Acc:94.2492%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0002243093842753587,Acc:94.4888%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00018794851375622743,Acc:95.1411%,lr:0.001\n",
      "Episode:11, Validation Loss:7.08860737451127e-05,Acc:98.0897%,lr:0.001\n",
      "Episode:12, Validation Loss:4.675402144848888e-05,Acc:98.7154%,lr:0.001\n",
      "Episode:13, Validation Loss:2.6803371922734876e-05,Acc:99.2079%,lr:0.001\n",
      "Episode:14, Validation Loss:0.00020904130777453208,Acc:94.9215%,lr:0.001\n",
      "Episode:15, Validation Loss:3.610100827494257e-05,Acc:99.0349%,lr:0.001\n",
      "Episode:16, Validation Loss:3.9115101441193506e-05,Acc:98.8884%,lr:0.001\n",
      "Episode:17, Validation Loss:2.176697423961311e-05,Acc:99.3876%,lr:0.001\n",
      "Episode:18, Validation Loss:5.228522606094837e-05,Acc:98.1097%,lr:0.001\n",
      "Episode:19, Validation Loss:4.230889944752422e-05,Acc:98.8884%,lr:0.001\n",
      "Episode:20, Validation Loss:2.5352906347455753e-05,Acc:99.3411%,lr:0.001\n",
      "Episode:21, Validation Loss:3.0062640994822922e-05,Acc:99.0948%,lr:0.001\n",
      "Episode:22, Validation Loss:2.9073281972882307e-05,Acc:99.2279%,lr:0.001\n",
      "Episode:23, Validation Loss:2.5847487047977183e-05,Acc:99.2745%,lr:0.001\n",
      "Episode:24, Validation Loss:2.173838243820765e-05,Acc:99.4342%,lr:0.001\n",
      "Episode:25, Validation Loss:1.795505575440959e-05,Acc:99.4476%,lr:0.001\n",
      "Episode:26, Validation Loss:2.0461730765381132e-05,Acc:99.4808%,lr:0.001\n",
      "Episode:27, Validation Loss:2.175541434692927e-05,Acc:99.3477%,lr:0.001\n",
      "Episode:28, Validation Loss:1.7333971798921816e-05,Acc:99.4276%,lr:0.001\n",
      "Episode:29, Validation Loss:2.791191131636278e-05,Acc:99.1147%,lr:0.001\n",
      "Episode:30, Validation Loss:1.9445710837061462e-05,Acc:99.4209%,lr:0.001\n",
      "Episode:31, Validation Loss:2.1666747776253884e-05,Acc:99.3144%,lr:0.001\n",
      "Episode:32, Validation Loss:1.5664233858211124e-05,Acc:99.5407%,lr:0.001\n",
      "Episode:33, Validation Loss:1.681783777479126e-05,Acc:99.4609%,lr:0.001\n",
      "Episode:34, Validation Loss:2.3042900098861653e-05,Acc:99.3277%,lr:0.001\n",
      "Episode:35, Validation Loss:1.406767333042436e-05,Acc:99.5674%,lr:0.001\n",
      "Episode:36, Validation Loss:2.235345367869884e-05,Acc:99.3477%,lr:0.001\n",
      "Episode:37, Validation Loss:1.70600782075393e-05,Acc:99.4409%,lr:0.001\n",
      "Episode:38, Validation Loss:1.959699214484713e-05,Acc:99.4209%,lr:0.001\n",
      "Episode:39, Validation Loss:1.884581942926533e-05,Acc:99.3943%,lr:0.001\n",
      "Episode:40, Validation Loss:1.904993274381049e-05,Acc:99.4276%,lr:0.001\n",
      "Episode:41, Validation Loss:1.4866848893540974e-05,Acc:99.5208%,lr:0.001\n",
      "Episode:42, Validation Loss:1.3706410954348322e-05,Acc:99.5607%,lr:0.001\n",
      "Episode:43, Validation Loss:1.3920844939693062e-05,Acc:99.5141%,lr:0.001\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    epochs = 150\n",
    "    ensemble_models = []\n",
    "    lr = 1e-3\n",
    "    val_period = 1\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "#     criterion_b = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    print(\"Fold:\",len(train_loaders))\n",
    "    \n",
    "    for fold in range(0,len(train_loaders)):\n",
    "        train_loader = train_loaders[fold]\n",
    "        val_loader = val_loaders[fold]\n",
    "        \n",
    "        model = get_model()\n",
    "            \n",
    "        max_acc = 0\n",
    "        min_loss = 10000\n",
    "        best_model_dict = None\n",
    "        data_num = 0\n",
    "        loss_avg = 0\n",
    "\n",
    "#         optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "#         optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=lr,betas=(0.9,0.99))\n",
    "#         optimizer = torch.optim.Adagrad(model.parameters(),lr=lr)\n",
    "#         lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=period,T_mult=1,eta_min=1e-5) #original \n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15,factor=0.1)\n",
    "        \n",
    "        for ep in range(0,epochs+1):\n",
    "            model.train()\n",
    "            for idx, data in enumerate(train_loader):\n",
    "                img, target = data\n",
    "                img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "                \n",
    "#                 print(np.shape(img),np.shape(target_b),np.shape(target)) #Tensor(4,1,28,28), Tensor(4)\n",
    "#                 print(np.max(img.cpu().numpy()),np.min(img.cpu().numpy())) #1.0 0.0\n",
    "                pred = model(img)\n",
    "#                 print(pred.size())   #(32,10)\n",
    "#                 print(target.size()) #(32,)\n",
    "                  \n",
    "                ###Input shape: input:(batch_num,1), target:(batch_num,a int 0 or 1) for CSE LOSS, target:(batch_num,1) for BCE loss\n",
    "#                 loss_b = criterion_b(pred_b,target_b) \n",
    "\n",
    "                ###Input shape: input:(batch_num,10), target:(batch_num,a int between 0~10)\n",
    "                loss = criterion(pred,target)\n",
    "                loss_avg += loss.item()\n",
    "                data_num += img.size(0)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            ###Cosine annealing\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "            ###Evaluate Train Loss \n",
    "#             if ep%2 == 0:\n",
    "#                 loss_avg /= data_num\n",
    "#                 print(\"Ep:{}, loss:{}, lr:{}\".format(ep, loss_avg,optimizer.param_groups[0]['lr']))\n",
    "#                 loss_avg = 0\n",
    "#                 data_num = 0\n",
    "\n",
    "            ###Validation\n",
    "            if ep!=0 and ep%val_period == 0:\n",
    "                model.eval()\n",
    "                acc = 0\n",
    "                val_loss = 0\n",
    "                data_num  = 0\n",
    "                with torch.no_grad():\n",
    "                    for idx, data in enumerate(val_loader):\n",
    "                        img, target = data\n",
    "                        img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "                        pred = model(img)\n",
    "\n",
    "                        val_loss += criterion(pred, target).item()\n",
    "                        \n",
    "                        # print(pred) \n",
    "                        _,pred_class = torch.max(pred.data, 1)\n",
    "    #                     print(pred_class)\n",
    "                        acc += (pred_class == target).sum().item()\n",
    "                        data_num += img.size(0)\n",
    "\n",
    "                acc /= data_num\n",
    "                val_loss /= data_num\n",
    "\n",
    "                ###Plateau\n",
    "                lr_scheduler.step(val_loss)\n",
    "                if optimizer.param_groups[0]['lr'] < 1e-5:\n",
    "                    break                    \n",
    "\n",
    "                if acc >= max_acc:\n",
    "                    max_acc = acc\n",
    "                    min_loss = val_loss\n",
    "                    best_model_dict = model.state_dict()                    \n",
    "                \n",
    "#                 if val_loss <= min_loss:\n",
    "#                     max_acc = acc\n",
    "#                     min_loss = val_loss\n",
    "#                     best_model_dict = model.state_dict()\n",
    "                \n",
    "                print(\"Episode:{}, Validation Loss:{},Acc:{:.4f}%,lr:{}\"\n",
    "                      .format(ep,val_loss,acc*100,optimizer.param_groups[0]['lr']))\n",
    "            \n",
    "#             if max_acc>0.995 and ep!=0 and ep%10 == 0:\n",
    "#                 torch.save(best_model_dict, \"./Kmnist_saved_model/tmp_Fold{}_acc{:.4f}\".format(fold,max_acc*1e2))\n",
    "    \n",
    "        ###K-Fold ensemble: Saved k best model for k dataloader\n",
    "        print(\"===================Best Fold:{} Saved Loss:{} Acc:{}==================\".format(fold,min_loss,max_acc))\n",
    "        torch.save(best_model_dict, \"./Kmnist_saved_model/Fold{}_loss{:.4f}_acc{:.3f}\".format(fold,min_loss*1e3,max_acc*1e2))\n",
    "        print(\"======================================================\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "            \n",
    "            ###Snapshot ensemble: saved model\n",
    "#             if ep!=0 and ep%period == 0:\n",
    "# #                 ensemble_models.append(best_model_dict)\n",
    "#                 model_id = ep//period\n",
    "#                 print(\"===================Best Model{} Saved, Acc:{}==================\".format(model_id,max_acc))\n",
    "#                 torch.save(best_model_dict, \"./Kmnist_saved_model/model{}_ep{}_acc{:.4f}\".format(model_id,ep,max_acc))\n",
    "#                 print(\"======================================================\")\n",
    "#                 max_acc = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native classifier Emsemble inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "# transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution        \n",
    "# transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "\n",
    "\n",
    "ensemble_root = \"./Kmnist_saved_model/senet2_5x2fold_65k\"   #model-> 1 fc(512) + dropout(0.1)\n",
    "ensemble_models = []\n",
    "\n",
    "ensemble_root_dig = \"./Kmnist_saved_model/ensemble_dig/baseline_cnn_60k_3fold\"    #model-> 1 fc(256) + dropout(0.2)\n",
    "ensemble_models_dig = []\n",
    "\n",
    "data_num = 0\n",
    "acc = 0\n",
    "\n",
    "# mean,std = 0.08229437, 0.23876116\n",
    "# mean_dig,std_dig = 0.09549136, 0.24336776\n",
    "# mean_large,std_large = 0.08889289, 0.24106446\n",
    "\n",
    "vr = 1\n",
    "# indices = np.arange(60000)\n",
    "# test_dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr,indices=indices)\n",
    "indices = np.arange(120000)\n",
    "test_dataset = KMnistDataset_binary_aid(data_len=None,is_validate=True, validate_rate=vr,indices=indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "native_model = convNet_native(in_channels=1)\n",
    "native_model.cuda()\n",
    "native_model.load_state_dict(torch.load(\"./Kmnist_saved_model/native_classifier/old/Fold0_loss0.0242_acc_b99.704_without_aug\"))\n",
    "native_model.eval()   \n",
    "\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = SE_Net2(in_channels=1)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "for file_name in os.listdir(ensemble_root_dig):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = convNet(in_channels=1)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root_dig,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models_dig.append(model)\n",
    "    \n",
    "### Test Native Classifier\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(test_loader):\n",
    "        ###Classify native or not\n",
    "        img, target_b, target = data\n",
    "        img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "        _,pred_native = torch.max(native_model(img),dim=1)  #(batch_num,)\n",
    "        \n",
    "        ###Classify by normal model, Average Ensemble\n",
    "        pred_list = torch.Tensor([]).to(device)\n",
    "        model_num = len(ensemble_models)\n",
    "        for i in range(model_num):\n",
    "            pred = ensemble_models[i](img) #(batch_num,10)\n",
    "            pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "        pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "        _,pred_class = torch.max(pred.data, 1)   #(batch_num,)\n",
    "        \n",
    "        \n",
    "        ###Classify by dig_aug_model, Average Ensemble\n",
    "        pred_list = torch.Tensor([]).to(device)\n",
    "        model_num = len(ensemble_models_dig)\n",
    "        for i in range(model_num):\n",
    "            pred = ensemble_models_dig[i](img) #(batch_num,10)\n",
    "            pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "        pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "        _,pred_class_dig = torch.max(pred.data, 1)   #(batch_num,)\n",
    "        \n",
    "        ###Make final result tensor\n",
    "        native_mask = pred_native    #(batch_num,)  ex: ([1,0,0,1,0])\n",
    "        nonnative_mask = torch.ones([img.size(0),], dtype=torch.long).to(device) - native_mask  #(batch_num,) ex:([0,1,1,0,1])\n",
    "        \n",
    "        r1 = (pred_class*native_mask)  #a*b = torch.mul(a,b)\n",
    "        r2 = (pred_class_dig*nonnative_mask)\n",
    "        pred_final = (r1+r2).to(torch.long)  #(batch_num,)\n",
    "\n",
    "#         print(\"model1:\",pred_class)\n",
    "#         print(\"model2:\",pred_class_dig)\n",
    "#         print(\"mask:\",native_mask)\n",
    "#         print(\"non_mask:\",nonnative_mask)\n",
    "#         print(\"r1:\",r1)\n",
    "#         print(\"r2:\",r2)\n",
    "#         print(\"result:\",result)\n",
    "#         print(\"target:\",target)\n",
    "#         stop\n",
    "    \n",
    "#         acc += (pred_native).sum().item()\n",
    "        acc += (pred_final == target).sum().item()\n",
    "        data_num += img.size(0)\n",
    "\n",
    "#     val_loss /= data_num\n",
    "    acc /= data_num\n",
    "    print(\"Acc:{:.4f}%\".format(acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble critical digits inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_root = \"./Kmnist_saved_model/senet2_5x2fold_65k\"\n",
    "ensemble_critical_root = \"./Kmnist_saved_model/critical_classifier/01\"\n",
    "ensemble_models = []\n",
    "ensemble_models_crit = []\n",
    "epochs = 500\n",
    "period = 100\n",
    "model_num = epochs//period\n",
    "model = 5\n",
    "data_num = 0\n",
    "acc = 0\n",
    "acc_2step = 0\n",
    "\n",
    "vr = 1\n",
    "indices = np.arange(60000)\n",
    "test_dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr,indices=indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = SE_Net2(in_channels=1)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "    \n",
    "for file_name in os.listdir(ensemble_critical_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue    \n",
    "    model_crit = SE_Net2(in_channels=1)\n",
    "    model_crit.out = nn.Linear(256,2)   #For critic cases classification\n",
    "    model_crit.cuda()\n",
    "    model_crit.load_state_dict(torch.load(\"{}/{}\".format(ensemble_critical_root,file_name)))\n",
    "    model_crit.eval()\n",
    "    ensemble_models_crit.append(model_crit)\n",
    "\n",
    "model_num = len(ensemble_models)\n",
    "crit_model_num = len(ensemble_models_crit)\n",
    "print(\"len of models:\",len(ensemble_models))    \n",
    "print(\"len of critical models:\",len(ensemble_models_crit))    \n",
    "result = np.array([])\n",
    "result1 =np.array([])\n",
    "label = np.array([])    \n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        img, target = data\n",
    "        img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "\n",
    "        ###Average Ensemble\n",
    "        pred_list = torch.Tensor([]).to(device)\n",
    "        for i in range(model_num):\n",
    "            pred = ensemble_models[i](img) #(batch_num,10)\n",
    "            pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "        pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "        _,pred_class = torch.max(pred.data, 1)   #(batch_num,)\n",
    "        \n",
    "        \n",
    "        ###Advanced inference for critical classes:\n",
    "        pred_list = torch.Tensor([]).to(device)\n",
    "        for i in range(crit_model_num):\n",
    "            pred = ensemble_models_crit[i](img) #(batch_num,10)\n",
    "            pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "        pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "        _,pred_class_crit = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "        \n",
    "        ###Make final result tensor\n",
    "        tensor1 = torch.tensor([1],dtype=torch.long).to(device)\n",
    "        tensor0 = torch.tensor([0],dtype=torch.long).to(device)\n",
    "        mask_1_0 = torch.where(pred_class==1,tensor1,tensor0) #(batch_num,)  ex: ([1,0,0,1,0])\n",
    "        mask_others = torch.ones([img.size(0),], dtype=torch.long).to(device) - mask_1_0  #(batch_num,) ex:([0,1,1,0,1])\n",
    "        \n",
    "        r1 = (pred_class_crit*mask_1_0)  #a*b = torch.mul(a,b)\n",
    "        r2 = (pred_class*mask_others)\n",
    "        pred_final = (r1+r2).to(torch.long)  #(batch_num,)\n",
    "\n",
    "#         print(\"pred_class:\",pred_class)\n",
    "#         print(\"pred_class_crit:\",pred_class_crit)\n",
    "#         print(\"mask_1_0:\",mask_1_0)\n",
    "#         print(\"mask_other:\",mask_others)\n",
    "#         print(\"r1:\",r1)\n",
    "#         print(\"r2:\",r2)\n",
    "#         print(\"pred:\",pred_final)\n",
    "        \n",
    "        \n",
    "        ###Voting Ensemble\n",
    "#         pred_list = torch.LongTensor([]).to(device)\n",
    "#         for i in range(model_num):\n",
    "#             pred = ensemble_models[i](img) #(batch_num,10)\n",
    "#             _,pred_class = torch.max(pred.data, 1)   #(batch_num,)\n",
    "#             pred_list = torch.cat((pred_list,pred_class.unsqueeze(1)),dim=1)\n",
    "            \n",
    "#         pred_class_list = torch.LongTensor([]).to(device)\n",
    "#         for i in range(img.size(0)):\n",
    "#             pred_np = pred_list[i].cpu().numpy()\n",
    "#             unique_class,count = np.unique(pred_np,return_counts=True)\n",
    "#             unique_class = np.array(unique_class[np.argmax(count)]).reshape(-1)   #unique class shape(1,)\n",
    "#             class_voted= torch.from_numpy(unique_class).to(device)    #(1,)\n",
    "#             pred_class_list = torch.cat((pred_class_list,class_voted))    \n",
    "    \n",
    "#         acc += (pred_class == target).sum().item()\n",
    "        acc += (pred_class == target).sum().item()\n",
    "        acc_2step += (pred_final == target).sum().item()\n",
    "        data_num += img.size(0)\n",
    "        result = np.hstack([result,pred_class.cpu().numpy()])\n",
    "        result1 = np.hstack([result1,pred_final.cpu().numpy()])\n",
    "        label = np.hstack([label,target.cpu().numpy()])\n",
    "\n",
    "#     val_loss /= data_num\n",
    "    acc /= data_num\n",
    "    acc_2step /= data_num\n",
    "    print(\"Acc:{:.4f}%\".format(acc*100))\n",
    "    print(\"Acc 2step :{:.4f}%\".format(acc_2step*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_root = \"./Kmnist_saved_model/ensemble_tuned_cnn/senet2_5x2fold_65k_tmp\"\n",
    "ensemble_root2 = \"./Kmnist_saved_model/ensemble_tuned_cnn/senet2_5fold_strong_aug_b768\"\n",
    "ensemble_models = []\n",
    "ensemble_models2 = []\n",
    "\n",
    "data_num = 0\n",
    "acc = 0\n",
    "\n",
    "vr = 1\n",
    "indices = np.arange(60000)\n",
    "test_dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr,indices=indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = SE_Net2(in_channels=1)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "    \n",
    "for file_name in os.listdir(ensemble_root2):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue    \n",
    "    model2 = SE_Net2(in_channels=1)\n",
    "    model2.cuda()\n",
    "    model2.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root2,file_name)))\n",
    "    model2.eval()\n",
    "    ensemble_models2.append(model2)\n",
    "\n",
    "model_num = len(ensemble_models)\n",
    "model2_num = len(ensemble_models2)\n",
    "print(\"len of models:\",len(ensemble_models))    \n",
    "print(\"len of models2:\",len(ensemble_models2))    \n",
    "result = np.array([])\n",
    "result1 =np.array([])\n",
    "label = np.array([])    \n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        img, target = data\n",
    "        img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "\n",
    "        ###Average Ensemble\n",
    "#         pred_list = torch.Tensor([]).to(device)\n",
    "#         for i in range(model_num):\n",
    "#             pred = ensemble_models[i](img) #(batch_num,10)\n",
    "#             pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "#         ###inference for models2\n",
    "#         for i in range(model2_num):\n",
    "#             pred = ensemble_models2[i](img) #(batch_num,10)\n",
    "#             pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "            \n",
    "#         pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "#         _,pred_class = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "        \n",
    "        ###Voting Ensemble\n",
    "        pred_list = torch.LongTensor([]).to(device)\n",
    "        for i in range(model_num):\n",
    "            pred = ensemble_models[i](img) #(batch_num,10)\n",
    "            _,pred_class = torch.max(pred.data, 1)   #(batch_num,)\n",
    "            pred_list = torch.cat((pred_list,pred_class.unsqueeze(1)),dim=1)\n",
    "        for i in range(model2_num):\n",
    "            pred = ensemble_models2[i](img) #(batch_num,10)\n",
    "            _,pred_class = torch.max(pred.data, 1)   #(batch_num,)\n",
    "            pred_list = torch.cat((pred_list,pred_class.unsqueeze(1)),dim=1)\n",
    "            \n",
    "        pred_class_list = torch.LongTensor([]).to(device)\n",
    "        for i in range(img.size(0)):\n",
    "            pred_np = pred_list[i].cpu().numpy()\n",
    "            unique_class,count = np.unique(pred_np,return_counts=True)\n",
    "            unique_class = np.array(unique_class[np.argmax(count)]).reshape(-1)   #unique class shape(1,)\n",
    "            class_voted= torch.from_numpy(unique_class).to(device)    #(1,)\n",
    "            pred_class_list = torch.cat((pred_class_list,class_voted))    \n",
    "    \n",
    "#         acc += (pred_class == target).sum().item()\n",
    "        acc += (pred_class == target).sum().item()\n",
    "        data_num += img.size(0)\n",
    "        \n",
    "#         result = np.hstack([result,pred_class.cpu().numpy()])\n",
    "#         result1 = np.hstack([result1,pred_final.cpu().numpy()])\n",
    "#         label = np.hstack([label,target.cpu().numpy()])\n",
    "\n",
    "#     val_loss /= data_num\n",
    "    acc /= data_num\n",
    "    print(\"Acc:{:.4f}%\".format(acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.where(label!=result)[0])\n",
    "print(np.where(label!=result1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.data = global_dataimport torch\n",
    "import numpy as np\n",
    "\n",
    "t1 = torch.Tensor([[1,2,3,4],[4,3,2,1],[1,5,3,3]])  #(3,4)\n",
    "t1 = t1.unsqueeze(2)\n",
    "\n",
    "t_list = torch.Tensor([])\n",
    "\n",
    "for i in range(3):\n",
    "    t_list = torch.cat((t_list,t1),dim=2)\n",
    "\n",
    "print(t_list.size())\n",
    "print(t_list)\n",
    "t_list = torch.mean(t_list,dim=2)\n",
    "print(t_list.size())\n",
    "print(t_list)\n",
    "\n",
    "\n",
    "# n1 = t1.cpu().numpy()\n",
    "\n",
    "# n1, count = np.unique(n1,return_counts=True,axis=0)\n",
    "# print(count)\n",
    "# n1 = np.argmax(count)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
