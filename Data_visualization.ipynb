{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "# from imgaug.augmentables.segmaps import SegmentationMapOnImage\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "#         iaa.Scale((640, 480)),\n",
    "#         iaa.Fliplr(0.5),\n",
    "          iaa.Sometimes(0.8,iaa.PerspectiveTransform(scale=(0,0.2)))  \n",
    "#         iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.6))),\n",
    "#         iaa.Sometimes(0.1, iaa.AverageBlur(1.2)),\n",
    "#         iaa.Sometimes(1, iaa.Affine(rotate=(-20, 20),order=[0, 1],translate_px={\"x\":(-2, 2),\"y\":(-2,2)},mode='symmetric')),\n",
    "#         iaa.Sometimes(0.2,iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.25))),\n",
    "#         iaa.Sometimes(0.1, iaa.SaltAndPepper(0.05,False)),\n",
    "#         iaa.Invert(0.5),\n",
    "#         iaa.Add((-5, 5)), # change brightness of images (by -10 to 10 of original value)\n",
    "#         iaa.AdditiveGaussianNoise(-1,1)\n",
    "#         iaa.Sometimes(0.2,iaa.GammaContrast(2))\n",
    "            \n",
    "#         iaa.AddToHueAndSaturation(from_colorspace=\"GRAY\",value=(-20, 20))  #Hue-> color, saturation -> saido\n",
    "    ])\n",
    "    def __call__(self, img, mask=None):\n",
    "        img = np.array(img)        \n",
    "        return self.aug.augment_image(image=img)\n",
    "#         return self.aug(image=img, segmentation_maps=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "        transforms.ColorJitter(0.5,0.5,0,0),\n",
    "#         transforms.RandomAffine(degrees=15,translate=(0.25,0.25),scale=(0.75,1.25),shear=8),  #normal    \n",
    "#         transforms.Resize((224,224)), #For resnet\n",
    "#         transforms.RandomAffine(degrees=2,translate=(0.05,0.05)), #For 01 classifier\n",
    "#         transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),  #Used in Chris Deotte avgpool\n",
    "#         transforms.RandomAffine(degrees=10,translate=(0.2,0.2),scale=[0.9,1.1]), #For native distinguisher\n",
    "#         ImgAugTransform(),\n",
    "#         lambda x: Image.fromarray(x),\n",
    "        transforms.RandomAffine(degrees=15,translate=(0.015,0.015),scale=(0.9,1.1),shear=3),  #for Se_res18    \n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1  \n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n",
    "\n",
    "trans_dig = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n",
    "\n",
    "trans_val = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train distribution: mean=[0.08229437],std=[0.23876116]\n",
    "# dig augmented distribution: mean=[0.09549136],std=[0.24336776]\n",
    "# train large distribution: mean=[0.08889286],std=[0.24106438]\n",
    "\n",
    "def get_dataset_mean_std(dataloader):\n",
    "    print(\"Calculate distribution:\")\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in dataloader:\n",
    "        img = data[0].to(device)\n",
    "        batch_samples = img.size(0)\n",
    "        img = img.contiguous().view(batch_samples, img.size(1), -1)\n",
    "        mean += img.mean(2).sum(0)\n",
    "        std += img.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "        if nb_samples%5120 == 0:\n",
    "            print(\"Finished:\", nb_samples)\n",
    "            \n",
    "    print(\"num of samples:\",nb_samples)\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "#     print(\"Average mean:\",mean)\n",
    "#     print(\"Average std:\", std)\n",
    "    return mean.cpu().numpy(), std.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMnist Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "# global_aug_dig = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")\n",
    "global_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# global_test_data = pd.read_csv(\"./dataset/test.csv\")\n",
    "# global_pseudo_data = pd.read_csv(\"./dataset/train_test_psuedo_65k.csv\")\n",
    "# global_critic01_data = pd.read_csv(\"./dataset/critic01_20k.csv\")\n",
    "# global_data = pd.read_csv(\"./dataset/train_digtop1_69548.csv\")\n",
    "# global_data = pd.read_csv(\"./dataset/digtop1_9548.csv\")\n",
    "\n",
    "\n",
    "class KMnistDataset(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None,indices=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = global_data\n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        self.indices = indices\n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_val\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        idx = self.indices[idx]\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = 0\n",
    "vr = 0\n",
    "k = 5\n",
    "indices_len = 60000\n",
    "# indices_len = 10240\n",
    "# indices_len = 120000\n",
    "\n",
    "###Single dataset\n",
    "indices = np.arange(indices_len)\n",
    "train_dataset = KMnistDataset(data_len=None,is_validate=False,validate_rate=vr,indices=indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# mean, std = get_dataset_mean_std(train_loader)\n",
    "# print(\"train distribution: mean={},std={}\".format(mean, std))\n",
    "\n",
    "for idx,data in enumerate(train_loader):\n",
    "    img, label = data\n",
    "    img, label = img.to(device), label.to(device)\n",
    "#     img = img.cpu().numpy()\n",
    "#     img = np.uint8(img*255).reshape(batch_size,-1)\n",
    "#     label = label.cpu().numpy()\n",
    "    \n",
    "    fig,axes = plt.subplots(1,1,figsize=(2,2))\n",
    "    img = img[0]\n",
    "    origin_img = img.clone()\n",
    "    axes.imshow(origin_img.cpu().numpy().reshape(28,28),cmap='gray')\n",
    "#     img = transforms.functional.adjust_brightness(img., 0.1)\n",
    "#     axes[1].imshow(img.cpu().numpy().reshape(28,28),cmap='gray')\n",
    "    plt.pause(.1)\n",
    "    if idx!=0 and idx%10 ==0 :\n",
    "        stop\n",
    "        input('stop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/critic01_20k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(0,100):\n",
    "\n",
    "    i = idx\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = global_data.iloc[i, 0]\n",
    "    \n",
    "    if i%10==0:\n",
    "        plt.pause(.1)\n",
    "        fig, axes = plt.subplots(1,10,figsize=(16,2))\n",
    "    axes[i%10].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "    #     img = trans(img).cpu().numpy().reshape(28,28)\n",
    "    #     img = transforms.functional.adjust_brightness(img, 0.01)\n",
    "    #     img = transforms.functional.adjust_contrast(img, 0.01)\n",
    "    #     img = transforms.functional.adjust_saturation(img, 5)\n",
    "#         axes[j][1].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "#     img = global_data_dig.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "#     img = Image.fromarray(img)\n",
    "#     label = global_data_dig.iloc[i, 0]\n",
    "#     axes[2].imshow(img,cmap=\"gray\")\n",
    "#     img = trans(img).cpu().numpy().reshape(28,28)\n",
    "#     axes[3].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "\n",
    "    print(\"Label:\",label)\n",
    "\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Imgaug Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_counter = np.zeros((5,))\n",
    "for i in range(0,1000):\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = data.iloc[i, 0]\n",
    "    img = np.array(img)\n",
    "    t = time.clock()\n",
    "    iaa.GaussianBlur(sigma=(0, 0.6)).augment_image(img)\n",
    "    time_counter[0] += time.clock()-t\n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.AverageBlur(2).augment_image(img)\n",
    "    time_counter[1] += time.clock()-t\n",
    "    \n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.MedianBlur(3).augment_image(img)\n",
    "    time_counter[2] += time.clock()-t\n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.MotionBlur(180,-1).augment_image(img)\n",
    "    time_counter[3] += time.clock()-t    \n",
    "\n",
    "print(time_counter/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff between train_set and Dig_val set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub: Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet,self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.bn9 = nn.BatchNorm1d(128,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(128,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.relu(self.c1(x)))\n",
    "        x = self.bn2(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        x = self.bn6(F.relu(self.c6(x)))\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.bn7(F.relu(self.c7(x)))\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)        \n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        \n",
    "        x = self.bn8(self.fc1(x))\n",
    "        x = self.bn9(self.fc2(x))\n",
    "        \n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in')\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub: Conv_avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class convNet_avp(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet_avp,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,2,2)  #Use strides 2 instead of maxpooling\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,2,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)        \n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,4,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(256,10)\n",
    "#         self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.relu(self.c1(x)))\n",
    "        x = self.bn2(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        x = self.bn6(F.relu(self.c6(x)))\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.bn7(F.relu(self.c7(x)))\n",
    "        x = self.d3(x)\n",
    "\n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn8(self.fc1(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub: SE_Net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Seq_Ex_Block(nn.Module):\n",
    "    def __init__(self, in_ch, r=16):\n",
    "        super(Seq_Ex_Block, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(in_ch, in_ch//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch//r, in_ch),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "#         print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "        return x.mul(se_weight)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "class SE_Net3(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(SE_Net3,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c4 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(64,1e-3,0.01)        \n",
    "        \n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c7 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.bn7 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c8 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn8 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.c9 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn9 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.c10 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn10 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        \n",
    "        self.se1 = Seq_Ex_Block(in_ch=256,r=16)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn11 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.leaky_relu(self.c1(x),0.05))\n",
    "        x = self.bn2(F.leaky_relu(self.c2(x),0.05))\n",
    "        x = self.bn3(F.leaky_relu(self.c3(x),0.05))\n",
    "        x = self.bn4(F.leaky_relu(self.c4(x),0.05))\n",
    "        x = self.d1(self.m1(x))\n",
    "        \n",
    "        x = self.bn5(F.leaky_relu(self.c5(x),0.05))\n",
    "        x = self.bn6(F.leaky_relu(self.c6(x),0.05))\n",
    "        x = self.bn7(F.leaky_relu(self.c7(x),0.05))\n",
    "        x = self.bn8(F.leaky_relu(self.c8(x),0.05))\n",
    "        x = self.d2(self.m2(x))\n",
    "        \n",
    "        x = self.bn9(F.leaky_relu(self.c9(x),0.05))\n",
    "        x = self.bn10(F.leaky_relu(self.c10(x),0.05))\n",
    "        x = self.se1(x)\n",
    "        x = self.d3(self.m3(x))\n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn11(F.leaky_relu(self.fc1(x),0.05))\n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub:SE_Net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Seq_Ex_Block(nn.Module):\n",
    "    def __init__(self, in_ch, r=16):\n",
    "        super(Seq_Ex_Block, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(in_ch, in_ch//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch//r, in_ch),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "#         print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "        return x.mul(se_weight)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "class SE_Net2(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(SE_Net2,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.se1 = Seq_Ex_Block(in_ch=64,r=8)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.se2 = Seq_Ex_Block(in_ch=128,r=8)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.se3 = Seq_Ex_Block(in_ch=256,r=8)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.leaky_relu(self.c1(x),0.1))\n",
    "        x = self.bn2(F.leaky_relu(self.c2(x),0.1))\n",
    "        x = self.bn3(F.leaky_relu(self.c3(x),0.1))\n",
    "        x = self.se1(x)\n",
    "        x = self.d1(self.m1(x))\n",
    "        \n",
    "        x = self.bn4(F.leaky_relu(self.c4(x),0.1))\n",
    "        x = self.bn5(F.leaky_relu(self.c5(x),0.1))\n",
    "        x = self.bn6(F.leaky_relu(self.c6(x),0.1))\n",
    "        x = self.se2(x)\n",
    "        x = self.d2(self.m2(x))\n",
    "        \n",
    "        x = self.bn7(F.leaky_relu(self.c7(x),0.1))\n",
    "        x = self.se3(x)\n",
    "        x = self.d3(self.m3(x))\n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn8(F.relu(self.fc1(x),0.1))\n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n",
    "\n",
    "\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.bn9 = nn.BatchNorm1d(128,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(128,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.relu(self.c1(x)))\n",
    "        x = self.bn2(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        x = self.bn6(F.relu(self.c6(x)))\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.bn7(F.relu(self.c7(x)))\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)        \n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        \n",
    "        x = self.bn8(self.fc1(x))\n",
    "        x = self.bn9(self.fc2(x))\n",
    "        \n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in')\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n",
    "        \n",
    "class convNet_native(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet_native,self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.c2 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c3 = nn.Conv2d(64,128,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(128,0.1)\n",
    "        self.c4 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(128,0.1)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.bn5 = nn.BatchNorm2d(256,0.1)\n",
    "        self.c6 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn6 = nn.BatchNorm2d(256,0.1)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(256*3*3,256)  #layer for binary entropy\n",
    "        self.d4 = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.bn1(self.c1(x)),negative_slope=0.1)\n",
    "        x = F.leaky_relu(self.bn2(self.c2(x)),0.1)\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn3(self.c3(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn4(self.c4(x)),0.1)\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn5(self.c5(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn6(self.c6(x)),0.1)\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        x = x.view(-1, 256*3*3) #reshape\n",
    "        x_b = F.leaky_relu(self.fc(x),0.1)\n",
    "        x_b = self.d4(x_b)\n",
    "        return self.out(x_b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# native_model = convNet_native(in_channels=1)\n",
    "# native_model.cuda()\n",
    "# native_model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble/native_classifier/Fold0_loss0.0242_acc_b99.704_without_aug\"))\n",
    "# native_model.eval()\n",
    "\n",
    "dig_model = convNet(in_channels=1)\n",
    "dig_model.cuda()\n",
    "dig_model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble_dig/SE_net2_60k/dig_Fold0_loss0.0093_acc99.720\"))\n",
    "dig_model.eval()\n",
    "\n",
    "# se_model = SE_Net2(in_channels=1)\n",
    "# se_model.cuda()\n",
    "# se_model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble_dig/SE_net2_60k/dig_Fold0_loss0.0093_acc99.720\"))\\\n",
    "# se_model.eval()\n",
    "\n",
    "# model = convNet(in_channels=1)\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble/10_fold_tuned_cnn/adam/Fold8_loss0.0033_acc99.917\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model num: 5\n",
      "finished: 10240\n",
      "(10240,) (0,) (10240,)\n"
     ]
    }
   ],
   "source": [
    "vr = 1\n",
    "indices=np.arange(10240)\n",
    "# indices=np.arange(60000)\n",
    "dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr,indices=indices)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "## Test Native Classifier\n",
    "# counter = 0\n",
    "# data_num = 0\n",
    "# with torch.no_grad():\n",
    "#     for idx,data in enumerate(loader):\n",
    "#         img, label = data\n",
    "#         img, label = img.to(device), label.to(device)\n",
    "#         img = data[0].to(device)\n",
    "        \n",
    "#         _,pred_native = torch.max(native_model(img),dim=1)\n",
    "#         counter += (pred_native.cpu().numpy()).sum()\n",
    "#         data_num += img.size(0)\n",
    "        \n",
    "# print(\"Native rate:\",counter/data_num)\n",
    "# print(\"Non Native rate:\",1-(counter/data_num))\n",
    "\n",
    "# ### Inference models\n",
    "ensemble_models = []\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/10_fold_tuned_cnn/adam_batch1024_baseline\"\n",
    "ensemble_root = \"Kmnist_saved_model/ensemble/5fold_senet3\"\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5x2fold_65k_senet2_b1024\"\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5x1fold_65k_senet3_b1024\"  #acc 99.00\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/15fold-avgpool-batch1024-adam\"\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/74k/8fold_74k_senet3_pseudo_digtop1\" #acc 99.04\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/74k/5fold_74k_senet3_augv1\"  #acc 99.06\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5fold_74k_senet3_augv2\"  #acc ??\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5fold_75k_senet3_augv1\"  #acc99.10\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5fold_75k_senet3_sgdr\"  #acc\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/75k/5fold_senet3_75k_Adamax\"  #acc\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/75k/5fold_senet3_75k_AdamW\"  #acc\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/75k/5fold_senet3_75k_RMSprop\"  #acc\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/75124/5fold_75124_senet3_augv1\"  #acc99.18\n",
    "\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/adam\"\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/adam2/origin_60k_5fold\"\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/optimizer_mix\"\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/RMSProp\"\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/adam2/65k_5fold_more_iteration\"\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/adam2/65k_5fold\"\n",
    "# ensemble_root = \"Kmnist_saved_model/Step5\"\n",
    "\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "#     model = convNet(in_channels=1)\n",
    "#     model = SE_Net2(in_channels=1)\n",
    "    model = SE_Net3(in_channels=1)\n",
    "#     model = convNet_avp(in_channels=1)\n",
    "\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "model_num = len(ensemble_models)\n",
    "print(\"model num:\",model_num)\n",
    "\n",
    "# result = np.empty((0,3))\n",
    "result = np.array([])\n",
    "\n",
    "result_dig = np.array([])\n",
    "labels = np.array([])\n",
    "data_num = 0\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        ###Average Ensemble\n",
    "        pred_list = torch.Tensor([]).to(device)\n",
    "        for i in range(model_num):\n",
    "            pred = ensemble_models[i](img) #(batch_num,10)\n",
    "            pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "        pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "        _,pred = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "#         _,pred = torch.topk(pred,3)  #(batch_num,k), get topk result\n",
    "        \n",
    "        result = np.concatenate([result,pred.cpu().numpy()],axis=0)\n",
    "        labels = np.concatenate([labels,label.cpu().numpy()],axis=0)\n",
    "        data_num += img.size(0)\n",
    "\n",
    "print(\"finished:\",data_num)\n",
    "print(np.shape(result),np.shape(result_dig),np.shape(labels))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#60k test:\n",
    "    #step 1~9: 9992 9994 9993 9994 9993 9994 9994 9994 9991 9993\n",
    "    #5fold 75124: 9990 \n",
    "    #65k_pseudo_only: 9988\n",
    "    \n",
    "#10240 test:\n",
    "    #step1-10: 9773 9880 9896 9909 9912 9912 9914 9917 9920 9920\n",
    "    #5fold 75124: 9907\n",
    "    #65k_pseudo_only: 9045\n",
    "    \n",
    "    \n",
    "#60k test \n",
    "    #step 49: 9993\n",
    "    #step 44: 9994\n",
    "    #step 37~39: 9994\n",
    "    #step 28: 9994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9284    0.8232    0.8727      1024\n",
      "         1.0     0.9289    0.9180    0.9234      1024\n",
      "         2.0     0.8619    0.9814    0.9178      1024\n",
      "         3.0     0.9672    0.8359    0.8968      1024\n",
      "         4.0     0.9714    0.9619    0.9666      1024\n",
      "         5.0     0.9685    0.9619    0.9652      1024\n",
      "         6.0     0.7804    0.8848    0.8293      1024\n",
      "         7.0     0.8542    0.8184    0.8359      1024\n",
      "         8.0     0.9722    0.9580    0.9651      1024\n",
      "         9.0     0.8758    0.9297    0.9019      1024\n",
      "\n",
      "    accuracy                         0.9073     10240\n",
      "   macro avg     0.9109    0.9073    0.9075     10240\n",
      "weighted avg     0.9109    0.9073    0.9075     10240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 69.0, 'Predicted label')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "###Confusion matrix\n",
    "print(classification_report(labels, result,digits=4))\n",
    "plt.figure(figsize=(10,10))\n",
    "confusion_mat = confusion_matrix(labels, result)\n",
    "sn.heatmap(confusion_mat, annot=True, cmap='YlGnBu',fmt=\"d\",linewidths=.5, linecolor='w')\n",
    "plt.title('Confusion matrix - DIG-MNIST dataset')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices1 = np.where(result!=labels)[0]       #(num)\n",
    "# indices2 = np.where(result_dig!=labels)[0]\n",
    "# indices3 = np.where((result!=labels)&(result_dig==labels))[0]\n",
    "indices4 = np.where((result[:,0]==labels))[0]\n",
    "indices5 = np.where((result[:,0]==labels)|(result[:,1]==labels))[0]\n",
    "indices6 = np.where((result[:,0]==labels)|(result[:,1]==labels)|(result[:,2]==labels))[0]\n",
    "\n",
    "cirtic_idx_list_ans0 = []\n",
    "idx_list_ans1 = []\n",
    "\n",
    "cirtic_idx_list_ans9 = []\n",
    "label_list = []\n",
    "count = 0\n",
    "\n",
    "data_num = len(labels)\n",
    "print(\"top1 acc:\",len(indices4)/data_num)\n",
    "print(\"top2 acc:\",len(indices5)/data_num)\n",
    "print(\"top3 acc:\",len(indices6)/data_num)\n",
    "stop\n",
    "\n",
    "for i in range(0,len(indices1)):\n",
    "    idx = indices1[i]\n",
    "#     img1 = global_dig.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "#     img1 = global_pseudo_data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = global_data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = Image.fromarray(img1)\n",
    "    label1 = result[idx]\n",
    "#     label2 = result_dig[idx]\n",
    "    label2 = None\n",
    "    label = labels[idx]\n",
    "  \n",
    "\n",
    "#     if label == 0:\n",
    "#         fig, axes = plt.subplots(1,1,figsize=(2,2))\n",
    "# #         cirtic_idx_list_ans0.append(idx)\n",
    "#         axes.imshow(img1,cmap=\"gray\")\n",
    "#         print(idx)\n",
    "#         print(\"Model:\",label1,\" Model2:\",label2,\" Label:\",label)\n",
    "#         plt.pause(.1)\n",
    "#     else:\n",
    "#         continue\n",
    "        \n",
    "\n",
    "# print(idx_list_ans1)\n",
    "# np.save(\"idx_ans1\",idx_list_ans1)\n",
    "\n",
    "# print(cirtic_idx_list_ans0)\n",
    "# print(cirtic_idx_list_ans9)\n",
    "\n",
    "cirtic_idx_list_ans0_v2 = [5520,6150,12280,18560,32730]\n",
    "np.save(\"critic_idx_ans0_v2\",cirtic_idx_list_ans0_v2)\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# data = np.uint8(cirtic_label_list)\n",
    "# print(len(data))\n",
    "# plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "# plt.xticks(range(10))\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# data = np.uint8(label_list)\n",
    "# print(len(data))\n",
    "# plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "# plt.xticks(range(10))\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "\n",
    "# 31 1 0 59969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect top-1 corrected data dig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(9340,)\n"
     ]
    }
   ],
   "source": [
    "dig_idx_list = np.array([])\n",
    "# dig_idx_list = np.load('top1_digidx3.npy')\n",
    "print(len(dig_idx_list))\n",
    "\n",
    "indices = np.where((result[:,0]==labels))[0]  #get top1 corrected index\n",
    "# indices = np.where((result[:,0]==labels)|(result[:,1]==labels))[0]  #get top2 corrected index\n",
    "dig_idx_list = np.hstack([dig_idx_list,indices])\n",
    "dig_idx_list = np.unique(dig_idx_list).astype(int)\n",
    "print(np.shape(dig_idx_list))\n",
    "np.save(\"final_digidx_9340_s1.npy\",dig_idx_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine train.csv with dig dataset in top k index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 785)\n",
      "(9340, 785)\n"
     ]
    }
   ],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "# top1_digidx = np.load(\"top1_digidx_len9367.npy\")\n",
    "# top1_digidx = np.load(\"top1_digidx_10k_acc9906.npy\")\n",
    "top1_digidx = np.load(\"final_digidx_9340_s1.npy\")\n",
    "origin_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "\n",
    "train_csv = np.array(origin_data).astype(int)\n",
    "tmp_csv = np.array(dig_data).astype(int)\n",
    "print(np.shape(tmp_csv))\n",
    "top1_dig_csv = []\n",
    "for idx in top1_digidx:\n",
    "    top1_dig_csv.append(tmp_csv[idx])\n",
    "\n",
    "top1_dig_csv = np.array(top1_dig_csv).astype(int)\n",
    "print(np.shape(top1_dig_csv))\n",
    "np.savetxt(\"./dataset_final/digtop1_9340_s1.csv\", top1_dig_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n",
    "# new_csv = np.vstack([train_csv,top1_dig_csv])\n",
    "# np.random.shuffle(new_csv)\n",
    "# np.random.shuffle(new_csv)\n",
    "# np.random.shuffle(new_csv)\n",
    "# print(\"new_csv_shape:\",np.shape(new_csv))\n",
    "# np.savetxt(\"./dataset/train_digtop1_69367.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine train.csv and Dig augmented, add additional \"native writer label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"native_label,label,\" + pix_str\n",
    "\n",
    "origin_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "dig_aug_data = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = np.array(origin_data).astype(int)\n",
    "dig_aug_csv = np.array(dig_aug_data).astype(int)\n",
    "native_label0 = np.zeros((60000,1)).astype(int)\n",
    "native_label1 = np.ones((60000,1)).astype(int)\n",
    "\n",
    "train_csv = np.concatenate([native_label1,train_csv],axis=1)\n",
    "dig_aug_csv = np.concatenate([native_label0,dig_aug_csv],axis=1)\n",
    "\n",
    "print(np.shape(train_csv))\n",
    "print(np.shape(dig_aug_csv))\n",
    "new_csv = np.vstack([train_csv,dig_aug_csv])\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset/train_large.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment dig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = 0\n",
    "batch_size = 1024\n",
    "dataset = KMnistDataset(data_len=None,is_validate=False, validate_rate=vr)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "num_per_class = 6000  # 6000 * 10 =60000\n",
    "\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# dig_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "\n",
    "###Load original 10240 data\n",
    "origin_img = dig_data.iloc[:, 1:].values.astype(np.uint8).reshape((-1,784))  #value: 0~255\n",
    "origin_label = np.array(dig_data.iloc[:,0]).astype(int)\n",
    "\n",
    "for i in range(len(origin_img)):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    tmp_img = origin_img[i]    #(784,)\n",
    "    tmp_label = origin_label[i].reshape(-1) #(1,)\n",
    "    csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "    aug_list = np.vstack((aug_list,csv_arr))\n",
    "    counter_list[tmp_label] += 1\n",
    "\n",
    "print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "print(\"counter_list:\",counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Augment data by random select and affine\n",
    "keep_loop = True\n",
    "while keep_loop:\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(batch_size,-1)\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            tmp_img = img[i]    #(784,)\n",
    "            tmp_label = label[i].reshape(-1) #(1,)\n",
    "            if counter_list[tmp_label] >= num_per_class:\n",
    "                continue\n",
    "#             print(np.shape(tmp_label),np.shape(tmp_img))\n",
    "            csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "#             print(\"csv arr shape:\",np.shape(csv_arr))\n",
    "            \n",
    "            aug_list = np.vstack((aug_list,csv_arr))\n",
    "#             print(\"aug_list shape:\",np.shape(aug_list))\n",
    "            counter_list[tmp_label] += 1\n",
    "\n",
    "        print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "        print(\"counter_list:\",counter_list)\n",
    "        if (counter_list>=num_per_class).all() == True:\n",
    "            print(\"Augment Finished\")\n",
    "            print(np.shape(aug_list))\n",
    "            print(counter_list)\n",
    "            np.savetxt(\"./dataset/Dig-Mnist-Augmented.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            keep_loop = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (5000, 785)\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n"
     ]
    }
   ],
   "source": [
    "trans_test = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_len=None):\n",
    "        self.data = pd.read_csv(\"./dataset/test.csv\")\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        self.transform = trans_test\n",
    "        if data_len == None:\n",
    "            self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        return img, torch.Tensor([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "test_dataset = TestDataset(data_len=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "### Inference models\n",
    "ensemble_models = []\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5x1fold_65k_senet3_b1024\"   #99.00%\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5fold_74k_senet3_augv1\"       #99.06%\n",
    "# ensemble_root = \"Kmnist_saved_model/ensemble/5fold_75k_senet3_augv1\"  #acc99.10\n",
    "\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/origin_60k_5fold\"\n",
    "ensemble_root = \"Kmnist_saved_model/final_submit/adam2/origin_60k_5fold\"\n",
    "\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = SE_Net3(in_channels=1)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "model_num = len(ensemble_models)\n",
    "print(\"model num:\",model_num)\n",
    "\n",
    "psuedo_labels = np.array([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(test_loader):\n",
    "            img, label = data\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            ###Average Ensemble\n",
    "            pred_list = torch.Tensor([]).to(device)\n",
    "            for i in range(model_num):\n",
    "                pred = ensemble_models[i](img) #(batch_num,10)\n",
    "                pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "            pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "            _,pred = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "    #         _,pred = torch.max(model(img),dim=1)\n",
    "\n",
    "            psuedo_labels = np.concatenate([psuedo_labels,pred.cpu().numpy()],axis=0)\n",
    "            data_num += img.size(0)\n",
    "            \n",
    "print(\"Inference complete:\",np.shape(psuedo_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "shape psuedo_labels: (5000,)\n",
      "(5000, 785)\n"
     ]
    }
   ],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "test_csv = np.array(pd.read_csv(\"./dataset/test.csv\")).astype(int)[:,1:]\n",
    "\n",
    "print(np.shape(test_csv))\n",
    "\n",
    "pseudo_labels = psuedo_labels.reshape(-1,1).astype(int)\n",
    "print(\"shape psuedo_labels:\",np.shape(psuedo_labels))\n",
    "test_csv = np.concatenate([pseudo_labels,test_csv],axis=1)\n",
    "\n",
    "print(np.shape(test_csv))\n",
    "np.savetxt(\"./dataset_final/test_pseu_s1.csv\", test_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "# test_csv = pd.read_csv(\"./dataset_final/test_pseu_s1.csv\")\n",
    "# test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented psuedo_label test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_aug = transforms.Compose([\n",
    "        transforms.ColorJitter(0.5,0.2,0,0),\n",
    "        transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "class AugDataset(Dataset):\n",
    "    def __init__(self,data_len=None):\n",
    "        self.data = pd.read_csv(\"./dataset/test_psuedo_label.csv\")\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        self.transform = trans_aug\n",
    "        if data_len == None:\n",
    "            self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "vr = 0\n",
    "batch_size = 1024\n",
    "dataset = AugDataset(data_len=None)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "num_per_class = 6000  # 6000 * 10 =60000\n",
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "    \n",
    "###Augment data by random select and affine\n",
    "keep_loop = True\n",
    "while keep_loop:\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(-1,784)\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        for i in range(img.shape[0]):\n",
    "            tmp_img = img[i]    #(784,)\n",
    "            tmp_label = label[i].reshape(-1) #(1,)\n",
    "            if counter_list[tmp_label] >= num_per_class:\n",
    "                continue\n",
    "#             print(np.shape(tmp_label),np.shape(tmp_img))\n",
    "            csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "#             print(\"csv arr shape:\",np.shape(csv_arr))\n",
    "            \n",
    "            aug_list = np.vstack((aug_list,csv_arr))\n",
    "#             print(\"aug_list shape:\",np.shape(aug_list))\n",
    "            counter_list[tmp_label] += 1\n",
    "\n",
    "        print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "        print(\"counter_list:\",counter_list)\n",
    "        if (counter_list>=num_per_class).all() == True:\n",
    "            print(\"Augment Finished\")\n",
    "            print(np.shape(aug_list))\n",
    "            print(counter_list)\n",
    "            np.savetxt(\"./dataset/test_psuedo_augmented.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            keep_loop = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine train.csv with test_psuedo_aug.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(5000, 785)\n",
      "(9340, 785)\n",
      "(65000, 785)\n",
      "(74340, 785)\n"
     ]
    }
   ],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "train_csv = np.array(pd.read_csv(\"./dataset_final/train.csv\")).astype(int)\n",
    "test_csv = np.array(pd.read_csv(\"./dataset_final/test_pseu_s1.csv\")).astype(int)\n",
    "digtop1_csv = np.array(pd.read_csv(\"./dataset_final/digtop1_9340_s1.csv\")).astype(int)\n",
    "\n",
    "# indices = np.where(test_csv[:,0]!=test_csv2[:,0])[0]\n",
    "# print(len(indices))\n",
    "\n",
    "print(np.shape(train_csv))\n",
    "print(np.shape(test_csv))\n",
    "print(np.shape(digtop1_csv))\n",
    "\n",
    "\n",
    "###Combine train, pseudo\n",
    "new_csv = np.vstack([train_csv,test_csv])\n",
    "for i in range(5):\n",
    "    np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset_final/train_pseu_65k_s1.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n",
    "###Combine train, pseudo and digtop1 \n",
    "new_csv = np.vstack([train_csv,test_csv,digtop1_csv])\n",
    "for i in range(5):\n",
    "    np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset_final/train_pseu_dig_74340_s1.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented train dataset with critic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " global_data = pd.read_csv(\"./dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_aug = transforms.Compose([\n",
    "        transforms.ColorJitter(0.9,0.2,0,0),\n",
    "        transforms.RandomAffine(degrees=20,translate=(0.1,0.05),scale=(0.8,1.05)),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "class AugDataset(Dataset):\n",
    "    def __init__(self,critic_idx_list=None):\n",
    "        self.data = global_data\n",
    "        self.transform = trans_aug\n",
    "        self.critic_idx_list = critic_idx_list\n",
    "        print(\"data len:\", np.shape(self.critic_idx_list))\n",
    "        self.len = len(critic_idx_list)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.critic_idx_list[idx]\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "batch_size = 10\n",
    "critic_idx_list = np.load(\"./critic_idx_ans0.npy\")\n",
    "# critic_idx_list = np.load(\"./idx_ans1.npy\")\n",
    "dataset = AugDataset(critic_idx_list)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "    \n",
    "###Augment data by random select and affine\n",
    "data_num = 0\n",
    "for ep in range(50000):\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(-1,784)\n",
    "        label = label.cpu().numpy().reshape(-1,1)\n",
    "        \n",
    "#         batch_num = np.shape(img)[0]\n",
    "#         fig,axes = plt.subplots(1,batch_num,figsize=(10,2))\n",
    "#         for i in range(batch_num):\n",
    "#             axes[i].imshow(img[i].reshape(28,28),cmap='gray')\n",
    "#         plt.pause(.1)\n",
    "        \n",
    "        csv_arr = np.hstack([label,img])\n",
    "        aug_list = np.vstack([aug_list,csv_arr])\n",
    "        data_num += img.shape[0]\n",
    "        if data_num %2000==0:\n",
    "            print(data_num)\n",
    "        if data_num > 10000:\n",
    "            print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "            aug_list = aug_list[:10000]\n",
    "            np.savetxt(\"./dataset/critic0_10k_complicated.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine label1_10k with critic0_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "critic0_csv = np.array(pd.read_csv(\"./dataset/critic0_10k_complicated.csv\")).astype(int)\n",
    "label1_csv = np.array(pd.read_csv(\"./dataset/label1_10k.csv\")).astype(int)\n",
    "\n",
    "print(np.shape(critic0_csv))\n",
    "print(np.shape(label1_csv))\n",
    "new_csv = np.vstack([critic0_csv,label1_csv])\n",
    "np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "np.random.shuffle(new_csv)\n",
    "np.random.shuffle(new_csv)\n",
    "\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset/critic01_20k_complicated.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.random.random([1000,])\n",
    "# global_data = pd.read_csv(\"./dataset/train_large.csv\")\n",
    "global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "# global_data_test = pd.read_csv(\"./dataset/train_test_psuedo_aug.csv\")\n",
    "global_data_test = pd.read_csv(\"./dataset/train_test_psuedo_65k.csv\")\n",
    "\n",
    "# data1 = global_data.iloc[:10,1:]\n",
    "# data2 = global_data_test.iloc[:,0]\n",
    "\n",
    "train_digtop1= pd.read_csv(\"./dataset/digtop1_9548.csv\")\n",
    "plt.hist(train_digtop1 ,density=0,label=True,rwidth=0.3)\n",
    "plt.xticks(range(0,10))\n",
    "\n",
    "# print((label==5).sum().item())\n",
    "# plt.ylabel('frequency')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
