{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import convNet, convNet_val\n",
    "\n",
    "dig_model = convNet_val(in_channels=1)\n",
    "dig_model.cuda()\n",
    "dig_model.load_state_dict(torch.load(\"Kmnist_saved_model/Fold4_ep119_loss0.000_acc0.9922\"))\n",
    "\n",
    "model = convNet(in_channels=1)\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(\"Kmnist_saved_model/ep70_acc0.9978\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dig = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1    \n",
    "        transforms.Normalize(mean=[0.1126489],std=[0.28132638])  #dig_val distribution\n",
    "    ])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "        transforms.ColorJitter(0.5,0.2,0.2,0.5),\n",
    "        transforms.RandomAffine(degrees=35,translate=(0.2,0.2),scale=[0.8,1.1],shear=15),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1    \n",
    "#         transforms.Normalize(mean=[0.08194405],std=[0.238141])\n",
    "    ])\n",
    "\n",
    "global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "global_data_dig = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "\n",
    "class KMnistDataset(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = global_data_dig\n",
    "#         self.data = global_data\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_dig\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST-Augmented.csv\")\n",
    "for i in range(10,20):\n",
    "    fig, axes = plt.subplots(1,2,figsize=(4,2))\n",
    "    img2 = dig_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img2 = Image.fromarray(img2)\n",
    "    label = dig_data.iloc[i, 0]\n",
    "    axes[0].imshow(img2,cmap=\"gray\")\n",
    "#     img2 = trans(img2).cpu().numpy().reshape(28,28)\n",
    "    axes[1].imshow(img2,cmap=\"gray\")\n",
    "    plt.pause(.1)\n",
    "    print(\"Label:\",label)\n",
    "\n",
    "dig_data.head(5)\n",
    "# type(dig_data.iloc[20,1:].values)  #numpy ndarray\n",
    "# type(dig_data.iloc[20,0])  #numpy int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff between train_set and Dig_val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vr = 1\n",
    "dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "result = np.array([])\n",
    "result_dig = np.array([])\n",
    "labels = np.array([])\n",
    "data_num = 0\n",
    "\n",
    "for idx,data in enumerate(loader):\n",
    "    img, label = data\n",
    "    img, label = img.to(device), label.to(device)\n",
    "    _,pred = torch.max(model(img),dim=1)\n",
    "    _,pred_dig = torch.max(dig_model(img),dim=1)\n",
    "    result = np.concatenate([result,pred.cpu().numpy()],axis=0)\n",
    "    result_dig = np.concatenate([result_dig,pred_dig.cpu().numpy()],axis=0)\n",
    "    labels = np.concatenate([labels,label.cpu().numpy()],axis=0)\n",
    "    data_num += img.size(0)\n",
    "\n",
    "print(\"finished:\",data_num)\n",
    "print(np.shape(result),np.shape(result_dig),np.shape(labels))\n",
    "  \n",
    "\n",
    "indices1 = np.where(result!=labels)[0]       #(num)\n",
    "indices2 = np.where(result_dig!=labels)[0]\n",
    "indices3 = np.where((result!=labels)&(result_dig==labels))[0]\n",
    "\n",
    "print(len(indices1),len(indices2),len(indices3))  #dig: 912 51 878\n",
    "#up: 954\n",
    "for i in range(40,50):\n",
    "    idx = indices2[i]\n",
    "    fig, axes = plt.subplots(1,1,figsize=(2,2))\n",
    "    img1 = global_data_dig.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "\n",
    "    img1 = Image.fromarray(img1)\n",
    "    label1 = result[idx]\n",
    "    label2 = result_dig[idx]\n",
    "    label = labels[idx]\n",
    "#     label = global_data.iloc[idx, 0]  #(num,)\n",
    "    axes.imshow(img1,cmap=\"gray\")\n",
    "    plt.pause(.1)\n",
    "    print(\"Model:\",label1,\" Model2:\",label2,\" Label:\",label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment dig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (10240, 785)\n"
     ]
    }
   ],
   "source": [
    "vr = 0\n",
    "batch_size = 1024\n",
    "dataset = KMnistDataset(data_len=None,is_validate=False, validate_rate=vr)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "num_per_class = 6000  # 6000 * 10 =60000\n",
    "\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# dig_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "shape of aug_list: (10240, 785)\n",
      "counter_list: [1024 1024 1024 1024 1024 1024 1024 1024 1024 1024]\n"
     ]
    }
   ],
   "source": [
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "\n",
    "###Load original 10240 data\n",
    "origin_img = dig_data.iloc[:, 1:].values.astype(np.uint8).reshape((-1,784))  #value: 0~255\n",
    "origin_label = np.array(dig_data.iloc[:,0]).astype(int)\n",
    "\n",
    "for i in range(len(origin_img)):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    tmp_img = origin_img[i]    #(784,)\n",
    "    tmp_label = origin_label[i].reshape(-1) #(1,)\n",
    "    csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "    aug_list = np.vstack((aug_list,csv_arr))\n",
    "    counter_list[tmp_label] += 1\n",
    "\n",
    "print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "print(\"counter_list:\",counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of aug_list: (11264, 785)\n",
      "counter_list: [1135 1137 1121 1131 1123 1137 1119 1121 1124 1116]\n",
      "shape of aug_list: (12288, 785)\n",
      "counter_list: [1229 1245 1233 1247 1228 1234 1225 1203 1226 1218]\n",
      "shape of aug_list: (13312, 785)\n",
      "counter_list: [1318 1331 1358 1356 1326 1323 1343 1305 1334 1318]\n",
      "shape of aug_list: (14336, 785)\n",
      "counter_list: [1420 1433 1449 1464 1422 1438 1450 1408 1445 1407]\n",
      "shape of aug_list: (15360, 785)\n",
      "counter_list: [1523 1529 1562 1561 1534 1542 1545 1492 1557 1515]\n",
      "shape of aug_list: (16384, 785)\n",
      "counter_list: [1625 1629 1661 1653 1639 1639 1667 1611 1650 1610]\n",
      "shape of aug_list: (17408, 785)\n",
      "counter_list: [1730 1734 1770 1765 1733 1739 1756 1703 1763 1715]\n",
      "shape of aug_list: (18432, 785)\n",
      "counter_list: [1838 1828 1868 1859 1853 1851 1852 1814 1840 1829]\n",
      "shape of aug_list: (19456, 785)\n",
      "counter_list: [1943 1933 1956 1954 1948 1958 1945 1932 1937 1950]\n",
      "shape of aug_list: (20480, 785)\n",
      "counter_list: [2048 2048 2048 2048 2048 2048 2048 2048 2048 2048]\n",
      "shape of aug_list: (21504, 785)\n",
      "counter_list: [2150 2152 2145 2151 2142 2146 2149 2156 2156 2157]\n",
      "shape of aug_list: (22528, 785)\n",
      "counter_list: [2238 2247 2240 2249 2253 2250 2251 2268 2261 2271]\n",
      "shape of aug_list: (23552, 785)\n",
      "counter_list: [2333 2370 2348 2355 2363 2356 2344 2353 2363 2367]\n",
      "shape of aug_list: (24576, 785)\n",
      "counter_list: [2442 2474 2453 2452 2465 2455 2462 2450 2452 2471]\n",
      "shape of aug_list: (25600, 785)\n",
      "counter_list: [2553 2575 2562 2554 2555 2566 2564 2565 2547 2559]\n",
      "shape of aug_list: (26624, 785)\n",
      "counter_list: [2667 2666 2674 2656 2657 2657 2675 2658 2649 2665]\n",
      "shape of aug_list: (27648, 785)\n",
      "counter_list: [2770 2768 2759 2762 2770 2761 2782 2754 2758 2764]\n",
      "shape of aug_list: (28672, 785)\n",
      "counter_list: [2878 2877 2863 2863 2868 2856 2884 2862 2875 2846]\n",
      "shape of aug_list: (29696, 785)\n",
      "counter_list: [2972 2973 2973 2972 2963 2963 2988 2965 2971 2956]\n",
      "shape of aug_list: (30720, 785)\n",
      "counter_list: [3072 3072 3072 3072 3072 3072 3072 3072 3072 3072]\n",
      "shape of aug_list: (31744, 785)\n",
      "counter_list: [3172 3166 3176 3170 3172 3195 3178 3174 3174 3167]\n",
      "shape of aug_list: (32768, 785)\n",
      "counter_list: [3268 3281 3275 3287 3273 3298 3254 3277 3284 3271]\n",
      "shape of aug_list: (33792, 785)\n",
      "counter_list: [3372 3392 3391 3393 3371 3386 3359 3381 3373 3374]\n",
      "shape of aug_list: (34816, 785)\n",
      "counter_list: [3481 3493 3489 3504 3471 3473 3459 3479 3484 3483]\n",
      "shape of aug_list: (35840, 785)\n",
      "counter_list: [3585 3593 3598 3605 3564 3566 3571 3585 3581 3592]\n",
      "shape of aug_list: (36864, 785)\n",
      "counter_list: [3694 3692 3694 3706 3667 3656 3677 3700 3687 3691]\n",
      "shape of aug_list: (37888, 785)\n",
      "counter_list: [3791 3807 3796 3798 3782 3763 3782 3796 3779 3794]\n",
      "shape of aug_list: (38912, 785)\n",
      "counter_list: [3887 3903 3902 3897 3887 3886 3894 3892 3870 3894]\n",
      "shape of aug_list: (39936, 785)\n",
      "counter_list: [3993 4006 4003 3998 3977 4000 4000 3994 3985 3980]\n",
      "shape of aug_list: (40960, 785)\n",
      "counter_list: [4096 4096 4096 4096 4096 4096 4096 4096 4096 4096]\n",
      "shape of aug_list: (41984, 785)\n",
      "counter_list: [4193 4187 4199 4195 4194 4211 4207 4204 4203 4191]\n",
      "shape of aug_list: (43008, 785)\n",
      "counter_list: [4304 4291 4304 4307 4292 4297 4302 4304 4310 4297]\n",
      "shape of aug_list: (44032, 785)\n",
      "counter_list: [4415 4383 4399 4414 4401 4391 4406 4403 4417 4403]\n",
      "shape of aug_list: (45056, 785)\n",
      "counter_list: [4525 4502 4489 4536 4502 4493 4499 4504 4515 4491]\n",
      "shape of aug_list: (46080, 785)\n",
      "counter_list: [4620 4615 4602 4640 4578 4582 4606 4622 4615 4600]\n",
      "shape of aug_list: (47104, 785)\n",
      "counter_list: [4712 4725 4740 4741 4683 4675 4697 4711 4726 4694]\n",
      "shape of aug_list: (48128, 785)\n",
      "counter_list: [4806 4819 4843 4871 4791 4772 4795 4806 4825 4800]\n",
      "shape of aug_list: (49152, 785)\n",
      "counter_list: [4920 4921 4935 4948 4894 4886 4914 4906 4914 4914]\n",
      "shape of aug_list: (50176, 785)\n",
      "counter_list: [5019 5015 5022 5038 5005 5006 5020 5015 5015 5021]\n",
      "shape of aug_list: (51200, 785)\n",
      "counter_list: [5120 5120 5120 5120 5120 5120 5120 5120 5120 5120]\n",
      "shape of aug_list: (52224, 785)\n",
      "counter_list: [5213 5234 5229 5208 5225 5220 5227 5231 5228 5209]\n",
      "shape of aug_list: (53248, 785)\n",
      "counter_list: [5317 5341 5337 5315 5326 5307 5334 5330 5314 5327]\n",
      "shape of aug_list: (54272, 785)\n",
      "counter_list: [5421 5441 5445 5422 5438 5423 5427 5437 5401 5417]\n",
      "shape of aug_list: (55296, 785)\n",
      "counter_list: [5523 5547 5545 5529 5530 5524 5516 5545 5509 5528]\n",
      "shape of aug_list: (56320, 785)\n",
      "counter_list: [5636 5635 5651 5637 5635 5624 5616 5645 5619 5622]\n",
      "shape of aug_list: (57344, 785)\n",
      "counter_list: [5738 5734 5753 5744 5760 5725 5715 5735 5717 5723]\n",
      "shape of aug_list: (58368, 785)\n",
      "counter_list: [5848 5830 5868 5857 5854 5820 5825 5835 5812 5819]\n",
      "shape of aug_list: (59392, 785)\n",
      "counter_list: [5936 5937 5955 5958 5955 5926 5930 5961 5917 5917]\n",
      "shape of aug_list: (60000, 785)\n",
      "counter_list: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n",
      "Augment Finished\n",
      "(60000, 785)\n",
      "[6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n"
     ]
    }
   ],
   "source": [
    "###Augment data by random select and affine\n",
    "keep_loop = True\n",
    "while keep_loop:\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(batch_size,-1)\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            tmp_img = img[i]    #(784,)\n",
    "            tmp_label = label[i].reshape(-1) #(1,)\n",
    "            if counter_list[tmp_label] >= num_per_class:\n",
    "                continue\n",
    "#             print(np.shape(tmp_label),np.shape(tmp_img))\n",
    "            csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "#             print(\"csv arr shape:\",np.shape(csv_arr))\n",
    "            \n",
    "            aug_list = np.vstack((aug_list,csv_arr))\n",
    "#             print(\"aug_list shape:\",np.shape(aug_list))\n",
    "            counter_list[tmp_label] += 1\n",
    "\n",
    "        print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "        print(\"counter_list:\",counter_list)\n",
    "        if (counter_list>=num_per_class).all() == True:\n",
    "            print(\"Augment Finished\")\n",
    "            print(np.shape(aug_list))\n",
    "            print(counter_list)\n",
    "            np.savetxt(\"./dataset/Dig-Mnist-Augmented.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            keep_loop = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = np.random.random([1000,])\n",
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST-Augmented.csv\")\n",
    "# dig_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "dig_data = dig_data.iloc[:,0]\n",
    "print(np.shape(dig_data))\n",
    "\n",
    "plt.hist(dig_data ,density=0,bins=10,label=True,rwidth=0.5)\n",
    "# plt.hist(img[100].reshape(-1) ,density=1,bins=10,range=(0.2,1),label=True)\n",
    "# print((label==5).sum().item())\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data ,density=1,bins=10,label=True,rwidth=0.6)\n",
    "plt.ylabel('frequency')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
