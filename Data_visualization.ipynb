{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "# from imgaug.augmentables.segmaps import SegmentationMapOnImage\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "#         iaa.Scale((640, 480)),\n",
    "#         iaa.Fliplr(0.5),\n",
    "          iaa.Sometimes(0.8,iaa.PerspectiveTransform(scale=(0,0.2)))  \n",
    "#         iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0, 0.6))),\n",
    "#         iaa.Sometimes(0.1, iaa.AverageBlur(1.2)),\n",
    "#         iaa.Sometimes(1, iaa.Affine(rotate=(-20, 20),order=[0, 1],translate_px={\"x\":(-2, 2),\"y\":(-2,2)},mode='symmetric')),\n",
    "#         iaa.Sometimes(0.2,iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.25))),\n",
    "#         iaa.Sometimes(0.1, iaa.SaltAndPepper(0.05,False)),\n",
    "#         iaa.Invert(0.5),\n",
    "#         iaa.Add((-5, 5)), # change brightness of images (by -10 to 10 of original value)\n",
    "#         iaa.AdditiveGaussianNoise(-1,1)\n",
    "#         iaa.Sometimes(0.2,iaa.GammaContrast(2))\n",
    "            \n",
    "#         iaa.AddToHueAndSaturation(from_colorspace=\"GRAY\",value=(-20, 20))  #Hue-> color, saturation -> saido\n",
    "    ])\n",
    "    def __call__(self, img, mask=None):\n",
    "        img = np.array(img)        \n",
    "        return self.aug.augment_image(image=img)\n",
    "#         return self.aug(image=img, segmentation_maps=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "        transforms.ColorJitter(0.5,0.5,0,0),\n",
    "#         transforms.RandomAffine(degrees=15,translate=(0.25,0.25),scale=(0.75,1.25),shear=8),  #normal    \n",
    "#         transforms.Resize((224,224)), #For resnet\n",
    "#         transforms.RandomAffine(degrees=2,translate=(0.05,0.05)), #For 01 classifier\n",
    "#         transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),  #Used in Chris Deotte avgpool\n",
    "#         transforms.RandomAffine(degrees=10,translate=(0.2,0.2),scale=[0.9,1.1]), #For native distinguisher\n",
    "        ImgAugTransform(),\n",
    "        lambda x: Image.fromarray(x),\n",
    "        transforms.RandomAffine(degrees=15,translate=(0.015,0.015),scale=(0.9,1.1),shear=3),  #for Se_res18    \n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1  \n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n",
    "\n",
    "trans_dig = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n",
    "\n",
    "trans_val = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train distribution: mean=[0.08229437],std=[0.23876116]\n",
    "# dig augmented distribution: mean=[0.09549136],std=[0.24336776]\n",
    "# train large distribution: mean=[0.08889286],std=[0.24106438]\n",
    "\n",
    "def get_dataset_mean_std(dataloader):\n",
    "    print(\"Calculate distribution:\")\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in dataloader:\n",
    "        img = data[0].to(device)\n",
    "        batch_samples = img.size(0)\n",
    "        img = img.contiguous().view(batch_samples, img.size(1), -1)\n",
    "        mean += img.mean(2).sum(0)\n",
    "        std += img.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "        if nb_samples%5120 == 0:\n",
    "            print(\"Finished:\", nb_samples)\n",
    "            \n",
    "    print(\"num of samples:\",nb_samples)\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "#     print(\"Average mean:\",mean)\n",
    "#     print(\"Average std:\", std)\n",
    "    return mean.cpu().numpy(), std.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "# global_aug_dig = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")\n",
    "# global_dig = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# global_test_data = pd.read_csv(\"./dataset/test.csv\")\n",
    "# global_pseudo_data = pd.read_csv(\"./dataset/train_test_psuedo_65k.csv\")\n",
    "# global_critic01_data = pd.read_csv(\"./dataset/critic01_20k.csv\")\n",
    "\n",
    "\n",
    "class KMnistDataset(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None,indices=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = global_data\n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        self.indices = indices\n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_val\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        idx = self.indices[idx]\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = 0\n",
    "vr = 0\n",
    "k = 5\n",
    "indices_len = 60000\n",
    "# indices_len = 10240\n",
    "# indices_len = 120000\n",
    "\n",
    "###Single dataset\n",
    "indices = np.arange(indices_len)\n",
    "train_dataset = KMnistDataset(data_len=None,is_validate=False,validate_rate=vr,indices=indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# mean, std = get_dataset_mean_std(train_loader)\n",
    "# print(\"train distribution: mean={},std={}\".format(mean, std))\n",
    "\n",
    "for idx,data in enumerate(train_loader):\n",
    "    img, label = data\n",
    "    img, label = img.to(device), label.to(device)\n",
    "#     img = img.cpu().numpy()\n",
    "#     img = np.uint8(img*255).reshape(batch_size,-1)\n",
    "#     label = label.cpu().numpy()\n",
    "    \n",
    "    fig,axes = plt.subplots(1,1,figsize=(2,2))\n",
    "    img = img[0]\n",
    "    origin_img = img.clone()\n",
    "    axes.imshow(origin_img.cpu().numpy().reshape(28,28),cmap='gray')\n",
    "#     img = transforms.functional.adjust_brightness(img., 0.1)\n",
    "#     axes[1].imshow(img.cpu().numpy().reshape(28,28),cmap='gray')\n",
    "    plt.pause(.1)\n",
    "    if idx!=0 and idx%10 ==0 :\n",
    "        stop\n",
    "        input('stop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/critic01_20k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0,100):\n",
    "\n",
    "    i = idx\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = global_data.iloc[i, 0]\n",
    "    \n",
    "    if i%10==0:\n",
    "        plt.pause(.1)\n",
    "        fig, axes = plt.subplots(1,10,figsize=(16,2))\n",
    "    axes[i%10].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "    #     img = trans(img).cpu().numpy().reshape(28,28)\n",
    "    #     img = transforms.functional.adjust_brightness(img, 0.01)\n",
    "    #     img = transforms.functional.adjust_contrast(img, 0.01)\n",
    "    #     img = transforms.functional.adjust_saturation(img, 5)\n",
    "#         axes[j][1].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "#     img = global_data_dig.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "#     img = Image.fromarray(img)\n",
    "#     label = global_data_dig.iloc[i, 0]\n",
    "#     axes[2].imshow(img,cmap=\"gray\")\n",
    "#     img = trans(img).cpu().numpy().reshape(28,28)\n",
    "#     axes[3].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "\n",
    "    print(\"Label:\",label)\n",
    "\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Imgaug Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "time_counter = np.zeros((5,))\n",
    "for i in range(0,1000):\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = data.iloc[i, 0]\n",
    "    img = np.array(img)\n",
    "    t = time.clock()\n",
    "    iaa.GaussianBlur(sigma=(0, 0.6)).augment_image(img)\n",
    "    time_counter[0] += time.clock()-t\n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.AverageBlur(2).augment_image(img)\n",
    "    time_counter[1] += time.clock()-t\n",
    "    \n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.MedianBlur(3).augment_image(img)\n",
    "    time_counter[2] += time.clock()-t\n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.MotionBlur(180,-1).augment_image(img)\n",
    "    time_counter[3] += time.clock()-t    \n",
    "\n",
    "print(time_counter/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff between train_set and Dig_val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Seq_Ex_Block(nn.Module):\n",
    "    def __init__(self, in_ch, r=16):\n",
    "        super(Seq_Ex_Block, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(in_ch, in_ch//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch//r, in_ch),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "#         print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "        return x.mul(se_weight)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "class SE_Net2(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(SE_Net2,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.se1 = Seq_Ex_Block(in_ch=64,r=8)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.se2 = Seq_Ex_Block(in_ch=128,r=8)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.se3 = Seq_Ex_Block(in_ch=256,r=8)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.leaky_relu(self.c1(x),0.1))\n",
    "        x = self.bn2(F.leaky_relu(self.c2(x),0.1))\n",
    "        x = self.bn3(F.leaky_relu(self.c3(x),0.1))\n",
    "        x = self.se1(x)\n",
    "        x = self.d1(self.m1(x))\n",
    "        \n",
    "        x = self.bn4(F.leaky_relu(self.c4(x),0.1))\n",
    "        x = self.bn5(F.leaky_relu(self.c5(x),0.1))\n",
    "        x = self.bn6(F.leaky_relu(self.c6(x),0.1))\n",
    "        x = self.se2(x)\n",
    "        x = self.d2(self.m2(x))\n",
    "        \n",
    "        x = self.bn7(F.leaky_relu(self.c7(x),0.1))\n",
    "        x = self.se3(x)\n",
    "        x = self.d3(self.m3(x))\n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn8(F.relu(self.fc1(x),0.1))\n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n",
    "\n",
    "\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn4 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c5 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c7 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn7 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn8 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.bn9 = nn.BatchNorm1d(128,1e-3,0.01)\n",
    "        \n",
    "        self.out = nn.Linear(128,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.relu(self.c1(x)))\n",
    "        x = self.bn2(F.relu(self.c2(x)))\n",
    "        x = self.bn3(F.relu(self.c3(x)))\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.bn4(F.relu(self.c4(x)))\n",
    "        x = self.bn5(F.relu(self.c5(x)))\n",
    "        x = self.bn6(F.relu(self.c6(x)))\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.bn7(F.relu(self.c7(x)))\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)        \n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        \n",
    "        x = self.bn8(self.fc1(x))\n",
    "        x = self.bn9(self.fc2(x))\n",
    "        \n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in')\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n",
    "        \n",
    "class convNet_native(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet_native,self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.c2 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c3 = nn.Conv2d(64,128,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(128,0.1)\n",
    "        self.c4 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(128,0.1)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.bn5 = nn.BatchNorm2d(256,0.1)\n",
    "        self.c6 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn6 = nn.BatchNorm2d(256,0.1)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(256*3*3,256)  #layer for binary entropy\n",
    "        self.d4 = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.bn1(self.c1(x)),negative_slope=0.1)\n",
    "        x = F.leaky_relu(self.bn2(self.c2(x)),0.1)\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn3(self.c3(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn4(self.c4(x)),0.1)\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn5(self.c5(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn6(self.c6(x)),0.1)\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        x = x.view(-1, 256*3*3) #reshape\n",
    "        x_b = F.leaky_relu(self.fc(x),0.1)\n",
    "        x_b = self.d4(x_b)\n",
    "        return self.out(x_b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native_model = convNet_native(in_channels=1)\n",
    "# native_model.cuda()\n",
    "# native_model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble/native_classifier/Fold0_loss0.0242_acc_b99.704_without_aug\"))\n",
    "# native_model.eval()\n",
    "\n",
    "dig_model = convNet(in_channels=1)\n",
    "dig_model.cuda()\n",
    "dig_model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble_dig/SE_net2_60k/dig_Fold0_loss0.0093_acc99.720\"))\n",
    "dig_model.eval()\n",
    "\n",
    "# se_model = SE_Net2(in_channels=1)\n",
    "# se_model.cuda()\n",
    "# se_model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble_dig/SE_net2_60k/dig_Fold0_loss0.0093_acc99.720\"))\\\n",
    "# se_model.eval()\n",
    "\n",
    "# model = convNet(in_channels=1)\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load(\"Kmnist_saved_model/ensemble/10_fold_tuned_cnn/adam/Fold8_loss0.0033_acc99.917\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model num: 1\n",
      "finished: 10240\n",
      "(10240,) (0,) (10240,)\n"
     ]
    }
   ],
   "source": [
    "vr = 1\n",
    "indices=np.arange(60000)\n",
    "dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr,indices=indices)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "## Test Native Classifier\n",
    "# counter = 0\n",
    "# data_num = 0\n",
    "# with torch.no_grad():\n",
    "#     for idx,data in enumerate(loader):\n",
    "#         img, label = data\n",
    "#         img, label = img.to(device), label.to(device)\n",
    "#         img = data[0].to(device)\n",
    "        \n",
    "#         _,pred_native = torch.max(native_model(img),dim=1)\n",
    "#         counter += (pred_native.cpu().numpy()).sum()\n",
    "#         data_num += img.size(0)\n",
    "        \n",
    "# print(\"Native rate:\",counter/data_num)\n",
    "# print(\"Non Native rate:\",1-(counter/data_num))\n",
    "\n",
    "# ### Inference models\n",
    "ensemble_models = []\n",
    "ensemble_root = \"Kmnist_saved_model/ensemble_dig/baseline_cnn_60k_3fold\"\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = convNet(in_channels=1)\n",
    "#     model = SE_Net2(in_channels=1)\n",
    "\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "model_num = len(ensemble_models)\n",
    "print(\"model num:\",model_num)\n",
    "\n",
    "result = np.array([])\n",
    "result_dig = np.array([])\n",
    "labels = np.array([])\n",
    "data_num = 0\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        ###Average Ensemble\n",
    "        pred_list = torch.Tensor([]).to(device)\n",
    "        for i in range(model_num):\n",
    "            pred = ensemble_models[i](img) #(batch_num,10)\n",
    "            pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "        pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "        _,pred = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "#         _,pred = torch.max(model(img),dim=1)\n",
    "        \n",
    "#         _,pred_dig = torch.max(dig_model(img),dim=1)\n",
    "        result = np.concatenate([result,pred.cpu().numpy()],axis=0)\n",
    "#         result_dig = np.concatenate([result_dig,pred_di-g.cpu().numpy()],axis=0)\n",
    "        labels = np.concatenate([labels,label.cpu().numpy()],axis=0)\n",
    "        data_num += img.size(0)\n",
    "\n",
    "print(\"finished:\",data_num)\n",
    "print(np.shape(result),np.shape(result_dig),np.shape(labels))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1024\n",
      "         1.0       1.00      1.00      1.00      1024\n",
      "         2.0       1.00      1.00      1.00      1024\n",
      "         3.0       1.00      1.00      1.00      1024\n",
      "         4.0       1.00      1.00      1.00      1024\n",
      "         5.0       1.00      1.00      1.00      1024\n",
      "         6.0       1.00      1.00      1.00      1024\n",
      "         7.0       1.00      1.00      1.00      1024\n",
      "         8.0       1.00      1.00      1.00      1024\n",
      "         9.0       1.00      1.00      1.00      1024\n",
      "\n",
      "    accuracy                           1.00     10240\n",
      "   macro avg       1.00      1.00      1.00     10240\n",
      "weighted avg       1.00      1.00      1.00     10240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 69.0, 'Predicted label')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "###Confusion matrix\n",
    "print(classification_report(labels, result))\n",
    "plt.figure(figsize=(10,10))\n",
    "confusion_mat = confusion_matrix(labels, result)\n",
    "sn.heatmap(confusion_mat, annot=True, cmap='YlGnBu')\n",
    "plt.title('Confusion matrix of Real World validation result')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices1 = np.where(result!=labels)[0]       #(num)\n",
    "indices2 = np.where(result_dig!=labels)[0]\n",
    "indices3 = np.where((result!=labels)&(result_dig==labels))[0]\n",
    "indices4 = np.where((result==labels))[0]\n",
    "\n",
    "cirtic_idx_list_ans0 = []\n",
    "idx_list_ans1 = []\n",
    "\n",
    "cirtic_idx_list_ans9 = []\n",
    "label_list = []\n",
    "count = 0\n",
    "print(len(indices1),len(indices2),len(indices3),len(indices4))  #dig: 912 51 878\n",
    "#up: 954\n",
    "for i in range(0,len(indices1)):\n",
    "    idx = indices1[i]\n",
    "#     img1 = global_dig.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "#     img1 = global_pseudo_data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = global_data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = Image.fromarray(img1)\n",
    "    label1 = result[idx]\n",
    "#     label2 = result_dig[idx]\n",
    "    label2 = None\n",
    "    label = labels[idx]\n",
    "  \n",
    "\n",
    "#     if label == 0:\n",
    "#         fig, axes = plt.subplots(1,1,figsize=(2,2))\n",
    "# #         cirtic_idx_list_ans0.append(idx)\n",
    "#         axes.imshow(img1,cmap=\"gray\")\n",
    "#         print(idx)\n",
    "#         print(\"Model:\",label1,\" Model2:\",label2,\" Label:\",label)\n",
    "#         plt.pause(.1)\n",
    "#     else:\n",
    "#         continue\n",
    "        \n",
    "\n",
    "# print(idx_list_ans1)\n",
    "# np.save(\"idx_ans1\",idx_list_ans1)\n",
    "\n",
    "# print(cirtic_idx_list_ans0)\n",
    "# print(cirtic_idx_list_ans9)\n",
    "\n",
    "cirtic_idx_list_ans0_v2 = [5520,6150,12280,18560,32730]\n",
    "np.save(\"critic_idx_ans0_v2\",cirtic_idx_list_ans0_v2)\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# data = np.uint8(cirtic_label_list)\n",
    "# print(len(data))\n",
    "# plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "# plt.xticks(range(10))\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# data = np.uint8(label_list)\n",
    "# print(len(data))\n",
    "# plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "# plt.xticks(range(10))\n",
    "# plt.ylabel('frequency')\n",
    "\n",
    "\n",
    "# 31 1 0 59969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine train.csv and Dig augmented, add additional \"native writer label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"native_label,label,\" + pix_str\n",
    "\n",
    "origin_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "dig_aug_data = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = np.array(origin_data).astype(int)\n",
    "dig_aug_csv = np.array(dig_aug_data).astype(int)\n",
    "native_label0 = np.zeros((60000,1)).astype(int)\n",
    "native_label1 = np.ones((60000,1)).astype(int)\n",
    "\n",
    "train_csv = np.concatenate([native_label1,train_csv],axis=1)\n",
    "dig_aug_csv = np.concatenate([native_label0,dig_aug_csv],axis=1)\n",
    "\n",
    "print(np.shape(train_csv))\n",
    "print(np.shape(dig_aug_csv))\n",
    "new_csv = np.vstack([train_csv,dig_aug_csv])\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset/train_large.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment dig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vr = 0\n",
    "batch_size = 1024\n",
    "dataset = KMnistDataset(data_len=None,is_validate=False, validate_rate=vr)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "num_per_class = 6000  # 6000 * 10 =60000\n",
    "\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# dig_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "\n",
    "###Load original 10240 data\n",
    "origin_img = dig_data.iloc[:, 1:].values.astype(np.uint8).reshape((-1,784))  #value: 0~255\n",
    "origin_label = np.array(dig_data.iloc[:,0]).astype(int)\n",
    "\n",
    "for i in range(len(origin_img)):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    tmp_img = origin_img[i]    #(784,)\n",
    "    tmp_label = origin_label[i].reshape(-1) #(1,)\n",
    "    csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "    aug_list = np.vstack((aug_list,csv_arr))\n",
    "    counter_list[tmp_label] += 1\n",
    "\n",
    "print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "print(\"counter_list:\",counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###Augment data by random select and affine\n",
    "keep_loop = True\n",
    "while keep_loop:\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(batch_size,-1)\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            tmp_img = img[i]    #(784,)\n",
    "            tmp_label = label[i].reshape(-1) #(1,)\n",
    "            if counter_list[tmp_label] >= num_per_class:\n",
    "                continue\n",
    "#             print(np.shape(tmp_label),np.shape(tmp_img))\n",
    "            csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "#             print(\"csv arr shape:\",np.shape(csv_arr))\n",
    "            \n",
    "            aug_list = np.vstack((aug_list,csv_arr))\n",
    "#             print(\"aug_list shape:\",np.shape(aug_list))\n",
    "            counter_list[tmp_label] += 1\n",
    "\n",
    "        print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "        print(\"counter_list:\",counter_list)\n",
    "        if (counter_list>=num_per_class).all() == True:\n",
    "            print(\"Augment Finished\")\n",
    "            print(np.shape(aug_list))\n",
    "            print(counter_list)\n",
    "            np.savetxt(\"./dataset/Dig-Mnist-Augmented.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            keep_loop = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trans_test = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_len=None):\n",
    "        self.data = pd.read_csv(\"./dataset/test.csv\")\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        self.transform = trans_test\n",
    "        if data_len == None:\n",
    "            self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        return img, torch.Tensor([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "test_dataset = TestDataset(data_len=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "### Inference models\n",
    "ensemble_models = []\n",
    "ensemble_root = \"Kmnist_saved_model/ensemble/10_fold_tuned_cnn/adam_batch1024_baseline\"\n",
    "for file_name in os.listdir(ensemble_root):\n",
    "    if file_name.find(\"Fold\") == -1:\n",
    "        continue\n",
    "    model = convNet(in_channels=1)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "model_num = len(ensemble_models)\n",
    "print(\"model num:\",model_num)\n",
    "\n",
    "psuedo_labels = np.array([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(test_loader):\n",
    "            img, label = data\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            ###Average Ensemble\n",
    "            pred_list = torch.Tensor([]).to(device)\n",
    "            for i in range(model_num):\n",
    "                pred = ensemble_models[i](img) #(batch_num,10)\n",
    "                pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "            pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "            _,pred = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "    #         _,pred = torch.max(model(img),dim=1)\n",
    "\n",
    "            psuedo_labels = np.concatenate([psuedo_labels,pred.cpu().numpy()],axis=0)\n",
    "            data_num += img.size(0)\n",
    "            \n",
    "print(\"Inference complete:\",np.shape(psuedo_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "test_csv = np.array(pd.read_csv(\"./dataset/test.csv\")).astype(int)[:,1:]\n",
    "\n",
    "print(np.shape(test_csv))\n",
    "\n",
    "pseudo_labels = psuedo_labels.reshape(-1,1).astype(int)\n",
    "print(\"shape psuedo_labels:\",np.shape(psuedo_labels))\n",
    "test_csv = np.concatenate([pseudo_labels,test_csv],axis=1)\n",
    "\n",
    "print(np.shape(test_csv))\n",
    "np.savetxt(\"./dataset/test_psuedo_label.csv\", test_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n",
    "test_csv = pd.read_csv(\"./dataset/test_psuedo_label.csv\")\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented psuedo_label test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trans_aug = transforms.Compose([\n",
    "        transforms.ColorJitter(0.5,0.2,0,0),\n",
    "        transforms.RandomAffine(degrees=10,translate=(0.1,0.1),scale=(0.9,1.1)),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "class AugDataset(Dataset):\n",
    "    def __init__(self,data_len=None):\n",
    "        self.data = pd.read_csv(\"./dataset/test_psuedo_label.csv\")\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        self.transform = trans_aug\n",
    "        if data_len == None:\n",
    "            self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "vr = 0\n",
    "batch_size = 1024\n",
    "dataset = AugDataset(data_len=None)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "num_per_class = 6000  # 6000 * 10 =60000\n",
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "    \n",
    "###Augment data by random select and affine\n",
    "keep_loop = True\n",
    "while keep_loop:\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(-1,784)\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        for i in range(img.shape[0]):\n",
    "            tmp_img = img[i]    #(784,)\n",
    "            tmp_label = label[i].reshape(-1) #(1,)\n",
    "            if counter_list[tmp_label] >= num_per_class:\n",
    "                continue\n",
    "#             print(np.shape(tmp_label),np.shape(tmp_img))\n",
    "            csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "#             print(\"csv arr shape:\",np.shape(csv_arr))\n",
    "            \n",
    "            aug_list = np.vstack((aug_list,csv_arr))\n",
    "#             print(\"aug_list shape:\",np.shape(aug_list))\n",
    "            counter_list[tmp_label] += 1\n",
    "\n",
    "        print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "        print(\"counter_list:\",counter_list)\n",
    "        if (counter_list>=num_per_class).all() == True:\n",
    "            print(\"Augment Finished\")\n",
    "            print(np.shape(aug_list))\n",
    "            print(counter_list)\n",
    "            np.savetxt(\"./dataset/test_psuedo_augmented.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            keep_loop = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine train.csv with test_psuedo_aug.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "train_csv = np.array(pd.read_csv(\"./dataset/train.csv\")).astype(int)\n",
    "test_csv = np.array(pd.read_csv(\"./dataset/test_psuedo_label.csv\")).astype(int)\n",
    "# test_csv = np.array(pd.read_csv(\"./dataset/test_psuedo_augmented.csv\")).astype(int)\n",
    "\n",
    "print(np.shape(train_csv))\n",
    "print(np.shape(test_csv))\n",
    "new_csv = np.vstack([train_csv,test_csv])\n",
    "np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "np.random.shuffle(new_csv)\n",
    "np.random.shuffle(new_csv)\n",
    "\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset/train_test_psuedo_65k.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented train dataset with critic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " global_data = pd.read_csv(\"./dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_aug = transforms.Compose([\n",
    "        transforms.ColorJitter(0.9,0.2,0,0),\n",
    "        transforms.RandomAffine(degrees=20,translate=(0.1,0.05),scale=(0.8,1.05)),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "class AugDataset(Dataset):\n",
    "    def __init__(self,critic_idx_list=None):\n",
    "        self.data = global_data\n",
    "        self.transform = trans_aug\n",
    "        self.critic_idx_list = critic_idx_list\n",
    "        print(\"data len:\", np.shape(self.critic_idx_list))\n",
    "        self.len = len(critic_idx_list)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.critic_idx_list[idx]\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "batch_size = 10\n",
    "critic_idx_list = np.load(\"./critic_idx_ans0.npy\")\n",
    "# critic_idx_list = np.load(\"./idx_ans1.npy\")\n",
    "dataset = AugDataset(critic_idx_list)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "    \n",
    "###Augment data by random select and affine\n",
    "data_num = 0\n",
    "for ep in range(50000):\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(-1,784)\n",
    "        label = label.cpu().numpy().reshape(-1,1)\n",
    "        \n",
    "#         batch_num = np.shape(img)[0]\n",
    "#         fig,axes = plt.subplots(1,batch_num,figsize=(10,2))\n",
    "#         for i in range(batch_num):\n",
    "#             axes[i].imshow(img[i].reshape(28,28),cmap='gray')\n",
    "#         plt.pause(.1)\n",
    "        \n",
    "        csv_arr = np.hstack([label,img])\n",
    "        aug_list = np.vstack([aug_list,csv_arr])\n",
    "        data_num += img.shape[0]\n",
    "        if data_num %2000==0:\n",
    "            print(data_num)\n",
    "        if data_num > 10000:\n",
    "            print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "            aug_list = aug_list[:10000]\n",
    "            np.savetxt(\"./dataset/critic0_10k_complicated.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine label1_10k with critic0_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "critic0_csv = np.array(pd.read_csv(\"./dataset/critic0_10k_complicated.csv\")).astype(int)\n",
    "label1_csv = np.array(pd.read_csv(\"./dataset/label1_10k.csv\")).astype(int)\n",
    "\n",
    "print(np.shape(critic0_csv))\n",
    "print(np.shape(label1_csv))\n",
    "new_csv = np.vstack([critic0_csv,label1_csv])\n",
    "np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "np.random.shuffle(new_csv)\n",
    "np.random.shuffle(new_csv)\n",
    "\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset/critic01_20k_complicated.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data = np.random.random([1000,])\n",
    "# global_data = pd.read_csv(\"./dataset/train_large.csv\")\n",
    "global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "# global_data_test = pd.read_csv(\"./dataset/train_test_psuedo_aug.csv\")\n",
    "global_data_test = pd.read_csv(\"./dataset/train_test_psuedo_65k.csv\")\n",
    "\n",
    "# data1 = global_data.iloc[:10,1:]\n",
    "data2 = global_data_test.iloc[:,0]\n",
    "\n",
    "plt.hist(data2 ,density=0,label=True,rwidth=0.3)\n",
    "plt.xticks(range(0,10))\n",
    "\n",
    "# print((label==5).sum().item())\n",
    "# plt.ylabel('frequency')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
