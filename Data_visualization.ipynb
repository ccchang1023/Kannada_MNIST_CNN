{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dig = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1    \n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1    \n",
    "#         transforms.Normalize(mean=[0.08889289],std=[0.24106446])  #train_large dataset distribution\n",
    "#         transforms.Normalize(mean=[0.08229437],std=[0.23876116]) #train dataset dist\n",
    "#         transforms.Normalize(mean=[0.09549136],std=[0.24336776]) #dig_augmented distribution\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train distribution: mean=[0.08229437],std=[0.23876116]\n",
    "# dig augmented distribution: mean=[0.09549136],std=[0.24336776]\n",
    "# train large distribution: mean=[0.08889286],std=[0.24106438]\n",
    "\n",
    "def get_dataset_mean_std(dataloader):\n",
    "    print(\"Calculate distribution:\")\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in dataloader:\n",
    "        img = data[0].to(device)\n",
    "        batch_samples = img.size(0)\n",
    "        img = img.contiguous().view(batch_samples, img.size(1), -1)\n",
    "        mean += img.mean(2).sum(0)\n",
    "        std += img.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "        if nb_samples%5120 == 0:\n",
    "            print(\"Finished:\", nb_samples)\n",
    "            \n",
    "    print(\"num of samples:\",nb_samples)\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "#     print(\"Average mean:\",mean)\n",
    "#     print(\"Average std:\", std)\n",
    "    return mean.cpu().numpy(), std.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "global_aug_dig = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")\n",
    "global_dig = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "\n",
    "class KMnistDataset(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = global_aug_dig\n",
    "#         self.data = global_data\n",
    "        print(\"data shape:\", np.shape(self.data))\n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_dig\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_workers = 4\n",
    "vr = 0\n",
    "k = 5\n",
    "# indices_len = 60000\n",
    "indices_len = 10240\n",
    "# indices_len = 120000\n",
    "\n",
    "###Single dataset\n",
    "indices = np.arange(indices_len)\n",
    "train_dataset = KMnistDataset(data_len=None,is_validate=False,validate_rate=vr,indices=indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "mean, std = get_dataset_mean_std(train_loader)\n",
    "print(\"train distribution: mean={},std={}\".format(mean, std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for idx in range(2000,2010):\n",
    "    i = np.random.randint(0,60000)\n",
    "    fig, axes = plt.subplots(1,4,figsize=(8,2))\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = global_data.iloc[i, 0]\n",
    "    axes[0].imshow(img,cmap=\"gray\")\n",
    "    img = trans(img).cpu().numpy().reshape(28,28)\n",
    "    axes[1].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "    img = global_data_dig.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = global_data_dig.iloc[i, 0]\n",
    "    axes[2].imshow(img,cmap=\"gray\")\n",
    "    img = trans(img).cpu().numpy().reshape(28,28)\n",
    "    axes[3].imshow(img,cmap=\"gray\")\n",
    "    \n",
    "    plt.pause(.1)\n",
    "    print(\"Label:\",label)\n",
    "\n",
    "# data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Imgaug Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "time_counter = np.zeros((5,))\n",
    "for i in range(0,1000):\n",
    "    img = global_data.iloc[i, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img = Image.fromarray(img)\n",
    "    label = data.iloc[i, 0]\n",
    "    img = np.array(img)\n",
    "    t = time.clock()\n",
    "    iaa.GaussianBlur(sigma=(0, 0.6)).augment_image(img)\n",
    "    time_counter[0] += time.clock()-t\n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.AverageBlur(2).augment_image(img)\n",
    "    time_counter[1] += time.clock()-t\n",
    "    \n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.MedianBlur(3).augment_image(img)\n",
    "    time_counter[2] += time.clock()-t\n",
    "    \n",
    "    t = time.clock()\n",
    "    iaa.MotionBlur(180,-1).augment_image(img)\n",
    "    time_counter[3] += time.clock()-t    \n",
    "\n",
    "print(time_counter/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff between train_set and Dig_val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.c2 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c3 = nn.Conv2d(64,128,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(128,0.1)\n",
    "        self.c4 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(128,0.1)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.bn5 = nn.BatchNorm2d(256,0.1)\n",
    "        self.c6 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn6 = nn.BatchNorm2d(256,0.1)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(256*3*3,256)  #layer for 10 classes cross entropy\n",
    "        self.d4 = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.bn1(self.c1(x)),negative_slope=0.1)\n",
    "        x = F.leaky_relu(self.bn2(self.c2(x)),0.1)\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn3(self.c3(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn4(self.c4(x)),0.1)\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn5(self.c5(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn6(self.c6(x)),0.1)\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        x = x.view(-1, 256*3*3) #reshape\n",
    "        \n",
    "        x_c = F.leaky_relu(self.fc(x),0.1)\n",
    "        x_c = self.d4(x_c)\n",
    "        \n",
    "        return self.out(x_c)\n",
    "\n",
    "class convNet_native(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(convNet_native,self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.c2 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64,momentum=0.1)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c3 = nn.Conv2d(64,128,5,1,2)\n",
    "        self.bn3 = nn.BatchNorm2d(128,0.1)\n",
    "        self.c4 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(128,0.1)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.bn5 = nn.BatchNorm2d(256,0.1)\n",
    "        self.c6 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn6 = nn.BatchNorm2d(256,0.1)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc = nn.Linear(256*3*3,256)  #layer for binary entropy\n",
    "        self.d4 = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.leaky_relu(self.bn1(self.c1(x)),negative_slope=0.1)\n",
    "        x = F.leaky_relu(self.bn2(self.c2(x)),0.1)\n",
    "        x = self.m1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn3(self.c3(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn4(self.c4(x)),0.1)\n",
    "        x = self.m2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.bn5(self.c5(x)),0.1)\n",
    "        x = F.leaky_relu(self.bn6(self.c6(x)),0.1)\n",
    "        x = self.m3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        x = x.view(-1, 256*3*3) #reshape\n",
    "        x_b = F.leaky_relu(self.fc(x),0.1)\n",
    "        x_b = self.d4(x_b)\n",
    "        return self.out(x_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import convNet, convNet_val\n",
    "\n",
    "native_model = convNet_native(in_channels=1)\n",
    "native_model.cuda()\n",
    "native_model.load_state_dict(torch.load(\"Kmnist_saved_model/native_classifier/Fold0_loss0.0242_acc_b99.704_without_aug\"))\n",
    "native_model.eval()\n",
    "\n",
    "# dig_model = convNet(in_channels=1)\n",
    "# dig_model.cuda()\n",
    "# dig_model.load_state_dict(torch.load(\"Kmnist_saved_model/Fold0_loss0.010_acc99.863\"))\n",
    "# dig_model.eval()\n",
    "\n",
    "# model = convNet(in_channels=1)\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load(\"Kmnist_saved_model/ep70_acc0.9978\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (60000, 785)\n",
      "Native rate: 0.008066666666666666\n",
      "Non Native rate: 0.9919333333333333\n"
     ]
    }
   ],
   "source": [
    "vr = 1\n",
    "dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "### Test Native Classifier\n",
    "counter = 0\n",
    "data_num = 0\n",
    "with torch.no_grad():\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        _,pred_native = torch.max(native_model(img),dim=1)\n",
    "        counter += (pred_native.cpu().numpy()).sum()\n",
    "        data_num += img.size(0)\n",
    "        \n",
    "print(\"Native rate:\",counter/data_num)\n",
    "print(\"Non Native rate:\",1-(counter/data_num))\n",
    "\n",
    "# result = np.array([])\n",
    "# result_dig = np.array([])\n",
    "# labels = np.array([])\n",
    "# data_num = 0\n",
    "# with torch.no_grad():\n",
    "#     for idx,data in enumerate(loader):\n",
    "#         img, label = data\n",
    "#         img, label = img.to(device), label.to(device)\n",
    "#         _,pred = torch.max(model(img),dim=1)\n",
    "#         _,pred_dig = torch.max(dig_model(img),dim=1)\n",
    "#         result = np.concatenate([result,pred.cpu().numpy()],axis=0)\n",
    "#         result_dig = np.concatenate([result_dig,pred_dig.cpu().numpy()],axis=0)\n",
    "#         labels = np.concatenate([labels,label.cpu().numpy()],axis=0)\n",
    "#         data_num += img.size(0)\n",
    "\n",
    "# print(\"finished:\",data_num)\n",
    "# print(np.shape(result),np.shape(result_dig),np.shape(labels))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933 15 922\n",
      "922\n",
      "141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAD4CAYAAAAq7wVkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUY0lEQVR4nO3df7DddZ3f8edLAuXHwvDrQrNETJiJVOqMAe+wKDPMLhEHhZV01V3Y6mQtbXZ2XARtZ41uZ+zOtB2Y2dHddjralOhmrYsCQqHqoDSC1v2B3mAsYLRBjBjJJtcVBKUjhn33j/PNNg33Jt8b9nvP/dw8HzN3zvl+z/me74sL5JXP5/vjpKqQJElteMm4A0iSpP4sbkmSGmJxS5LUEItbkqSGWNySJDVkybgD9HH66afX8uXLxx1DkqR5sWXLlh9W1cRMrzVR3MuXL2dqamrcMSRJmhdJvjfba06VS5LUEItbkqSGWNySJDXE4pYkqSEWtyRJDbG4JUlqiMUtSVJDLG5JkhpicUuS1JAm7pwmSdI+y9d/dtwRZrTjxivmZT+OuCVJaojFLUlSQyxuSZIaMmhxJ3l3kkeSPJzkliTHJlmR5IEk25N8KskxQ2aQJGkxGay4k5wFvAuYrKpXAkcBVwM3AR+qqpXAk8C1Q2WQJGmxGXqqfAlwXJIlwPHALuBS4Pbu9U3AmoEzSJK0aAxW3FX1A+APgccZFfaPgS3AU1W1t3vbTuCsmbZPsi7JVJKp6enpoWJKktSUIafKTwGuAlYAvwicALxhhrfWTNtX1YaqmqyqyYmJiaFiSpLUlCGnyl8HfLeqpqvq58AdwGuBk7upc4BlwBMDZpAkaVEZsrgfBy5KcnySAKuBbwL3AW/p3rMWuGvADJIkLSpDHuN+gNFJaA8CD3X72gC8F3hPkkeB04CNQ2WQJGmxGfRe5VX1AeADB6x+DLhwyP1KkrRYeec0SZIaYnFLktQQi1uSpIZY3JIkNcTiliSpIRa3JEkNsbglSWqIxS1JUkMsbkmSGmJxS5LUEItbkqSGWNySJDXE4pYkqSEWtyRJDbG4JUlqiMUtSVJDBivuJOcm2brfz9NJbkhyapJ7k2zvHk8ZKoMkSYvNYMVdVd+uqlVVtQp4NfAscCewHthcVSuBzd2yJEnqYb6mylcD36mq7wFXAZu69ZuANfOUQZKk5s1XcV8N3NI9P7OqdgF0j2fMtEGSdUmmkkxNT0/PU0xJkha2wYs7yTHAm4Db5rJdVW2oqsmqmpyYmBgmnCRJjZmPEfcbgAerane3vDvJUoDucc88ZJAkaVGYj+K+hv83TQ5wN7C2e74WuGseMkiStCgMWtxJjgcuA+7Yb/WNwGVJtnev3ThkBkmSFpMlQ354VT0LnHbAur9hdJa5JEmaI++cJklSQyxuSZIaYnFLktQQi1uSpIZY3JIkNcTiliSpIRa3JEkNsbglSWqIxS1JUkMsbkmSGmJxS5LUEItbkqSGWNySJDXE4pYkqSEWtyRJDbG4JUlqyKDFneTkJLcn+VaSbUlek+TUJPcm2d49njJkBkmSFpOhR9x/DNxTVf8IeBWwDVgPbK6qlcDmblmSJPUwWHEnOQm4BNgIUFXPVdVTwFXApu5tm4A1Q2WQJGmxGXLEfQ4wDXwsydeT3JzkBODMqtoF0D2eMdPGSdYlmUoyNT09PWBMSZLaMWRxLwEuAD5cVecDP2UO0+JVtaGqJqtqcmJiYqiMkiQ1Zcji3gnsrKoHuuXbGRX57iRLAbrHPQNmkCRpURmsuKvqr4HvJzm3W7Ua+CZwN7C2W7cWuGuoDJIkLTZLBv7864BPJDkGeAx4B6O/LNya5FrgceCtA2eQJGnRGLS4q2orMDnDS6uH3K8kSYuVd06TJKkhFrckSQ2xuCVJaojFLUlSQyxuSZIaYnFLktQQi1uSpIZY3JIkNcTiliSpIRa3JEkNsbglSWqIxS1JUkMOWdxJTp2PIJIk6dD6jLgfSHJbkjcmyeCJJEnSrPoU98uBDcDbgUeT/PskLx82liRJmskhi7tG7q2qa4B/DqwFvprkS0leM3hCSZL0d5Yc6g1JTgPexmjEvRu4DrgbWAXcBqw4yLY7gGeA54G9VTXZHTP/FLAc2AH8elU9+WL+ISRJOlL0mSr/S+AkYE1VXVFVd1TV3qqaAj7SY/tfqapVVTXZLa8HNlfVSmBztyxJkno45IgbOLeqaqYXquqmw9jnVcAvd883AfcD7z2Mz5Ek6YjTZ8T9hSQn71tIckqSz/f8/Oq235JkXbfuzKraBdA9njHThknWJZlKMjU9Pd1zd5IkLW59RtwTVfXUvoWqejLJjGU7g4ur6onu/fcm+VbfYFW1gdHZ7ExOTs444pck6UjTZ8T9fJKz9y0keRmjkfQhVdUT3eMe4E7gQmB3kqXdZy0F9sw1tCRJR6o+xf37wFeSfDzJx4EvA+871EZJTkhy4r7nwOuBhxmdkb62e9ta4K7DCS5J0pHokFPlVXVPkguAi4AA766qH/b47DOBO7ubrS0B/qz7rK8Btya5FngceOthp5ck6QjT5xg3wD8AftS9/7wkVNWXD7ZBVT0GvGqG9X8DrJ5rUEmS1O8GLDcBvwE8Avxtt7oYTZlLkqR51GfEvYbRtdw/GzqMJEk6uD4npz0GHD10EEmSdGh9RtzPAluTbAb+btRdVe8aLJUkSZpRn+K+u/uRJElj1udysE1JjgPOrqpvz0MmSZI0i0Me407yq8BW4J5ueVUSR+CSJI1Bn5PT/g2jW5U+BVBVWznId3BLkqTh9CnuvVX14wPW+aUfkiSNQZ+T0x5O8pvAUUlWAu8C/mLYWJIkaSZ9RtzXAf+Y0aVgtwBPAzcMGUqSJM2sz1nlzzL6hrDfHz6OJEk6mD73Kr+PGY5pV9WlgySSJEmz6nOM+1/t9/xY4M3A3mHiSJKkg+kzVb7lgFV/nuRLA+WRJEkH0Weq/NT9Fl8CvBr4h4MlkiRJs+ozVb6F0THuMJoi/y5wbd8dJDkKmAJ+UFVXJlkBfBI4FXgQeHtVPTfX4JIkHYkOeTlYVa2oqnO6x5VV9fqq+soc9nE9sG2/5ZuAD1XVSuBJ5vCXAEmSjnR9psp/7WCvV9UdB9l2GXAF8O+A9yQJcCnwm91bNjG6peqHe+aVJOmI1meq/FrgtcAXu+VfAe4HfsxoCn3W4gb+CPg94MRu+TTgqarad1b6TuCsmTZMsg5YB3D22Wf3iClJ0uLX585pBZxXVW+uqjczuosaVfWOqvpns22U5EpgzwFnpWeWz3/hyqoNVTVZVZMTExM9YkqStPj1GXEvr6pd+y3vBl7eY7uLgTcleSOj679PYjQCPznJkm7UvQx4Yo6ZJUk6YvUZcd+f5PNJfivJWuCzwH2H2qiq3ldVy6pqOXA18MWq+qfdtm/p3rYWuOvwokuSdOTpc1b57wIfAV4FrAI2VNV1L2Kf72V0otqjjI55b3wRnyVJ0hGlz1Q5jK63fqaq/keS45OcWFXP9N1JVd3P6IQ2quox4MK5BpUkST1G3En+BXA78J+7VWcB/23IUJIkaWZ9jnG/k9GJZk8DVNV24IwhQ0mSpJn1Ke6f7X9L0iRLmOUSLkmSNKw+xf2lJO8HjktyGXAb8N+HjSVJkmbSp7jXA9PAQ8BvA58D/vWQoSRJ0swOelZ5981em6rqbcB/mZ9IkiRpNgcdcVfV88BEkmPmKY8kSTqIPtdx7wD+PMndwE/3rayqDw4VSpIkzWzWEXeSj3dPfwP4TPfeE/f7kSRJ8+xgI+5XJ3kZ8DjwH+cpjyRJOoiDFfdHgHuAFcDUfuvD6DrucwbMJUmSZjDrVHlV/YeqegXwsao6Z7+fFVVlaUuSNAZ9vh3sd+YjiCRJOrQ+N2CRJEkLhMUtSVJDLG5JkhoyWHEnOTbJV5N8I8kjSf6gW78iyQNJtif5lHdlkySpvyFH3D8DLq2qVwGrgMuTXATcBHyoqlYCTwLXDphBkqRFZbDirpGfdItHdz8FXArc3q3fBKwZKoMkSYvNoMe4kxyVZCuwB7gX+A7wVFXt7d6yEzhrlm3XJZlKMjU9PT1kTEmSmjFocVfV81W1ClgGXAi8Yqa3zbLthqqarKrJiYmJIWNKktSMeTmrvKqeAu4HLgJOTrLvVqvLgCfmI4MkSYvBkGeVTyQ5uXt+HPA6YBtwH/CW7m1rgbuGyiBJ0mLT5/u4D9dSYFOSoxj9BeHWqvpMkm8Cn0zyb4GvAxsHzCBJ0qIyWHFX1f8Czp9h/WOMjndLkqQ58s5pkiQ1xOKWJKkhFrckSQ2xuCVJaojFLUlSQyxuSZIaYnFLktQQi1uSpIZY3JIkNWTIW54KWL7+s+OOMKMdN14x7giSpMPgiFuSpIZY3JIkNcTiliSpIRa3JEkNsbglSWqIxS1JUkMGK+4kL01yX5JtSR5Jcn23/tQk9ybZ3j2eMlQGSZIWmyFH3HuBf1lVrwAuAt6Z5DxgPbC5qlYCm7tlSZLUw2DFXVW7qurB7vkzwDbgLOAqYFP3tk3AmqEySJK02MzLMe4ky4HzgQeAM6tqF4zKHThjlm3WJZlKMjU9PT0fMSVJWvAGL+4kvwB8Grihqp7uu11VbaiqyaqanJiYGC6gJEkNGbS4kxzNqLQ/UVV3dKt3J1navb4U2DNkBkmSFpMhzyoPsBHYVlUf3O+lu4G13fO1wF1DZZAkabEZ8tvBLgbeDjyUZGu37v3AjcCtSa4FHgfeOmAGSZIWlcGKu6q+AmSWl1cPtV9JkhYz75wmSVJDLG5JkhpicUuS1BCLW5KkhljckiQ1xOKWJKkhFrckSQ2xuCVJaojFLUlSQyxuSZIaYnFLktQQi1uSpIZY3JIkNcTiliSpIRa3JEkNsbglSWrIkqE+OMlHgSuBPVX1ym7dqcCngOXADuDXq+rJoTJIkg7f8vWfHXcEzWDIEfefAJcfsG49sLmqVgKbu2VJktTTYMVdVV8GfnTA6quATd3zTcCaofYvSdJiNN/HuM+sql0A3eMZs70xybokU0mmpqen5y2gJEkL2YI9Oa2qNlTVZFVNTkxMjDuOJEkLwmAnp81id5KlVbUryVJgzzzvXwvcQj0ZZseNV4w7giQB8z/ivhtY2z1fC9w1z/uXJKlpgxV3kluAvwTOTbIzybXAjcBlSbYDl3XLkiSpp8GmyqvqmlleWj3UPiVJWuwW7MlpkiTphSxuSZIaYnFLktQQi1uSpIbM93Xcko4AXo8vDccRtyRJDbG4JUlqiMUtSVJDLG5JkhpicUuS1BCLW5Kkhng5mCSN2UK9fE4LkyNuSZIaYnFLktQQp8qPUE7Nzc1C/X15JzDpyOOIW5KkhoxlxJ3kcuCPgaOAm6vqxnHkkHRkWagzJ9JczPuIO8lRwH8C3gCcB1yT5Lz5ziFJUovGMVV+IfBoVT1WVc8BnwSuGkMOSZKaM46p8rOA7++3vBP4pQPflGQdsK5b/FmSh+ch2xBOB3447hAvQsv5W84OPfLnpnlKMneL/ne/gLWcHRrOn5v+XrO/bLYXxlHcmWFdvWBF1QZgA0CSqaqaHDrYEFrODm3nbzk7tJ2/5ezQdv6Ws0Pb+ecr+zimyncCL91veRnwxBhySJLUnHEU99eAlUlWJDkGuBq4eww5JElqzrxPlVfV3iS/C3ye0eVgH62qRw6x2Ybhkw2m5ezQdv6Ws0Pb+VvODm3nbzk7tJ1/XrKn6gWHlyVJ0gLlndMkSWqIxS1JUkMWdHEnuTzJt5M8mmT9uPPMRZKPJtnT4vXnSV6a5L4k25I8kuT6cWeaiyTHJvlqkm90+f9g3JnmKslRSb6e5DPjzjJXSXYkeSjJ1iRT484zF0lOTnJ7km91//2/ZtyZ+kpybvc73/fzdJIbxp2rryTv7v5/fTjJLUmOHXemuUhyfZf9kaF/7wv2GHd3a9T/DVzG6BKyrwHXVNU3xxqspySXAD8B/rSqXjnuPHORZCmwtKoeTHIisAVY09DvPsAJVfWTJEcDXwGur6q/GnO03pK8B5gETqqqK8edZy6S7AAmq6q5m2gk2QT8z6q6ubvq5fiqemrcueaq+/PzB8AvVdX3xp3nUJKcxej/0/Oq6v8kuRX4XFX9yXiT9ZPklYzuAnoh8BxwD/A7VbV9iP0t5BF307dGraovAz8ad47DUVW7qurB7vkzwDZGd7xrQo38pFs8uvtZmH9DnUGSZcAVwM3jznIkSXIScAmwEaCqnmuxtDurge+0UNr7WQIcl2QJcDxt3d/jFcBfVdWzVbUX+BLwT4ba2UIu7plujdpMeSwWSZYD5wMPjDfJ3HRTzVuBPcC9VdVS/j8Cfg/423EHOUwFfCHJlu7Wxa04B5gGPtYdprg5yQnjDnWYrgZuGXeIvqrqB8AfAo8Du4AfV9UXxptqTh4GLklyWpLjgTfy/99o7O/VQi7uXrdG1XCS/ALwaeCGqnp63Hnmoqqer6pVjO7Md2E3lbXgJbkS2FNVW8ad5UW4uKouYPQNgO/sDhu1YAlwAfDhqjof+CnQ1Lk1AN0U/5uA28adpa8kpzCaUV0B/CJwQpK3jTdVf1W1DbgJuJfRNPk3gL1D7W8hF7e3Rh2j7tjwp4FPVNUd485zuLqpzvuBy8ccpa+LgTd1x4k/CVya5L+ON9LcVNUT3eMe4E5Gh71asBPYud/szO2Mirw1bwAerKrd4w4yB68DvltV01X1c+AO4LVjzjQnVbWxqi6oqksYHSYd5Pg2LOzi9taoY9Kd3LUR2FZVHxx3nrlKMpHk5O75cYz+UPjWeFP1U1Xvq6plVbWc0X/zX6yqZkYeSU7oTmikm2Z+PaNpxAWvqv4a+H6Sc7tVq4EmTsg8wDU0NE3eeRy4KMnx3Z8/qxmdW9OMJGd0j2cDv8aA/w7G8e1gvRzmrVEXjCS3AL8MnJ5kJ/CBqto43lS9XQy8HXioO04M8P6q+twYM83FUmBTd2btS4Bbq6q5y6oadSZw5+jPXpYAf1ZV94w30pxcB3yiGyw8BrxjzHnmpDu+ehnw2+POMhdV9UCS24EHGU0xf532bn366SSnAT8H3llVTw61owV7OZgkSXqhhTxVLkmSDmBxS5LUEItbkqSGWNySJDXE4pYkqSEWtyRJDbG4JUlqyP8FYzCZav+ju0kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices1 = np.where(result!=labels)[0]       #(num)\n",
    "indices2 = np.where(result_dig!=labels)[0]\n",
    "indices3 = np.where((result!=labels)&(result_dig==labels))[0]\n",
    "\n",
    "cirtic_label_list = []\n",
    "label_list = []\n",
    "\n",
    "print(len(indices1),len(indices2),len(indices3))  #dig: 912 51 878\n",
    "#up: 954\n",
    "for i in range(len(indices3)):\n",
    "    idx = indices3[i]\n",
    "    img1 = global_data_dig.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "    img1 = Image.fromarray(img1)\n",
    "    label1 = result[idx]\n",
    "    label2 = result_dig[idx]\n",
    "    label = labels[idx]\n",
    "    cirtic_label_list.append(label)\n",
    "    \n",
    "    if label ==0:\n",
    "        label_list.append(label1)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "#     fig, axes = plt.subplots(1,1,figsize=(1,1))\n",
    "#     axes.imshow(img1,cmap=\"gray\")\n",
    "#     plt.pause(.1)\n",
    "#     print(\"Model:\",label1,\" Model2:\",label2,\" Label:\",label)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "data = np.uint8(cirtic_label_list)\n",
    "print(len(data))\n",
    "plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "plt.xticks(range(10))\n",
    "plt.ylabel('frequency')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "data = np.uint8(label_list)\n",
    "print(len(data))\n",
    "plt.hist(data ,density=0,align=\"mid\",bins=10,rwidth=1)\n",
    "plt.xticks(range(10))\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine train.csv and Dig augmented, add additional \"native writer label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"native_label,label,\" + pix_str\n",
    "\n",
    "origin_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "dig_aug_data = pd.read_csv(\"./dataset/Dig-Mnist-Augmented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 786)\n",
      "(60000, 786)\n",
      "(120000, 786)\n"
     ]
    }
   ],
   "source": [
    "train_csv = np.array(origin_data).astype(int)\n",
    "dig_aug_csv = np.array(dig_aug_data).astype(int)\n",
    "native_label0 = np.zeros((60000,1)).astype(int)\n",
    "native_label1 = np.ones((60000,1)).astype(int)\n",
    "\n",
    "train_csv = np.concatenate([native_label1,train_csv],axis=1)\n",
    "dig_aug_csv = np.concatenate([native_label0,dig_aug_csv],axis=1)\n",
    "\n",
    "print(np.shape(train_csv))\n",
    "print(np.shape(dig_aug_csv))\n",
    "new_csv = np.vstack([train_csv,dig_aug_csv])\n",
    "print(np.shape(new_csv))\n",
    "np.savetxt(\"./dataset/large_train.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment dig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = 0\n",
    "batch_size = 1024\n",
    "dataset = KMnistDataset(data_len=None,is_validate=False, validate_rate=vr)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "num_per_class = 6000  # 6000 * 10 =60000\n",
    "\n",
    "pix_str = \"pixel0\"\n",
    "for i in range(1,784):\n",
    "    pix_str = pix_str + \",pixel\" + str(i)\n",
    "numpy_header = \"label,\" + pix_str\n",
    "\n",
    "dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "# dig_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_list = np.empty((0,785))\n",
    "counter_list = np.zeros((10,)).astype(int)\n",
    "\n",
    "###Load original 10240 data\n",
    "origin_img = dig_data.iloc[:, 1:].values.astype(np.uint8).reshape((-1,784))  #value: 0~255\n",
    "origin_label = np.array(dig_data.iloc[:,0]).astype(int)\n",
    "\n",
    "for i in range(len(origin_img)):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    tmp_img = origin_img[i]    #(784,)\n",
    "    tmp_label = origin_label[i].reshape(-1) #(1,)\n",
    "    csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "    aug_list = np.vstack((aug_list,csv_arr))\n",
    "    counter_list[tmp_label] += 1\n",
    "\n",
    "print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "print(\"counter_list:\",counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Augment data by random select and affine\n",
    "keep_loop = True\n",
    "while keep_loop:\n",
    "    for idx,data in enumerate(loader):\n",
    "        img, label = data\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        img = img.cpu().numpy()\n",
    "        img = np.uint8(img*255).reshape(batch_size,-1)\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            tmp_img = img[i]    #(784,)\n",
    "            tmp_label = label[i].reshape(-1) #(1,)\n",
    "            if counter_list[tmp_label] >= num_per_class:\n",
    "                continue\n",
    "#             print(np.shape(tmp_label),np.shape(tmp_img))\n",
    "            csv_arr = np.concatenate([tmp_label,tmp_img])   #(785,)\n",
    "#             print(\"csv arr shape:\",np.shape(csv_arr))\n",
    "            \n",
    "            aug_list = np.vstack((aug_list,csv_arr))\n",
    "#             print(\"aug_list shape:\",np.shape(aug_list))\n",
    "            counter_list[tmp_label] += 1\n",
    "\n",
    "        print(\"shape of aug_list:\",np.shape(aug_list))\n",
    "        print(\"counter_list:\",counter_list)\n",
    "        if (counter_list>=num_per_class).all() == True:\n",
    "            print(\"Augment Finished\")\n",
    "            print(np.shape(aug_list))\n",
    "            print(counter_list)\n",
    "            np.savetxt(\"./dataset/Dig-Mnist-Augmented.csv\", aug_list, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "            keep_loop = False\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.random.random([1000,])\n",
    "global_data = pd.read_csv(\"./dataset/train_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fcba9ac25c0>],\n",
       " <a list of 1 Text xticklabel objects>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = global_data.iloc[:,0]\n",
    "print(np.shape(data))\n",
    "\n",
    "plt.hist(data ,density=0,label=True,bins=2,rwidth=0.3)\n",
    "plt.xticks(range(0,1))\n",
    "# print((label==5).sum().item())\n",
    "# plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data ,density=1,bins=10,label=True,rwidth=0.6)\n",
    "plt.ylabel('frequency')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
