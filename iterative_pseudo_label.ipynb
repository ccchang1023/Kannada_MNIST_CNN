{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub: SE_Net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Seq_Ex_Block(nn.Module):\n",
    "    def __init__(self, in_ch, r=16):\n",
    "        super(Seq_Ex_Block, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            GlobalAvgPool(),\n",
    "            nn.Linear(in_ch, in_ch//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_ch//r, in_ch),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "#         print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "        return x.mul(se_weight)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "class SE_Net3(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(SE_Net3,self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        #                dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels, out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=64,eps=1e-3,momentum=0.01)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,0)\n",
    "        self.bn2 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(64,1e-3,0.01)\n",
    "        self.c4 = nn.Conv2d(64,64,5,1,2)\n",
    "        self.bn4 = nn.BatchNorm2d(64,1e-3,0.01)        \n",
    "        \n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.c5 = nn.Conv2d(64,128,3,1,0)\n",
    "        self.bn5 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c6 = nn.Conv2d(128,128,3,1,0)\n",
    "        self.bn6 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c7 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.bn7 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        self.c8 = nn.Conv2d(128,128,5,1,2)\n",
    "        self.bn8 = nn.BatchNorm2d(128,1e-3,0.01)\n",
    "        \n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.c9 = nn.Conv2d(128,256,3,1,0)\n",
    "        self.bn9 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        self.c10 = nn.Conv2d(256,256,3,1,1)\n",
    "        self.bn10 = nn.BatchNorm2d(256,1e-3,0.01)\n",
    "        \n",
    "        self.se1 = Seq_Ex_Block(in_ch=256,r=16)\n",
    "        self.m3 = nn.MaxPool2d(2)\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*1*1,256)\n",
    "        self.bn11 = nn.BatchNorm1d(256,1e-3,0.01)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "        self.init_linear_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.bn1(F.leaky_relu(self.c1(x),0.05))\n",
    "        x = self.bn2(F.leaky_relu(self.c2(x),0.05))\n",
    "        x = self.bn3(F.leaky_relu(self.c3(x),0.05))\n",
    "        x = self.bn4(F.leaky_relu(self.c4(x),0.05))\n",
    "        x = self.d1(self.m1(x))\n",
    "        \n",
    "        x = self.bn5(F.leaky_relu(self.c5(x),0.05))\n",
    "        x = self.bn6(F.leaky_relu(self.c6(x),0.05))\n",
    "        x = self.bn7(F.leaky_relu(self.c7(x),0.05))\n",
    "        x = self.bn8(F.leaky_relu(self.c8(x),0.05))\n",
    "        x = self.d2(self.m2(x))\n",
    "        \n",
    "        x = self.bn9(F.leaky_relu(self.c9(x),0.05))\n",
    "        x = self.bn10(F.leaky_relu(self.c10(x),0.05))\n",
    "        x = self.se1(x)\n",
    "        x = self.d3(self.m3(x))\n",
    "        \n",
    "        x = x.view(-1, 256*1*1) #reshape\n",
    "        x = self.bn11(F.leaky_relu(self.fc1(x),0.05))\n",
    "        return self.out(x)\n",
    "    \n",
    "    def init_linear_weights(self):\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in')  #default mode: fan_in\n",
    "        nn.init.kaiming_normal_(self.out.weight, mode='fan_in')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/train.csv\") #will change during iteration\n",
    "global_data_dig = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "global_data_test = pd.read_csv(\"./dataset/test.csv\")\n",
    "# ensemble_root = \"Kmnist_saved_model/final_submit/adam2\" #will change during iteration\n",
    "\n",
    "trans = transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=20,translate=(0.25,0.25),scale=[0.65,1.1],shear=15),\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1  \n",
    "    ])\n",
    "\n",
    "trans_val = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n",
    "\n",
    "trans_test = transforms.Compose([\n",
    "        transforms.ToTensor(),  #Take Image as input and convert to tensor with value from 0 to1\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMnist Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMnistDataset(Dataset):\n",
    "    def __init__(self,data_len=None, is_validate=False,validate_rate=None,indices=None, data=None):\n",
    "        self.is_validate = is_validate\n",
    "        self.data = data\n",
    "        if data_len == None:\n",
    "            data_len = len(self.data)\n",
    "        \n",
    "        self.indices = indices\n",
    "        if self.is_validate:\n",
    "            self.len = int(data_len*validate_rate)\n",
    "            self.offset = int(data_len*(1-validate_rate))\n",
    "            self.transform = trans_val\n",
    "        else:\n",
    "            self.len = int(data_len*(1-validate_rate))\n",
    "            self.offset = 0\n",
    "            self.transform = trans\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.offset\n",
    "        idx = self.indices[idx]\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        label = self.data.iloc[idx, 0]  #(num,)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        label = torch.as_tensor(label, dtype=torch.uint8)    #value: 0~9, shape(1)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_len=None):\n",
    "        self.data = pd.read_csv(\"./dataset/test.csv\")\n",
    "        self.transform = trans_test\n",
    "        if data_len == None:\n",
    "            self.len = len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.iloc[idx, 1:].values.astype(np.uint8).reshape((28, 28))  #value: 0~255\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)     #value: 0~1, shape:(1,28,28)\n",
    "        return img, torch.Tensor([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Kfold dataset & Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_dataset_loader(k=5,val_rate=0.1,indices_len=None, batch_size=None,num_workers=None,data=None):\n",
    "    ###Return [list of train dataset_loader, list of val dataset_loader]\n",
    "    train_loader_list = []\n",
    "    val_loader_list = []\n",
    "    indices = np.arange(indices_len)\n",
    "    val_len = indices_len//k\n",
    "    idx = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        ind = np.concatenate([indices[:idx],indices[idx+val_len:],indices[idx:idx+val_len]])\n",
    "        idx += val_len\n",
    "        train_dataset = KMnistDataset(data_len=None,is_validate=False, validate_rate=val_rate,indices=ind,data=data)\n",
    "        val_dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=val_rate, indices=ind,data=data)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        \n",
    "        train_loader_list.append(train_loader)\n",
    "        val_loader_list.append(val_loader)\n",
    "        \n",
    "    return train_loader_list, val_loader_list\n",
    "\n",
    "def get_model(native_net=False):\n",
    "    if native_net == True:\n",
    "        model = convNet_native(in_channels=1)\n",
    "    else:\n",
    "        model = SE_Net3(in_channels=1)\n",
    "    if device == \"cuda\":\n",
    "        model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and generate from DIG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer_and_gen_dig_dataset(step=None,ensemble_root=None):\n",
    "    print(\"start inference & gernerate Dig dataset...\")\n",
    "    vr = 1\n",
    "    indices=np.arange(len(global_data_dig))\n",
    "    dataset = KMnistDataset(data_len=None,is_validate=True, validate_rate=vr,indices=indices,data=global_data_dig)\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "    ensemble_models = []\n",
    "    for file_name in os.listdir(ensemble_root):\n",
    "        if file_name.find(\"Fold\") == -1:\n",
    "            continue\n",
    "        model = SE_Net3(in_channels=1)\n",
    "        model.cuda()\n",
    "        model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "        model.eval()\n",
    "        ensemble_models.append(model)\n",
    "\n",
    "    model_num = len(ensemble_models)\n",
    "    print(\"model num:\",model_num)\n",
    "\n",
    "    ###Inference Dig dataset\n",
    "    result = np.empty((0,3))\n",
    "    # result = np.array([])\n",
    "    labels = np.array([])\n",
    "    data_num = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,data in enumerate(loader):\n",
    "            img, label = data\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            ###Average Ensemble\n",
    "            pred_list = torch.Tensor([]).to(device)\n",
    "            for i in range(model_num):\n",
    "                pred = ensemble_models[i](img) #(batch_num,10)\n",
    "                pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "            pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "    #         _,pred = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "            _,pred = torch.topk(pred,3)  #(batch_num,k), get topk result\n",
    "\n",
    "            result = np.concatenate([result,pred.cpu().numpy()],axis=0)\n",
    "            labels = np.concatenate([labels,label.cpu().numpy()],axis=0)\n",
    "            data_num += img.size(0)\n",
    "\n",
    "    print(\"Inference finished:\",data_num)\n",
    "    print(np.shape(result),np.shape(labels))\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    ###Collect top-1 corrected data from dig dataset\n",
    "    dig_idx_list = np.array([])\n",
    "    indices = np.where((result[:,0]==labels))[0]  #get top1 corrected index\n",
    "    dig_idx_list = np.hstack([dig_idx_list,indices])\n",
    "    dig_idx_list = np.unique(dig_idx_list).astype(int)\n",
    "    data_len = len(dig_idx_list)\n",
    "    npy_name = \"./dataset_final/iterative_trained/digidx_{}_s{}.npy\".format(data_len,step)\n",
    "    print(\"Top1 data num:\",data_len)\n",
    "    print(\"Save npy as:\",npy_name)\n",
    "    np.save(npy_name,dig_idx_list)\n",
    "    \n",
    "    ### Combine train.csv with top 1 corrected index from dig dataset\n",
    "    pix_str = \"pixel0\"\n",
    "    for i in range(1,784):\n",
    "        pix_str = pix_str + \",pixel\" + str(i)\n",
    "    numpy_header = \"label,\" + pix_str\n",
    "\n",
    "    top1_digidx = np.load(npy_name)\n",
    "    origin_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "    dig_data = pd.read_csv(\"./dataset/Dig-MNIST.csv\")\n",
    "\n",
    "    train_csv = np.array(origin_data).astype(int)\n",
    "    tmp_csv = np.array(dig_data).astype(int)\n",
    "    top1_dig_csv = []\n",
    "    for idx in top1_digidx:\n",
    "        top1_dig_csv.append(tmp_csv[idx])\n",
    "\n",
    "    top1_dig_csv = np.array(top1_dig_csv).astype(int)\n",
    "    print(\"shape of top1_dig_csv:\", np.shape(top1_dig_csv))\n",
    "    data_len = np.shape(top1_dig_csv)[0]\n",
    "    top1_digcsv_name = \"./dataset_final/iterative_trained/digtop1_{}_s{}.csv\".format(data_len,step)\n",
    "    print(\"Save dig csv as:\",top1_digcsv_name)\n",
    "    np.savetxt(top1_digcsv_name, top1_dig_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n",
    "    print(\"Dig csv finished\")\n",
    "    return top1_digcsv_name\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo labeling & combine with Dig csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_labeling(step=None,ensemble_root=None):\n",
    "    print(\"Start pseudo_labeling...\")\n",
    "    test_dataset = TestDataset(data_len=None)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "    ### Inference models\n",
    "    ensemble_models = []\n",
    "    for file_name in os.listdir(ensemble_root):\n",
    "        if file_name.find(\"Fold\") == -1:\n",
    "            continue\n",
    "        model = SE_Net3(in_channels=1)\n",
    "        model.cuda()\n",
    "        model.load_state_dict(torch.load(\"{}/{}\".format(ensemble_root,file_name)))\n",
    "        model.eval()\n",
    "        ensemble_models.append(model)\n",
    "\n",
    "    model_num = len(ensemble_models)\n",
    "    print(\"model num:\",model_num)\n",
    "\n",
    "    data_num = 0\n",
    "    psuedo_labels = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for idx,data in enumerate(test_loader):\n",
    "                img, label = data\n",
    "                img, label = img.to(device), label.to(device)\n",
    "\n",
    "                ###Average Ensemble\n",
    "                pred_list = torch.Tensor([]).to(device)\n",
    "                for i in range(model_num):\n",
    "                    pred = ensemble_models[i](img) #(batch_num,10)\n",
    "                    pred_list = torch.cat((pred_list,pred.unsqueeze(2)),dim=2) #pred_list: (batch_num,10,model_num)\n",
    "                pred = torch.mean(pred_list,dim=2)   #(batch,10)\n",
    "                _,pred = torch.max(pred.data, 1)   #(batch_num,)        \n",
    "                psuedo_labels = np.concatenate([psuedo_labels,pred.cpu().numpy()],axis=0)\n",
    "                data_num += img.size(0)\n",
    "    print(\"Inference complete:\",np.shape(psuedo_labels))\n",
    "    \n",
    "    ###Generate test_csv\n",
    "    pix_str = \"pixel0\"\n",
    "    for i in range(1,784):\n",
    "        pix_str = pix_str + \",pixel\" + str(i)\n",
    "    numpy_header = \"label,\" + pix_str\n",
    "\n",
    "    test_csv = np.array(pd.read_csv(\"./dataset/test.csv\")).astype(int)[:,1:]\n",
    "    pseudo_labels = psuedo_labels.reshape(-1,1).astype(int)\n",
    "    test_csv = np.concatenate([pseudo_labels,test_csv],axis=1)\n",
    "\n",
    "    print(\"test csv shape:\",np.shape(test_csv))\n",
    "    test_csv_name = \"./dataset_final/iterative_trained/test_pseu_s{}.csv\".format(step)\n",
    "    print(\"Save test csv as:\",test_csv_name)\n",
    "    np.savetxt(test_csv_name, test_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "    \n",
    "    print(\"pseudo label finished\")\n",
    "    return test_csv_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(step,dig_csv_name, test_pseu_csv_name):\n",
    "    print(\"start combining...\")\n",
    "    \n",
    "    pix_str = \"pixel0\"\n",
    "    for i in range(1,784):\n",
    "        pix_str = pix_str + \",pixel\" + str(i)\n",
    "    numpy_header = \"label,\" + pix_str    \n",
    "    \n",
    "    ### Combine train.csv with test_pseudo csv and digtop1 csv\n",
    "    train_csv = np.array(pd.read_csv(\"./dataset_final/train.csv\")).astype(int)\n",
    "    digtop1_csv = np.array(pd.read_csv(dig_csv_name)).astype(int)\n",
    "    test_csv = np.array(pd.read_csv(test_pseu_csv_name)).astype(int)\n",
    "    \n",
    "    print(\"shape of digtop1_csv:\",np.shape(digtop1_csv))\n",
    "    print(\"shape of test_csv:\",np.shape(test_csv))\n",
    "\n",
    "    ###Combine train, pseudo\n",
    "#     new_csv = np.vstack([train_csv,test_csv])\n",
    "#     for i in range(5):\n",
    "#         np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "#     print(np.shape(new_csv))\n",
    "#     np.savetxt(\"./dataset_final/train_pseu_65k_s1.csv\", new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n",
    "    ###Combine train, pseudo and digtop1 \n",
    "    new_csv = np.vstack([train_csv,test_csv,digtop1_csv])\n",
    "    for i in range(5):\n",
    "        np.random.shuffle(new_csv)  #Multi-dimensional arrays are only shuffled along the first axis:\n",
    "    print(\"shape of new csv:\",np.shape(new_csv))\n",
    "    data_len = np.shape(new_csv)[0]\n",
    "    new_csv_name = \"./dataset_final/iterative_trained/train_pseu_dig_{}_s{}.csv\".format(data_len,step)\n",
    "    print(\"Save new csv as:\",new_csv_name)\n",
    "    np.savetxt(new_csv_name, new_csv, delimiter=\",\",fmt=\"%d\",header=numpy_header,comments='')\n",
    "\n",
    "    print(\"===================All finished===================\")\n",
    "    print(\"\")\n",
    "    return new_csv_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10150\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10150_s3.npy\n",
      "shape of top1_dig_csv: (10150, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10150_s3.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s3.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10150, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75150, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75150_s3.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75150_s3.csv\n",
      "Set ensemble root to: Kmnist_saved_model/Step2\n",
      "Step: 3\n",
      "global_data len: 75150\n",
      "validation rate: 0.2\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.003536253901854088,Acc:10.8516%,lr:0.001\n",
      "Episode:2, Validation Loss:0.00481172683472167,Acc:17.8842%,lr:0.001\n",
      "Episode:3, Validation Loss:0.0130228161256629,Acc:9.8935%,lr:0.001\n",
      "Episode:4, Validation Loss:0.020063961559506314,Acc:9.8869%,lr:0.001\n",
      "Episode:5, Validation Loss:0.010783641812647491,Acc:12.4884%,lr:0.001\n",
      "Episode:6, Validation Loss:0.004417360677611249,Acc:34.0386%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0031602315560072484,Acc:63.1470%,lr:0.001\n",
      "Episode:8, Validation Loss:8.355716661025268e-05,Acc:97.6447%,lr:0.001\n",
      "Episode:9, Validation Loss:6.017538044088615e-05,Acc:98.4298%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00022001235745227582,Acc:95.3094%,lr:0.001\n",
      "Episode:11, Validation Loss:4.439172511567137e-05,Acc:98.8090%,lr:0.001\n",
      "Episode:12, Validation Loss:5.623552321158325e-05,Acc:98.4697%,lr:0.001\n",
      "Episode:13, Validation Loss:3.624198870288477e-05,Acc:98.8955%,lr:0.001\n",
      "Episode:14, Validation Loss:3.73491499367271e-05,Acc:99.0685%,lr:0.001\n",
      "Episode:15, Validation Loss:4.766908060965027e-05,Acc:98.8357%,lr:0.001\n",
      "Episode:16, Validation Loss:3.118376072226012e-05,Acc:99.0419%,lr:0.001\n",
      "Episode:17, Validation Loss:3.6562972777062705e-05,Acc:98.9687%,lr:0.001\n",
      "Episode:18, Validation Loss:2.8445343756509162e-05,Acc:99.1550%,lr:0.001\n",
      "Episode:19, Validation Loss:2.2886758354193198e-05,Acc:99.2814%,lr:0.001\n",
      "Episode:20, Validation Loss:2.7356498781157903e-05,Acc:99.2548%,lr:0.001\n",
      "Episode:21, Validation Loss:2.627979737228738e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:22, Validation Loss:2.5971305816225505e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:23, Validation Loss:2.316554084405333e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:24, Validation Loss:2.6170091228888022e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:25, Validation Loss:2.37569712345313e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:26, Validation Loss:2.8522460983541913e-05,Acc:99.1018%,lr:0.001\n",
      "Episode:27, Validation Loss:2.622193138221067e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:28, Validation Loss:2.5117575641441408e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:29, Validation Loss:2.0388336461818146e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:30, Validation Loss:2.987204579337787e-05,Acc:99.1550%,lr:0.001\n",
      "Episode:31, Validation Loss:2.8296185041457436e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:32, Validation Loss:1.637979313924522e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:33, Validation Loss:1.884298715108407e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:34, Validation Loss:2.2820692511891336e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:35, Validation Loss:1.691670583948959e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:36, Validation Loss:1.626375093510844e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:37, Validation Loss:2.171844739717241e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:38, Validation Loss:1.799182328739447e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:39, Validation Loss:1.7965420013565027e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:40, Validation Loss:1.5226082847821102e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:41, Validation Loss:1.681217820280128e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:42, Validation Loss:2.2202916691204903e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:43, Validation Loss:1.5174857844522376e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:44, Validation Loss:1.4831807126036424e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:45, Validation Loss:2.152878116922861e-05,Acc:99.2415%,lr:0.001\n",
      "Episode:46, Validation Loss:1.535818181530444e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:47, Validation Loss:1.9225045259117444e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:48, Validation Loss:8.050891845248496e-05,Acc:96.6534%,lr:0.001\n",
      "Episode:49, Validation Loss:1.9227766016088005e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:50, Validation Loss:1.4955612272519868e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:51, Validation Loss:1.8971906361465683e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:52, Validation Loss:1.8767338445631965e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:53, Validation Loss:2.1691219038463243e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:54, Validation Loss:1.9251043813492723e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:55, Validation Loss:1.745248738247517e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:56, Validation Loss:1.7659178162297247e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:57, Validation Loss:1.417850094636083e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:58, Validation Loss:1.6045776559554253e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:59, Validation Loss:1.3674010788490196e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:60, Validation Loss:2.0101949224324125e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:61, Validation Loss:1.2743129833035681e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:62, Validation Loss:1.9674979742673423e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:63, Validation Loss:1.4355804223421011e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:64, Validation Loss:1.4682013959099036e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:65, Validation Loss:1.954176058560233e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:66, Validation Loss:1.4919177359509135e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:67, Validation Loss:1.557459267809323e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:68, Validation Loss:1.6408147698073728e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:69, Validation Loss:1.65802795633287e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:70, Validation Loss:1.2227865549440155e-05,Acc:99.5808%,lr:0.001\n",
      "Episode:71, Validation Loss:1.557254311780452e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:72, Validation Loss:1.2322073537144991e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:73, Validation Loss:1.4165202614244666e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:74, Validation Loss:1.52395515196417e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:75, Validation Loss:4.607868292235725e-05,Acc:98.2236%,lr:0.001\n",
      "Episode:76, Validation Loss:1.1478062639792442e-05,Acc:99.6540%,lr:0.001\n",
      "Episode:77, Validation Loss:1.379107936835059e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:78, Validation Loss:1.4407891799966574e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:79, Validation Loss:1.2826703765187276e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:80, Validation Loss:1.2125173541491061e-05,Acc:99.5941%,lr:0.001\n",
      "Episode:81, Validation Loss:1.4720271798179139e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4253006938222799e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:83, Validation Loss:1.2478418524314465e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:84, Validation Loss:1.2241824017620768e-05,Acc:99.5941%,lr:0.001\n",
      "Episode:85, Validation Loss:1.6497372025630115e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:86, Validation Loss:1.7012780933769165e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:87, Validation Loss:1.3301747244443802e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:88, Validation Loss:1.3550469578700469e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:89, Validation Loss:1.7634676075376276e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:90, Validation Loss:1.6209923960293282e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:91, Validation Loss:1.220330032095541e-05,Acc:99.6274%,lr:0.001\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:92, Validation Loss:1.3746308947895379e-05,Acc:99.5941%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.268397389132224e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:94, Validation Loss:8.613484538595874e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.14837532171252e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:96, Validation Loss:8.30565536480226e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:97, Validation Loss:8.270970569875189e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:98, Validation Loss:8.231443145417088e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:99, Validation Loss:7.919874971736215e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.286185781344405e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:101, Validation Loss:7.953559539850283e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:102, Validation Loss:8.031813841727045e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:103, Validation Loss:8.10034437376463e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:104, Validation Loss:7.945320293857547e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:105, Validation Loss:7.958808190084582e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:106, Validation Loss:7.829860259276268e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:107, Validation Loss:7.967848215482668e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:108, Validation Loss:7.75572724568491e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:109, Validation Loss:7.501795143756522e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:110, Validation Loss:7.924067735776097e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:111, Validation Loss:7.456895016649328e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:112, Validation Loss:7.5553883894465005e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:113, Validation Loss:7.415815558301871e-06,Acc:99.7937%,lr:0.0001\n",
      "Episode:114, Validation Loss:7.519720067069956e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.313946118572118e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:116, Validation Loss:8.04414915655822e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:117, Validation Loss:8.445282786445108e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:118, Validation Loss:8.427540301354583e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.722005956648234e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:120, Validation Loss:7.965534044639099e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.218947405160386e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.057494194222663e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:123, Validation Loss:8.667523090319283e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:124, Validation Loss:8.045217358145964e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:125, Validation Loss:7.521348983094007e-06,Acc:99.7804%,lr:0.0001\n",
      "Episode:126, Validation Loss:8.194119789088003e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:127, Validation Loss:7.846032043749186e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:128, Validation Loss:7.559234541001236e-06,Acc:99.7738%,lr:0.0001\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:129, Validation Loss:7.583160856174812e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:130, Validation Loss:7.6079609601232345e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:131, Validation Loss:7.627682428229514e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:132, Validation Loss:7.623685548653305e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:133, Validation Loss:7.5863127913313636e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:134, Validation Loss:7.5796842128930696e-06,Acc:99.7804%,lr:1e-05\n",
      "Episode:135, Validation Loss:7.594675160275248e-06,Acc:99.7804%,lr:1e-05\n",
      "Episode:136, Validation Loss:7.6792480334818e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:137, Validation Loss:7.658868241765185e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:138, Validation Loss:7.571721126041013e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:139, Validation Loss:7.591903174366661e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:140, Validation Loss:7.689242339206591e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:141, Validation Loss:7.63346037702884e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:142, Validation Loss:7.60493564889757e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:143, Validation Loss:7.641098941648435e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:144, Validation Loss:7.605327789610374e-06,Acc:99.7738%,lr:1e-05\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:7.415815558301871e-06 Acc:0.9979374584165003==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.003142352066116181,Acc:22.1823%,lr:0.001\n",
      "Episode:2, Validation Loss:0.007892280154758029,Acc:10.3260%,lr:0.001\n",
      "Episode:3, Validation Loss:0.008549360045574541,Acc:10.4923%,lr:0.001\n",
      "Episode:4, Validation Loss:0.005904919103392742,Acc:23.4864%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0015638044573669028,Acc:63.8789%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0009456501075290317,Acc:77.4052%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00014626598524714182,Acc:96.4005%,lr:0.001\n",
      "Episode:8, Validation Loss:6.238592866652026e-05,Acc:98.0639%,lr:0.001\n",
      "Episode:9, Validation Loss:9.824326503538562e-05,Acc:97.3520%,lr:0.001\n",
      "Episode:10, Validation Loss:5.568868232146153e-05,Acc:98.5230%,lr:0.001\n",
      "Episode:11, Validation Loss:4.4532666132795916e-05,Acc:98.9421%,lr:0.001\n",
      "Episode:12, Validation Loss:4.1871716677944264e-05,Acc:98.9155%,lr:0.001\n",
      "Episode:13, Validation Loss:6.76119671570644e-05,Acc:98.1836%,lr:0.001\n",
      "Episode:14, Validation Loss:4.658491009287412e-05,Acc:98.8423%,lr:0.001\n",
      "Episode:15, Validation Loss:7.787175967307862e-05,Acc:98.2701%,lr:0.001\n",
      "Episode:16, Validation Loss:2.9061692602639983e-05,Acc:99.2415%,lr:0.001\n",
      "Episode:17, Validation Loss:3.6520358789724584e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:18, Validation Loss:5.661462776298453e-05,Acc:98.7226%,lr:0.001\n",
      "Episode:19, Validation Loss:2.447747013823477e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:20, Validation Loss:3.601905684707487e-05,Acc:99.0353%,lr:0.001\n",
      "Episode:21, Validation Loss:2.3888283039251727e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:22, Validation Loss:3.140051183070806e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:23, Validation Loss:2.2242509797760746e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:24, Validation Loss:2.17332425065641e-05,Acc:99.2947%,lr:0.001\n",
      "Episode:25, Validation Loss:3.2013300149462976e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:26, Validation Loss:3.105315050768281e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:27, Validation Loss:2.9615923534293057e-05,Acc:99.1683%,lr:0.001\n",
      "Episode:28, Validation Loss:2.277463684459567e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4446304354640695e-05,Acc:99.2415%,lr:0.001\n",
      "Episode:30, Validation Loss:2.38560787659245e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:31, Validation Loss:1.9842483994321116e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:32, Validation Loss:2.787712098893053e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:33, Validation Loss:2.1889322534629843e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:34, Validation Loss:2.2747801618027194e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:35, Validation Loss:2.5909725844324707e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:36, Validation Loss:2.4871859161638057e-05,Acc:99.1949%,lr:0.001\n",
      "Episode:37, Validation Loss:2.2140148307084642e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:38, Validation Loss:1.5975302271173148e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:39, Validation Loss:1.9952232149477333e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9186775244063564e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:41, Validation Loss:2.1480323581975536e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:42, Validation Loss:2.0319242736774528e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:43, Validation Loss:2.2718927829823173e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:44, Validation Loss:1.895001575757247e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:45, Validation Loss:1.5503164109385417e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:46, Validation Loss:0.00010974739175674048,Acc:95.4092%,lr:0.001\n",
      "Episode:47, Validation Loss:0.00012385930595838936,Acc:95.8816%,lr:0.001\n",
      "Episode:48, Validation Loss:1.8464460106428988e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:49, Validation Loss:2.0680081065811082e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8636540572344265e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:51, Validation Loss:2.0263637852912655e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:52, Validation Loss:1.8916199887227155e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:53, Validation Loss:1.6731119833029038e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:54, Validation Loss:2.1681834708748065e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:55, Validation Loss:1.8899002795913816e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:56, Validation Loss:2.0480136147248532e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6975948024424648e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:58, Validation Loss:1.6647695265685568e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:59, Validation Loss:1.483839900615171e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:60, Validation Loss:1.3265540081008782e-05,Acc:99.5941%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5580985002363433e-05,Acc:99.5675%,lr:0.001\n",
      "Episode:62, Validation Loss:3.034339787677694e-05,Acc:98.9421%,lr:0.001\n",
      "Episode:63, Validation Loss:7.267714077166851e-05,Acc:97.3520%,lr:0.001\n",
      "Episode:64, Validation Loss:1.2827922787742858e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:65, Validation Loss:1.8310106402177534e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:66, Validation Loss:1.6287514377268886e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:67, Validation Loss:1.6304952137702637e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:68, Validation Loss:1.7356937311227848e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:69, Validation Loss:1.4788346273387105e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:70, Validation Loss:2.6768505764122574e-05,Acc:99.1949%,lr:0.001\n",
      "Episode:71, Validation Loss:2.0180898362241503e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6035833684151283e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5808980638088184e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:74, Validation Loss:1.4443718936698325e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:75, Validation Loss:3.7011771982737726e-05,Acc:98.8423%,lr:0.001\n",
      "Episode:76, Validation Loss:1.460520540694356e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:77, Validation Loss:1.663524203289967e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:78, Validation Loss:1.1248206713559703e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:79, Validation Loss:2.139203857038113e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:80, Validation Loss:1.6510039158983384e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:81, Validation Loss:1.543069107139499e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4732955599913815e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:83, Validation Loss:6.994353365636395e-05,Acc:97.6381%,lr:0.001\n",
      "Episode:84, Validation Loss:1.5404679132743193e-05,Acc:99.5675%,lr:0.001\n",
      "Episode:85, Validation Loss:1.5055485527047855e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:86, Validation Loss:1.5184684444023067e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:87, Validation Loss:1.640040083544816e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:88, Validation Loss:2.056126813054164e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:89, Validation Loss:1.3750177855818413e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:90, Validation Loss:1.269095682328987e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:91, Validation Loss:1.4820216234131448e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:92, Validation Loss:2.0948418491059592e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:93, Validation Loss:1.3921224634229384e-05,Acc:99.5675%,lr:0.001\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:94, Validation Loss:1.9869245793261452e-05,Acc:99.4544%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.133393836458643e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0677600987082074e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0341298329586278e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0658019759549115e-05,Acc:99.7671%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0556261180958903e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0580068524785622e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0612621563855442e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0607795014045512e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0165775471124662e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0743383652792719e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.94091600065658e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.1217560190323267e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.86500224315438e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.940743151400301e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.945824405231717e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.890857319324634e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.0551500592085812e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.0003287441835195e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.0005517813785426e-05,Acc:99.7605%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.035420771214816e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.0002012868335622e-05,Acc:99.7405%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0514842669763965e-05,Acc:99.7405%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0227375581404485e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.896913890343306e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.507468900954969e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.0053504658683252e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.0173658004460617e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.90648126243276e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.0413611902596946e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.1272065456726117e-05,Acc:99.7538%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.0695803386276353e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.0377389000244166e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.0651057395224007e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.0994667062165335e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.0563577547005153e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0408073538543777e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.0446109359740655e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.0765650286695517e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0537760733755048e-05,Acc:99.7405%,lr:0.0001\n",
      "Episode:134, Validation Loss:9.913963320865205e-06,Acc:99.7472%,lr:0.0001\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:135, Validation Loss:1.0595226961517049e-05,Acc:99.6939%,lr:1e-05\n",
      "Episode:136, Validation Loss:1.0184923537615848e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:137, Validation Loss:1.0056174264171086e-05,Acc:99.7405%,lr:1e-05\n",
      "Episode:138, Validation Loss:1.0063330824434241e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:139, Validation Loss:1.0032183785023724e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:140, Validation Loss:9.954440409313895e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:141, Validation Loss:9.97430752437371e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:142, Validation Loss:9.991583728534494e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:143, Validation Loss:9.908199066163617e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:144, Validation Loss:9.829144558050755e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:145, Validation Loss:9.881852954348484e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:146, Validation Loss:9.80922576481215e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:147, Validation Loss:9.837293010936209e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:148, Validation Loss:9.840797150850851e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:149, Validation Loss:9.825310923273137e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:150, Validation Loss:9.866723098624213e-06,Acc:99.7605%,lr:1e-05\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:1.0658019759549115e-05 Acc:0.9976713240186295==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0024214669060722955,Acc:22.6480%,lr:0.001\n",
      "Episode:2, Validation Loss:0.004760767250797071,Acc:24.6574%,lr:0.001\n",
      "Episode:3, Validation Loss:0.013062927807003993,Acc:9.7006%,lr:0.001\n",
      "Episode:4, Validation Loss:0.010939705697045037,Acc:12.6081%,lr:0.001\n",
      "Episode:5, Validation Loss:0.004162948732763152,Acc:41.9428%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0025812655548532247,Acc:50.2861%,lr:0.001\n",
      "Episode:7, Validation Loss:0.003453569767559201,Acc:50.3992%,lr:0.001\n",
      "Episode:8, Validation Loss:0.003577563037732721,Acc:56.5269%,lr:0.001\n",
      "Episode:9, Validation Loss:0.00039278752829183044,Acc:90.7917%,lr:0.001\n",
      "Episode:10, Validation Loss:9.291631901414888e-05,Acc:97.6580%,lr:0.001\n",
      "Episode:11, Validation Loss:0.000248619276566737,Acc:93.8989%,lr:0.001\n",
      "Episode:12, Validation Loss:0.0001215878058614052,Acc:96.8862%,lr:0.001\n",
      "Episode:13, Validation Loss:0.0015127799468126126,Acc:76.3872%,lr:0.001\n",
      "Episode:14, Validation Loss:4.543922680441888e-05,Acc:98.5363%,lr:0.001\n",
      "Episode:15, Validation Loss:3.487258847165885e-05,Acc:98.8889%,lr:0.001\n",
      "Episode:16, Validation Loss:3.8802876934676824e-05,Acc:99.0020%,lr:0.001\n",
      "Episode:17, Validation Loss:4.2967083018102094e-05,Acc:98.6893%,lr:0.001\n",
      "Episode:18, Validation Loss:2.613108715442761e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:19, Validation Loss:4.753864215995499e-05,Acc:98.5895%,lr:0.001\n",
      "Episode:20, Validation Loss:2.8379416280362263e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:21, Validation Loss:2.5678408987131106e-05,Acc:99.2282%,lr:0.001\n",
      "Episode:22, Validation Loss:2.9408900750056158e-05,Acc:99.0951%,lr:0.001\n",
      "Episode:23, Validation Loss:3.0378360643298804e-05,Acc:99.1949%,lr:0.001\n",
      "Episode:24, Validation Loss:3.1349222291650095e-05,Acc:99.1018%,lr:0.001\n",
      "Episode:25, Validation Loss:3.171655363685198e-05,Acc:99.0752%,lr:0.001\n",
      "Episode:26, Validation Loss:3.955763772734783e-05,Acc:98.6361%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6041927920308656e-05,Acc:99.2149%,lr:0.001\n",
      "Episode:28, Validation Loss:2.1406396522037364e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:29, Validation Loss:2.891058492624831e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:30, Validation Loss:2.3975798764767365e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:31, Validation Loss:2.2729165314220225e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:32, Validation Loss:3.640272159498688e-05,Acc:98.9355%,lr:0.001\n",
      "Episode:33, Validation Loss:2.027816304606116e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:34, Validation Loss:1.7272493339138116e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:35, Validation Loss:2.05154109347168e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:36, Validation Loss:2.260454053571045e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:37, Validation Loss:2.9578073048147453e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:38, Validation Loss:3.00254295403491e-05,Acc:99.0419%,lr:0.001\n",
      "Episode:39, Validation Loss:2.2852005770384114e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9092874753915383e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:41, Validation Loss:3.7069964958125564e-05,Acc:98.9554%,lr:0.001\n",
      "Episode:42, Validation Loss:2.1557058706502872e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:43, Validation Loss:2.2103999018252728e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:44, Validation Loss:2.0992147555935408e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:45, Validation Loss:1.7645193607170265e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:46, Validation Loss:2.3067873392653164e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:47, Validation Loss:1.81806367944061e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:48, Validation Loss:1.997823798465118e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7114773179520312e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:50, Validation Loss:1.9446480895330013e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:51, Validation Loss:2.232618624975264e-05,Acc:99.2947%,lr:0.001\n",
      "Episode:52, Validation Loss:2.0084470226686554e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:53, Validation Loss:1.6052258174298846e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:54, Validation Loss:2.0112049674797438e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:55, Validation Loss:1.6707945082160684e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:56, Validation Loss:1.6766035320833374e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6469743253981677e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:58, Validation Loss:1.4519320859146848e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:59, Validation Loss:1.8464827926176355e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:60, Validation Loss:1.4068625144863716e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5049108229106613e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:62, Validation Loss:1.9358112727721295e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:63, Validation Loss:1.5470544675629058e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:64, Validation Loss:1.530039926008114e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:65, Validation Loss:1.7540281358424695e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:66, Validation Loss:1.5284280005795356e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:67, Validation Loss:1.5717767010469558e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:68, Validation Loss:2.0742522836405676e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:69, Validation Loss:1.889315389805608e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:70, Validation Loss:1.2195810671903178e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:71, Validation Loss:1.3048678366386802e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:72, Validation Loss:1.3346354466573604e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:73, Validation Loss:1.3488142163116616e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:74, Validation Loss:1.927416899296655e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:75, Validation Loss:1.4585460655772916e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:76, Validation Loss:1.6722723771027937e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:77, Validation Loss:1.4465312731866827e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:78, Validation Loss:1.9440331377946608e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:79, Validation Loss:1.559848254280077e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:80, Validation Loss:1.6762496418978322e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:81, Validation Loss:1.2858270147613343e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4259901203844679e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:83, Validation Loss:1.5572866509189545e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:84, Validation Loss:1.560221900215406e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:85, Validation Loss:2.863144889939886e-05,Acc:98.9820%,lr:0.001\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:86, Validation Loss:4.2422911175790026e-05,Acc:98.6693%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.1754114830188567e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.1166701054898247e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.1131204342493119e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.094098842974829e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0931699555949695e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.0551751082538765e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.001498774710252e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0329403394631203e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.046607978468487e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0178953871448201e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0017461483617742e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0270270204799856e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.992148222789635e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0005329194629264e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0071625822754757e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0315831614309998e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.751490751654406e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.890434723186318e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.0484275615669376e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.585056033825683e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0248658563929324e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.054474946386562e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.0639169121425071e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.974991005466766e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.0349658204469376e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.863637573645262e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.0549146322631392e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.0128270497598889e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.85791294507717e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0225618368414981e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0124818376666374e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.805598920204999e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.859807068061924e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.0215878797693801e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:121, Validation Loss:9.742847793126455e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.435800933393732e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:123, Validation Loss:9.847627407409554e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.704471354484954e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.0123003413002251e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:126, Validation Loss:9.815651596246842e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:127, Validation Loss:9.639920816767319e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.628651039061432e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:129, Validation Loss:9.428293686496443e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.620350371012669e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.0685712075528904e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.010291987233216e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0376540802701742e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:134, Validation Loss:9.834927123186197e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:135, Validation Loss:9.761832490890563e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.023452662685e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:137, Validation Loss:1.0428092946222204e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:138, Validation Loss:1.0205820297013104e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:139, Validation Loss:9.718644064036276e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:140, Validation Loss:9.667474580699416e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:141, Validation Loss:9.981981811379482e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:142, Validation Loss:9.940803969304956e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:143, Validation Loss:9.668147946129778e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:144, Validation Loss:9.619295801558419e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:145, Validation Loss:9.236205245305599e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:146, Validation Loss:8.980867980235192e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:147, Validation Loss:9.885982499369286e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:148, Validation Loss:9.340752276802016e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:149, Validation Loss:9.548372923038994e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:150, Validation Loss:1.0106798524132428e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:151, Validation Loss:9.367599555415784e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:152, Validation Loss:9.568047282829415e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:153, Validation Loss:9.589944609843012e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:154, Validation Loss:9.956625516384502e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:155, Validation Loss:1.0163669089624982e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:156, Validation Loss:8.962737366616608e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:157, Validation Loss:9.52420860320746e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:158, Validation Loss:9.882556682257992e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:159, Validation Loss:9.55991667564599e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:160, Validation Loss:9.479723326708187e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:161, Validation Loss:9.173266428534538e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:162, Validation Loss:9.319447513845708e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:163, Validation Loss:9.714363419208539e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:164, Validation Loss:9.874389825992322e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:165, Validation Loss:1.0046140580169772e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:166, Validation Loss:1.0106165838227697e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:167, Validation Loss:9.176791264506396e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:168, Validation Loss:9.509899510356957e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:169, Validation Loss:9.796847214430313e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:170, Validation Loss:9.883011468820626e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:171, Validation Loss:9.305429962759246e-06,Acc:99.6939%,lr:0.0001\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:172, Validation Loss:9.361440402592569e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:173, Validation Loss:9.256486854678936e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:174, Validation Loss:9.094956854552884e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:175, Validation Loss:9.20086424904352e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:176, Validation Loss:9.173958600112698e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:177, Validation Loss:9.191856537998239e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:178, Validation Loss:9.301766791614548e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:179, Validation Loss:9.355650060944611e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:180, Validation Loss:9.353648832765564e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:181, Validation Loss:9.310654044171135e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:182, Validation Loss:9.265158998365411e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:183, Validation Loss:9.292966258016254e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:184, Validation Loss:9.261961054758319e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:185, Validation Loss:9.312940710636273e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:186, Validation Loss:9.342149167717574e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:187, Validation Loss:9.364140866273496e-06,Acc:99.7139%,lr:1e-05\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:9.55991667564599e-06 Acc:0.9973386560212908==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.005162910200006075,Acc:9.8603%,lr:0.001\n",
      "Episode:2, Validation Loss:0.015989955171139655,Acc:9.8603%,lr:0.001\n",
      "Episode:3, Validation Loss:0.01743945656660312,Acc:9.8603%,lr:0.001\n",
      "Episode:4, Validation Loss:0.008095115419236803,Acc:18.0971%,lr:0.001\n",
      "Episode:5, Validation Loss:0.003169562859449558,Acc:37.0126%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0012680997153718078,Acc:75.6554%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0004903830672135293,Acc:89.1484%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0002327473825481996,Acc:93.0672%,lr:0.001\n",
      "Episode:9, Validation Loss:7.355571343394335e-05,Acc:98.1238%,lr:0.001\n",
      "Episode:10, Validation Loss:6.292981981081084e-05,Acc:98.4232%,lr:0.001\n",
      "Episode:11, Validation Loss:3.372684510886986e-05,Acc:99.0951%,lr:0.001\n",
      "Episode:12, Validation Loss:5.555987353136122e-05,Acc:98.5695%,lr:0.001\n",
      "Episode:13, Validation Loss:3.4833174689622695e-05,Acc:99.0153%,lr:0.001\n",
      "Episode:14, Validation Loss:3.6140210450647356e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:15, Validation Loss:4.7643387508011625e-05,Acc:98.8157%,lr:0.001\n",
      "Episode:16, Validation Loss:3.124563815351018e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:17, Validation Loss:3.073774179021121e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:18, Validation Loss:4.090306312539779e-05,Acc:98.8490%,lr:0.001\n",
      "Episode:19, Validation Loss:3.9281673402248506e-05,Acc:99.1018%,lr:0.001\n",
      "Episode:20, Validation Loss:3.092709131890825e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:21, Validation Loss:2.9495053355168758e-05,Acc:99.0818%,lr:0.001\n",
      "Episode:22, Validation Loss:2.4596590571060865e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:23, Validation Loss:2.8104574809313138e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:24, Validation Loss:3.2811181487159897e-05,Acc:99.0020%,lr:0.001\n",
      "Episode:25, Validation Loss:2.757000816826097e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:26, Validation Loss:3.277594180243537e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:27, Validation Loss:1.9779049370658452e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:28, Validation Loss:2.5578626231380247e-05,Acc:99.2282%,lr:0.001\n",
      "Episode:29, Validation Loss:2.1554724854266573e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:30, Validation Loss:2.6533216751085784e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:31, Validation Loss:2.7789210830025094e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:32, Validation Loss:2.5869229361067908e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:33, Validation Loss:2.3539134202722065e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:34, Validation Loss:3.1369963582761275e-05,Acc:99.1683%,lr:0.001\n",
      "Episode:35, Validation Loss:1.8390430743525367e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:36, Validation Loss:2.477881315840298e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:37, Validation Loss:1.857152846297937e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:38, Validation Loss:1.6600314555014282e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:39, Validation Loss:1.561506555297338e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:40, Validation Loss:2.367924688184412e-05,Acc:99.2681%,lr:0.001\n",
      "Episode:41, Validation Loss:2.070718741692548e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:42, Validation Loss:2.3096713751148005e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:43, Validation Loss:2.0552479556042276e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:44, Validation Loss:1.9069678687347387e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:45, Validation Loss:1.8639187622847592e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:46, Validation Loss:1.9921176817146683e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:47, Validation Loss:1.8007476880392944e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:48, Validation Loss:2.7254139676105158e-05,Acc:99.1816%,lr:0.001\n",
      "Episode:49, Validation Loss:2.518083704406233e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:50, Validation Loss:2.3222994462091846e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:51, Validation Loss:2.3539839169916437e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:52, Validation Loss:1.9913788665524737e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:53, Validation Loss:1.7143965959648093e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:54, Validation Loss:3.0496547584801773e-05,Acc:99.0885%,lr:0.001\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:55, Validation Loss:1.5968295385539332e-05,Acc:99.5409%,lr:0.0001\n",
      "Episode:56, Validation Loss:1.3474664351570154e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:57, Validation Loss:1.27389810790995e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:58, Validation Loss:1.3067638557292745e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:59, Validation Loss:1.2055151839941959e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:60, Validation Loss:1.1837631228540392e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:61, Validation Loss:1.154498653195139e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.1635202070523403e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.1072013897701097e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.137489298047499e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.070636782500241e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.0491803124874176e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.1171992274567594e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.146588254539037e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.2380964601696212e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.1563174028745193e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.1081117405466294e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.1247861262904115e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.1295817156662483e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.1729093235052988e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.1659947491027241e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.1045922427943207e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.1175900824115186e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.2033892341865276e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.0925920181972775e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.1233849164671052e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.073462540979038e-05,Acc:99.7006%,lr:0.0001\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:82, Validation Loss:1.0914157323801985e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:83, Validation Loss:1.0733082995849773e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:84, Validation Loss:1.0659451691244177e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:85, Validation Loss:1.0619762354218713e-05,Acc:99.6939%,lr:1e-05\n",
      "Episode:86, Validation Loss:1.0609838594784755e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:87, Validation Loss:1.0499809245893104e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:88, Validation Loss:1.053554575991924e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:89, Validation Loss:1.0586885459032046e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:90, Validation Loss:1.0523197339650638e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:91, Validation Loss:1.0594749186220205e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:92, Validation Loss:1.058838186452211e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:93, Validation Loss:1.0622815146586218e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:94, Validation Loss:1.0623175065892582e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:95, Validation Loss:1.0546665893977908e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:96, Validation Loss:1.0566762602049672e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:97, Validation Loss:1.0540798220954494e-05,Acc:99.6939%,lr:1e-05\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:1.0566762602049672e-05 Acc:0.9970059880239521==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.00349952119711789,Acc:19.4212%,lr:0.001\n",
      "Episode:2, Validation Loss:0.007321131744943138,Acc:18.9488%,lr:0.001\n",
      "Episode:3, Validation Loss:0.016157591128777602,Acc:10.3593%,lr:0.001\n",
      "Episode:4, Validation Loss:0.018336963336307528,Acc:10.3925%,lr:0.001\n",
      "Episode:5, Validation Loss:0.013599534456680714,Acc:12.0758%,lr:0.001\n",
      "Episode:6, Validation Loss:0.006307162369241416,Acc:36.7931%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0004387756049910626,Acc:90.2595%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0007557623162716924,Acc:85.2428%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0007859243683551679,Acc:86.0279%,lr:0.001\n",
      "Episode:10, Validation Loss:3.7270497359677464e-05,Acc:98.9088%,lr:0.001\n",
      "Episode:11, Validation Loss:4.387194648910505e-05,Acc:98.8889%,lr:0.001\n",
      "Episode:12, Validation Loss:5.0696518695996904e-05,Acc:98.5363%,lr:0.001\n",
      "Episode:13, Validation Loss:4.094236171590592e-05,Acc:98.6228%,lr:0.001\n",
      "Episode:14, Validation Loss:2.5161659792412622e-05,Acc:99.2681%,lr:0.001\n",
      "Episode:15, Validation Loss:3.9519727755528806e-05,Acc:98.9288%,lr:0.001\n",
      "Episode:16, Validation Loss:3.89721834473188e-05,Acc:98.9554%,lr:0.001\n",
      "Episode:17, Validation Loss:3.915950581580103e-05,Acc:98.9687%,lr:0.001\n",
      "Episode:18, Validation Loss:3.3655620402522035e-05,Acc:99.0619%,lr:0.001\n",
      "Episode:19, Validation Loss:2.94987656949404e-05,Acc:99.1550%,lr:0.001\n",
      "Episode:20, Validation Loss:2.0956733039098823e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:21, Validation Loss:2.307411796318557e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:22, Validation Loss:2.2207592884778818e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:23, Validation Loss:3.592534187787069e-05,Acc:99.0419%,lr:0.001\n",
      "Episode:24, Validation Loss:2.4183928416279736e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:25, Validation Loss:2.2972203265684727e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:26, Validation Loss:2.6934895495910765e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:27, Validation Loss:2.0362776490355917e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:28, Validation Loss:2.106458459270056e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:29, Validation Loss:2.410010281635457e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:30, Validation Loss:1.9329679908053683e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:31, Validation Loss:1.8237641667395692e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:32, Validation Loss:2.1348924500618627e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:33, Validation Loss:1.9510959864346803e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:34, Validation Loss:2.026207582728909e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:35, Validation Loss:1.6089727208563588e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:36, Validation Loss:1.81342139270055e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:37, Validation Loss:1.5172479285084637e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:38, Validation Loss:3.192575310102242e-05,Acc:98.8357%,lr:0.001\n",
      "Episode:39, Validation Loss:2.6929121853626337e-05,Acc:99.1550%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9192015745999887e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:41, Validation Loss:1.957554435846969e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:42, Validation Loss:1.7153218615346562e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:43, Validation Loss:2.442182900529065e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:44, Validation Loss:1.8432988064563123e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:45, Validation Loss:2.1963429724622866e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:46, Validation Loss:2.184899837393326e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:47, Validation Loss:1.482845442673205e-05,Acc:99.5675%,lr:0.001\n",
      "Episode:48, Validation Loss:3.1047521861727364e-05,Acc:99.0220%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7398591348511017e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:50, Validation Loss:1.5305029940918455e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:51, Validation Loss:1.8994476279356603e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:52, Validation Loss:2.0672592501133105e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:53, Validation Loss:1.445315516146714e-05,Acc:99.5808%,lr:0.001\n",
      "Episode:54, Validation Loss:1.872696929889485e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:55, Validation Loss:1.52647330289978e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:56, Validation Loss:1.5343852800949763e-05,Acc:99.4677%,lr:0.001\n",
      "Episode:57, Validation Loss:2.3509422719914836e-05,Acc:99.2681%,lr:0.001\n",
      "Episode:58, Validation Loss:1.3399926179689086e-05,Acc:99.5808%,lr:0.001\n",
      "Episode:59, Validation Loss:1.1897007736463549e-05,Acc:99.6740%,lr:0.001\n",
      "Episode:60, Validation Loss:1.579587894949767e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:61, Validation Loss:1.485733109627338e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:62, Validation Loss:1.6588557583446592e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:63, Validation Loss:1.2618085308742777e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:64, Validation Loss:1.4251769202465782e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:65, Validation Loss:1.680767157437876e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:66, Validation Loss:1.2984315735236534e-05,Acc:99.5675%,lr:0.001\n",
      "Episode:67, Validation Loss:1.3562847710823665e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:68, Validation Loss:1.7131465355198304e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:69, Validation Loss:6.798762909904449e-05,Acc:97.9175%,lr:0.001\n",
      "Episode:70, Validation Loss:1.6125413252713674e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:71, Validation Loss:1.9298089886268852e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6726851890871148e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:73, Validation Loss:1.6381469086129824e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:74, Validation Loss:1.415366394270561e-05,Acc:99.5742%,lr:0.001\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:75, Validation Loss:1.5970033482559825e-05,Acc:99.5210%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.1507354345834421e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.1026053097661702e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.1208921383399609e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.0557643510277321e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.0764099879367544e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.0383124968268756e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.0147734550748043e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:83, Validation Loss:9.588059037923813e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:84, Validation Loss:9.16544942238572e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.262491979884729e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:86, Validation Loss:9.417650739074308e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.46060314412642e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.106892809836926e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:89, Validation Loss:9.167809284113086e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:90, Validation Loss:9.065165561800469e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:91, Validation Loss:9.30963550692428e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.576339492758988e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.251960490644969e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.266074489075902e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:95, Validation Loss:9.1552985640006e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.532473177084586e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.337507968449981e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.190693717011197e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.236075678073162e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.118993992775341e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.82490166493816e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.315968128646205e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.501533005299842e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.747211408075775e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.042278510913084e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.199652476304385e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.37412601678136e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.415687123190857e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.330547230686257e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.801026725230697e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:111, Validation Loss:8.875975575538492e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.339790808623106e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:113, Validation Loss:8.850207977388512e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.137310561087635e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.576701618904521e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:116, Validation Loss:8.635763549856242e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.134962519039651e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.012858600852018e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.864020488794375e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.82083172113675e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.623977393130025e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.465302116668232e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:123, Validation Loss:8.606427105630706e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:124, Validation Loss:8.975210582870922e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:125, Validation Loss:8.371925534195925e-06,Acc:99.7804%,lr:0.0001\n",
      "Episode:126, Validation Loss:8.990694967012403e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:127, Validation Loss:8.862514045096919e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:128, Validation Loss:8.598363574740496e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:129, Validation Loss:8.760528553448275e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.164994418948235e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:131, Validation Loss:9.25499887632594e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:132, Validation Loss:9.041625593682963e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:133, Validation Loss:9.432935118129947e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:134, Validation Loss:9.285016462494355e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:135, Validation Loss:9.38222471237956e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:136, Validation Loss:8.824218779613951e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:137, Validation Loss:8.809783310689532e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:138, Validation Loss:9.266437940344126e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:139, Validation Loss:9.174905460221286e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:140, Validation Loss:9.439184366962708e-06,Acc:99.7405%,lr:0.0001\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:141, Validation Loss:8.961745876761888e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:142, Validation Loss:8.938776227538379e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:143, Validation Loss:9.02468494138992e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:144, Validation Loss:9.05115922624202e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:145, Validation Loss:9.110498695038829e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:146, Validation Loss:9.121648974701792e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:147, Validation Loss:9.212456457688661e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:148, Validation Loss:9.152039461685511e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:149, Validation Loss:9.130884218447936e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:150, Validation Loss:9.084022675187923e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:151, Validation Loss:9.074197593811188e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:152, Validation Loss:9.032274724659091e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:153, Validation Loss:9.025103076102728e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:154, Validation Loss:9.017578634127965e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:155, Validation Loss:8.936951489014897e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:156, Validation Loss:8.969648440039443e-06,Acc:99.7472%,lr:1e-05\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:8.371925534195925e-06 Acc:0.9978043912175649==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10153\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10153_s4.npy\n",
      "shape of top1_dig_csv: (10153, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10153_s4.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s4.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10153, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75153, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75153_s4.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75153_s4.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step3\n",
      "Step: 4\n",
      "global_data len: 75153\n",
      "validation rate: 0.199992016286775\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.007026601741889756,Acc:10.0798%,lr:0.001\n",
      "Episode:2, Validation Loss:0.010029987264139527,Acc:10.2063%,lr:0.001\n",
      "Episode:3, Validation Loss:0.006923124874264735,Acc:21.1910%,lr:0.001\n",
      "Episode:4, Validation Loss:0.007983807191322108,Acc:20.1065%,lr:0.001\n",
      "Episode:5, Validation Loss:0.006509681455468782,Acc:27.3919%,lr:0.001\n",
      "Episode:6, Validation Loss:0.004779748510537113,Acc:39.5343%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0038713664748394245,Acc:41.2043%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0002663431023647209,Acc:93.4265%,lr:0.001\n",
      "Episode:9, Validation Loss:9.463625481068414e-05,Acc:97.6713%,lr:0.001\n",
      "Episode:10, Validation Loss:4.483717056864988e-05,Acc:98.8423%,lr:0.001\n",
      "Episode:11, Validation Loss:6.119826398368526e-05,Acc:98.4564%,lr:0.001\n",
      "Episode:12, Validation Loss:5.235986292104442e-05,Acc:98.5695%,lr:0.001\n",
      "Episode:13, Validation Loss:5.488825871479646e-05,Acc:98.5629%,lr:0.001\n",
      "Episode:14, Validation Loss:3.135673725309565e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:15, Validation Loss:6.966842456174864e-05,Acc:98.3234%,lr:0.001\n",
      "Episode:16, Validation Loss:3.718226102099606e-05,Acc:98.9155%,lr:0.001\n",
      "Episode:17, Validation Loss:4.279236591167634e-05,Acc:98.6693%,lr:0.001\n",
      "Episode:18, Validation Loss:4.033069581745152e-05,Acc:98.9754%,lr:0.001\n",
      "Episode:19, Validation Loss:3.14636649817962e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:20, Validation Loss:3.501854183837642e-05,Acc:98.9687%,lr:0.001\n",
      "Episode:21, Validation Loss:3.167784240540471e-05,Acc:99.0419%,lr:0.001\n",
      "Episode:22, Validation Loss:3.0103858364516705e-05,Acc:99.1683%,lr:0.001\n",
      "Episode:23, Validation Loss:2.1299002636335568e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:24, Validation Loss:2.7592574554190028e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:25, Validation Loss:2.8406426679846134e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:26, Validation Loss:2.495253158712181e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:27, Validation Loss:2.1368624854409052e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:28, Validation Loss:2.495413986905289e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:29, Validation Loss:2.1163188726582373e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:30, Validation Loss:2.556554056054659e-05,Acc:99.1683%,lr:0.001\n",
      "Episode:31, Validation Loss:2.010727083745474e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:32, Validation Loss:2.30326603525532e-05,Acc:99.2149%,lr:0.001\n",
      "Episode:33, Validation Loss:1.739191064265317e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:34, Validation Loss:2.0535726159692048e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:35, Validation Loss:1.9571121350793305e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:36, Validation Loss:2.065354128475397e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:37, Validation Loss:2.2027348072149717e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:38, Validation Loss:1.7655657013197858e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:39, Validation Loss:2.8944715203163392e-05,Acc:99.1018%,lr:0.001\n",
      "Episode:40, Validation Loss:2.1451865852682177e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:41, Validation Loss:2.1422618296163447e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:42, Validation Loss:2.3400933120501335e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:43, Validation Loss:1.8739477029232604e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:44, Validation Loss:1.6950939379815886e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:45, Validation Loss:2.029135424200091e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:46, Validation Loss:2.1255804697969953e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:47, Validation Loss:1.6575735136717857e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:48, Validation Loss:2.116908784645919e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7794771200505718e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8018841494372982e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:51, Validation Loss:1.944445218600913e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:52, Validation Loss:2.0115221748333017e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:53, Validation Loss:1.918743067084553e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:54, Validation Loss:2.0649314641764142e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:55, Validation Loss:1.2157317337716967e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:56, Validation Loss:1.7329372889445927e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:57, Validation Loss:1.7467982780760873e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:58, Validation Loss:2.030115329839552e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:59, Validation Loss:1.658989142574474e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:60, Validation Loss:2.085638132766732e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:61, Validation Loss:1.7409950277271744e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:62, Validation Loss:2.1589224283160247e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:63, Validation Loss:2.124045832368904e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:64, Validation Loss:1.5503162684207824e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:65, Validation Loss:1.9721982533425706e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:66, Validation Loss:2.146710084623602e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:67, Validation Loss:2.634942002411057e-05,Acc:99.2282%,lr:0.001\n",
      "Episode:68, Validation Loss:1.8017638365645765e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:69, Validation Loss:1.47921558970205e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:70, Validation Loss:1.448815767805099e-05,Acc:99.6141%,lr:0.001\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:71, Validation Loss:1.597194058705352e-05,Acc:99.5010%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.2837697337279301e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.2235372734373201e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.143999769540128e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.2044678860438799e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.1123807484895011e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.1470277607193091e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.1242181093680486e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.1660063271215576e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.1526356455550856e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.126366236178342e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.1056990202216411e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.1514387783146428e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.1985579379155727e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.1142686750499392e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.1707903105946517e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.1299190768898921e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0956777321671694e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.2028291951604708e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.1766562579138946e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.158906612855073e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.1283980499078097e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.141495760393912e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.114382103695246e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.068372640037489e-05,Acc:99.7405%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.1553395575461431e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0996729077266917e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0728535749865862e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0761913749886923e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.1248655427626508e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0649611862377571e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0781200988068235e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.097050624331354e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0656352704533402e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.072346441031335e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.0519790917347449e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.1076795647363224e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.134190603679248e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.099481091215582e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.0873254819841918e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.0729474415203293e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.0693373458481041e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.0832187336084451e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.0847785687960153e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.0859861527523118e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0838474135248565e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0574125689135261e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.035244544907284e-05,Acc:99.7405%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.0720747650036476e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.1275961365568107e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.1332267343859155e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.1454049543696329e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.097357957682765e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.0848306838227207e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.085827626530837e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.0512169749189121e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.030281469280412e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.1101388326007686e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.0387629180085794e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0738698784224764e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.0841028332333524e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.1138060964837283e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0809689327697712e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.0859094967871051e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.0661131170090643e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.120150980929375e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:137, Validation Loss:1.1055245536986146e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:138, Validation Loss:1.0838559769832604e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:139, Validation Loss:1.0977129849121322e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.1069856891414758e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:141, Validation Loss:1.1414483484532621e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:142, Validation Loss:1.0926313871791659e-05,Acc:99.7006%,lr:0.0001\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:143, Validation Loss:1.0991256054508155e-05,Acc:99.7139%,lr:1e-05\n",
      "Episode:144, Validation Loss:1.0845714595096951e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:145, Validation Loss:1.0817945722294742e-05,Acc:99.7139%,lr:1e-05\n",
      "Episode:146, Validation Loss:1.0768835899418223e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:147, Validation Loss:1.0748431229057982e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:148, Validation Loss:1.0763919563419963e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:149, Validation Loss:1.0726768281794117e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:150, Validation Loss:1.075057392160415e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:151, Validation Loss:1.0878591211444524e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:152, Validation Loss:1.0789155090105034e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:153, Validation Loss:1.0736452983177986e-05,Acc:99.7139%,lr:1e-05\n",
      "Episode:154, Validation Loss:1.0752023451144269e-05,Acc:99.7139%,lr:1e-05\n",
      "Episode:155, Validation Loss:1.0891855865994534e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:156, Validation Loss:1.0918559387564183e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:157, Validation Loss:1.0935041442493637e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:158, Validation Loss:1.091553134991182e-05,Acc:99.7073%,lr:1e-05\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:1.035244544907284e-05 Acc:0.9974051896207585==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0032450221969695862,Acc:9.7871%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005378369878945316,Acc:9.7871%,lr:0.001\n",
      "Episode:3, Validation Loss:0.003857902931675305,Acc:19.8669%,lr:0.001\n",
      "Episode:4, Validation Loss:0.001415902491180562,Acc:62.4884%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0005229222342243055,Acc:85.7019%,lr:0.001\n",
      "Episode:6, Validation Loss:0.00030520259937443737,Acc:92.2355%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0001436861119148181,Acc:96.3806%,lr:0.001\n",
      "Episode:8, Validation Loss:8.165287306248468e-05,Acc:97.6979%,lr:0.001\n",
      "Episode:9, Validation Loss:4.2850014345295335e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:10, Validation Loss:4.6043360825189334e-05,Acc:98.8224%,lr:0.001\n",
      "Episode:11, Validation Loss:3.940682456700388e-05,Acc:98.8822%,lr:0.001\n",
      "Episode:12, Validation Loss:4.436552712937949e-05,Acc:98.8290%,lr:0.001\n",
      "Episode:13, Validation Loss:5.580581258672599e-05,Acc:98.5163%,lr:0.001\n",
      "Episode:14, Validation Loss:3.491652173969798e-05,Acc:99.0353%,lr:0.001\n",
      "Episode:15, Validation Loss:4.3040008488013916e-05,Acc:98.5762%,lr:0.001\n",
      "Episode:16, Validation Loss:3.6068623160530706e-05,Acc:99.0818%,lr:0.001\n",
      "Episode:17, Validation Loss:3.4226625550511036e-05,Acc:99.1284%,lr:0.001\n",
      "Episode:18, Validation Loss:3.509380218293456e-05,Acc:99.0020%,lr:0.001\n",
      "Episode:19, Validation Loss:3.245484129744455e-05,Acc:99.0885%,lr:0.001\n",
      "Episode:20, Validation Loss:2.5978887172357605e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:21, Validation Loss:2.3998601854105276e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:22, Validation Loss:2.2386392443400577e-05,Acc:99.3546%,lr:0.001\n",
      "Episode:23, Validation Loss:3.48343129108052e-05,Acc:99.1018%,lr:0.001\n",
      "Episode:24, Validation Loss:2.807205504504189e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:25, Validation Loss:2.4334384290797664e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:26, Validation Loss:2.6935686345546148e-05,Acc:99.1949%,lr:0.001\n",
      "Episode:27, Validation Loss:2.3897462391250545e-05,Acc:99.2548%,lr:0.001\n",
      "Episode:28, Validation Loss:2.222860626088169e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4612927753589824e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:30, Validation Loss:2.8942603585685164e-05,Acc:99.1683%,lr:0.001\n",
      "Episode:31, Validation Loss:2.4340760597311015e-05,Acc:99.1816%,lr:0.001\n",
      "Episode:32, Validation Loss:2.3688739463092085e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:33, Validation Loss:1.9267149683501986e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:34, Validation Loss:2.312805740310205e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:35, Validation Loss:1.7425576962297627e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:36, Validation Loss:2.6257758054210596e-05,Acc:99.1284%,lr:0.001\n",
      "Episode:37, Validation Loss:2.216775495749827e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:38, Validation Loss:1.858655792113867e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:39, Validation Loss:2.0846968959132118e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:40, Validation Loss:3.7783239946433566e-05,Acc:98.8090%,lr:0.001\n",
      "Episode:41, Validation Loss:1.9181936518279855e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:42, Validation Loss:2.3313963640771225e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:43, Validation Loss:4.068041667689186e-05,Acc:98.8357%,lr:0.001\n",
      "Episode:44, Validation Loss:1.6328436709786762e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:45, Validation Loss:2.219935027722589e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:46, Validation Loss:2.04879219234188e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:47, Validation Loss:1.5041564485270107e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:48, Validation Loss:1.8720155307949976e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:49, Validation Loss:2.1155616076426433e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:50, Validation Loss:1.6345621903965415e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:51, Validation Loss:2.6862104426442348e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:52, Validation Loss:1.7374315678934534e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:53, Validation Loss:2.2982499275309438e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:54, Validation Loss:1.6976712012560624e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:55, Validation Loss:1.5178857884274986e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:56, Validation Loss:2.1363248929619314e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6227692609785482e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:58, Validation Loss:1.7275515552151622e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:59, Validation Loss:1.8896978857839653e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:60, Validation Loss:2.281715965154999e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:61, Validation Loss:1.39820397504948e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:62, Validation Loss:1.8862167036214115e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:63, Validation Loss:1.4912886532669216e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:64, Validation Loss:1.6996436687316486e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:65, Validation Loss:1.5770280777079538e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:66, Validation Loss:1.4964752060349434e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:67, Validation Loss:1.4546337393090794e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:68, Validation Loss:1.71021704579978e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:69, Validation Loss:1.644811243517789e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:70, Validation Loss:2.400289108098069e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:71, Validation Loss:2.078539428517411e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:72, Validation Loss:1.678788707314613e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5671550112213204e-05,Acc:99.5808%,lr:0.001\n",
      "Episode:74, Validation Loss:1.6583086884346946e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:75, Validation Loss:1.669542080737001e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:76, Validation Loss:1.7321461108987204e-05,Acc:99.4478%,lr:0.001\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:77, Validation Loss:1.824032766242584e-05,Acc:99.4611%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.3123771965166607e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.2404732009568217e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.1934547332510184e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.1066485091632435e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.1044668271661757e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0797811030141925e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0095049576934227e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.0066845405323856e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.0189415325602134e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.0026230446434147e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0577924716883077e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.0216831838735643e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0747922533603804e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0112861911217847e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.0406470337680634e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.0546482634728778e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.000238521147274e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0136510533635726e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.801896215873168e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0143774849717726e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.922771290172678e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0058379478638599e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0273012556309155e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0426204492965699e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.678993919394609e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.76631662629282e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.248908906580208e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.17333403152382e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:106, Validation Loss:8.825529013535458e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.47908249250548e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.0005635824686514e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.38828653486784e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.657121997720705e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.791552803602444e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.506865462173007e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.319363645242597e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.786686720605381e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.369620457242031e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.426064863652289e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.78056809239719e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.587238414469593e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.534620454984749e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.031943867683252e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:121, Validation Loss:9.614237257622118e-06,Acc:99.7272%,lr:0.0001\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:122, Validation Loss:9.191188656403395e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:123, Validation Loss:9.235605152592767e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:124, Validation Loss:9.275549472478812e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:125, Validation Loss:9.33776132474918e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:126, Validation Loss:9.307858806180304e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:127, Validation Loss:9.355116486846806e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:128, Validation Loss:9.361054024554377e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:129, Validation Loss:9.304645526423029e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:130, Validation Loss:9.39770122706216e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:131, Validation Loss:9.390809563938491e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:132, Validation Loss:9.443785026124217e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:133, Validation Loss:9.454273124902707e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:134, Validation Loss:9.327203330304412e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:135, Validation Loss:9.35815025619166e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:136, Validation Loss:9.362078293493726e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:137, Validation Loss:9.3709480101695e-06,Acc:99.7605%,lr:1e-05\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:9.275549472478812e-06 Acc:0.9977378576180972==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0018887968041146508,Acc:35.4358%,lr:0.001\n",
      "Episode:2, Validation Loss:0.0030992928934509725,Acc:28.3500%,lr:0.001\n",
      "Episode:3, Validation Loss:0.004881433130341693,Acc:20.8716%,lr:0.001\n",
      "Episode:4, Validation Loss:0.008397096074269916,Acc:16.8197%,lr:0.001\n",
      "Episode:5, Validation Loss:0.013042894110866808,Acc:16.7864%,lr:0.001\n",
      "Episode:6, Validation Loss:0.004557770946703192,Acc:37.1391%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0015272641451614187,Acc:72.8277%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00024774121746410944,Acc:93.3134%,lr:0.001\n",
      "Episode:9, Validation Loss:0.000128277320803917,Acc:96.1810%,lr:0.001\n",
      "Episode:10, Validation Loss:5.3561446136105324e-05,Acc:98.7558%,lr:0.001\n",
      "Episode:11, Validation Loss:4.5285725263421406e-05,Acc:98.9288%,lr:0.001\n",
      "Episode:12, Validation Loss:4.463287260004146e-05,Acc:98.8955%,lr:0.001\n",
      "Episode:13, Validation Loss:5.6756116296161594e-05,Acc:98.3832%,lr:0.001\n",
      "Episode:14, Validation Loss:3.577254375496152e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:15, Validation Loss:4.522349853973268e-05,Acc:98.6094%,lr:0.001\n",
      "Episode:16, Validation Loss:3.7325485420480856e-05,Acc:99.0619%,lr:0.001\n",
      "Episode:17, Validation Loss:4.668837228538351e-05,Acc:98.6893%,lr:0.001\n",
      "Episode:18, Validation Loss:5.9490696126155195e-05,Acc:98.5096%,lr:0.001\n",
      "Episode:19, Validation Loss:3.109523110681586e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:20, Validation Loss:3.592538760748214e-05,Acc:98.9953%,lr:0.001\n",
      "Episode:21, Validation Loss:2.7636257672579543e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:22, Validation Loss:3.230009384140997e-05,Acc:98.9687%,lr:0.001\n",
      "Episode:23, Validation Loss:2.4837466714010188e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:24, Validation Loss:2.2920246619584954e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:25, Validation Loss:3.0424467802880528e-05,Acc:99.1550%,lr:0.001\n",
      "Episode:26, Validation Loss:2.043656447155033e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:27, Validation Loss:2.3198804643974254e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:28, Validation Loss:2.3829377320157e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:29, Validation Loss:2.5121453239849544e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:30, Validation Loss:2.1457057185991556e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:31, Validation Loss:2.5532549000527966e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:32, Validation Loss:2.246357213039043e-05,Acc:99.3679%,lr:0.001\n",
      "Episode:33, Validation Loss:2.089554446433991e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:34, Validation Loss:2.1613187126255163e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:35, Validation Loss:2.4366358707764904e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:36, Validation Loss:1.8458781083543857e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:37, Validation Loss:1.967397576702371e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:38, Validation Loss:2.479166906582302e-05,Acc:99.3413%,lr:0.001\n",
      "Episode:39, Validation Loss:1.758216041885688e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:40, Validation Loss:2.3152501243634457e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:41, Validation Loss:2.9925724023027336e-05,Acc:99.2415%,lr:0.001\n",
      "Episode:42, Validation Loss:1.7805824165324806e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:43, Validation Loss:1.8356723527480426e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:44, Validation Loss:1.8924807712029236e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:45, Validation Loss:2.000259845229442e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:46, Validation Loss:2.552288363198796e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:47, Validation Loss:2.0973018109699288e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:48, Validation Loss:1.9209773520767413e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:49, Validation Loss:1.896497020801543e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:50, Validation Loss:1.7844790410614774e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:51, Validation Loss:1.806835557197184e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:52, Validation Loss:1.9028756664650724e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:53, Validation Loss:1.8190956040621995e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:54, Validation Loss:1.897901682033193e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:55, Validation Loss:1.6492869115062183e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:56, Validation Loss:2.7709622530939574e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:57, Validation Loss:1.4244101127375386e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:58, Validation Loss:1.908790336268708e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:59, Validation Loss:2.0103617084875e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:60, Validation Loss:1.7941984765018452e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:61, Validation Loss:1.7845684275804404e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:62, Validation Loss:2.0670521439252024e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:63, Validation Loss:1.5656799400201735e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:64, Validation Loss:2.1667011622500594e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:65, Validation Loss:1.5700470652438686e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:66, Validation Loss:1.6633636415431044e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:67, Validation Loss:1.9049327027397163e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:68, Validation Loss:1.948323445946117e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:69, Validation Loss:1.8727659208778136e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:70, Validation Loss:1.681468995437968e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:71, Validation Loss:1.8309796457033274e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:72, Validation Loss:1.674470431602009e-05,Acc:99.4677%,lr:0.001\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:73, Validation Loss:1.9433197992310394e-05,Acc:99.4544%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.4181227775827219e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.3329313587117259e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.3052694330949904e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.2091764528366303e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.2051856674437355e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.207474552228779e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.1541625374527828e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.2251641074628014e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.1986727359706533e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.1316023479480389e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.1706142794744856e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.1384526623322498e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.1149631702872174e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.1521422738582392e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.1184510693737292e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.1282959080493934e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.176691521764674e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.141586603072589e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.1044953678965727e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.1491450231400871e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0975433701893447e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.13594531641154e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0913460380977102e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.1151652078002353e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.082215783466955e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.118983810052464e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0914355764290688e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.1516891944105039e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.1021273237908988e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0715372251942804e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0813606087507523e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.0374220985366515e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.060326830920821e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0459126064371682e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.0482216574851466e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.1071562457207592e-05,Acc:99.6806%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.114615780150819e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.0604847251070156e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.1186103391661219e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.0755737247075625e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.0817296398990724e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.0392254036284255e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0621248287751685e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0868841788408681e-05,Acc:99.6939%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.1446329294713195e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.0915774869387418e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.0905312981483783e-05,Acc:99.6740%,lr:0.0001\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:121, Validation Loss:1.073024057208778e-05,Acc:99.6673%,lr:1e-05\n",
      "Episode:122, Validation Loss:1.06664976453333e-05,Acc:99.6673%,lr:1e-05\n",
      "Episode:123, Validation Loss:1.0699621375082575e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:124, Validation Loss:1.0693457481994758e-05,Acc:99.6673%,lr:1e-05\n",
      "Episode:125, Validation Loss:1.0759015217502752e-05,Acc:99.6673%,lr:1e-05\n",
      "Episode:126, Validation Loss:1.0758717200475301e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:127, Validation Loss:1.0830403943202214e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:128, Validation Loss:1.0820941507558543e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:129, Validation Loss:1.086165740620035e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:130, Validation Loss:1.0812409991721907e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:131, Validation Loss:1.078182372871194e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:132, Validation Loss:1.0828851460072095e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:133, Validation Loss:1.0868544452987904e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:134, Validation Loss:1.0940041430220157e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:135, Validation Loss:1.0967774177868605e-05,Acc:99.6806%,lr:1e-05\n",
      "Episode:136, Validation Loss:1.0850913611972482e-05,Acc:99.6806%,lr:1e-05\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:1.0392254036284255e-05 Acc:0.9970725216234199==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.004310193350532415,Acc:10.2994%,lr:0.001\n",
      "Episode:2, Validation Loss:0.009795528178364137,Acc:10.2462%,lr:0.001\n",
      "Episode:3, Validation Loss:0.02245093223180917,Acc:9.8137%,lr:0.001\n",
      "Episode:4, Validation Loss:0.012173652839279936,Acc:11.1910%,lr:0.001\n",
      "Episode:5, Validation Loss:0.010785010966632815,Acc:19.2681%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0001553433165896042,Acc:95.6886%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00031217251689292873,Acc:93.4864%,lr:0.001\n",
      "Episode:8, Validation Loss:5.631322959463991e-05,Acc:98.3832%,lr:0.001\n",
      "Episode:9, Validation Loss:5.784696011406853e-05,Acc:98.5230%,lr:0.001\n",
      "Episode:10, Validation Loss:4.9279354815077005e-05,Acc:98.7625%,lr:0.001\n",
      "Episode:11, Validation Loss:6.239022873713823e-05,Acc:98.4498%,lr:0.001\n",
      "Episode:12, Validation Loss:3.4791543826966464e-05,Acc:99.1084%,lr:0.001\n",
      "Episode:13, Validation Loss:4.963626092422508e-05,Acc:98.6494%,lr:0.001\n",
      "Episode:14, Validation Loss:3.720098426063617e-05,Acc:98.9355%,lr:0.001\n",
      "Episode:15, Validation Loss:3.1096280533237924e-05,Acc:99.0353%,lr:0.001\n",
      "Episode:16, Validation Loss:3.3650115189338954e-05,Acc:99.0885%,lr:0.001\n",
      "Episode:17, Validation Loss:3.065018247285051e-05,Acc:99.0885%,lr:0.001\n",
      "Episode:18, Validation Loss:2.8295312956699275e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:19, Validation Loss:2.6427893214676274e-05,Acc:99.2149%,lr:0.001\n",
      "Episode:20, Validation Loss:4.223598661774885e-05,Acc:98.7092%,lr:0.001\n",
      "Episode:21, Validation Loss:4.195237925111335e-05,Acc:98.9554%,lr:0.001\n",
      "Episode:22, Validation Loss:2.7048360452264132e-05,Acc:99.0951%,lr:0.001\n",
      "Episode:23, Validation Loss:4.541368848945963e-05,Acc:98.7359%,lr:0.001\n",
      "Episode:24, Validation Loss:3.1264908785274326e-05,Acc:99.1550%,lr:0.001\n",
      "Episode:25, Validation Loss:3.1243227496594485e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:26, Validation Loss:3.407670808330188e-05,Acc:98.9887%,lr:0.001\n",
      "Episode:27, Validation Loss:2.4472081789614278e-05,Acc:99.2282%,lr:0.001\n",
      "Episode:28, Validation Loss:3.099901711968525e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:29, Validation Loss:2.26059313851123e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:30, Validation Loss:2.5798906017583128e-05,Acc:99.2282%,lr:0.001\n",
      "Episode:31, Validation Loss:2.4922988709020203e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:32, Validation Loss:1.7588212435503682e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:33, Validation Loss:1.945764675900013e-05,Acc:99.4810%,lr:0.001\n",
      "Episode:34, Validation Loss:2.812078087550358e-05,Acc:99.1284%,lr:0.001\n",
      "Episode:35, Validation Loss:2.1960844700326938e-05,Acc:99.3812%,lr:0.001\n",
      "Episode:36, Validation Loss:2.0477896294769097e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:37, Validation Loss:1.6948395282902562e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:38, Validation Loss:2.897584108178487e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:39, Validation Loss:2.0348561738065618e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:40, Validation Loss:2.0581849863726697e-05,Acc:99.3945%,lr:0.001\n",
      "Episode:41, Validation Loss:1.5223834103472774e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:42, Validation Loss:1.848258040300109e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:43, Validation Loss:1.8600252452625565e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:44, Validation Loss:2.618707717704281e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:45, Validation Loss:1.7642424208268832e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:46, Validation Loss:1.464156757393283e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:47, Validation Loss:1.9572488715747e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:48, Validation Loss:1.704730359925402e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:49, Validation Loss:1.9079581224028062e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:50, Validation Loss:1.7389647088850726e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:51, Validation Loss:1.947553159144824e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:52, Validation Loss:1.6436027517853305e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:53, Validation Loss:1.4655682037095586e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:54, Validation Loss:1.758951253827143e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:55, Validation Loss:1.8207934026371536e-05,Acc:99.4411%,lr:0.001\n",
      "Episode:56, Validation Loss:1.6436472390137034e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:57, Validation Loss:2.1940283477306367e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:58, Validation Loss:2.466569699877433e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:59, Validation Loss:1.5040516824828968e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:60, Validation Loss:1.405253746135982e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:61, Validation Loss:1.6750387056759812e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:62, Validation Loss:1.3497993207511232e-05,Acc:99.5941%,lr:0.001\n",
      "Episode:63, Validation Loss:1.3061478567952247e-05,Acc:99.5675%,lr:0.001\n",
      "Episode:64, Validation Loss:2.002053803015136e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:65, Validation Loss:1.879678193308755e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:66, Validation Loss:1.3099761130765368e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:67, Validation Loss:1.579424746195753e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:68, Validation Loss:1.463362877706409e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:69, Validation Loss:1.3843797338123887e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:70, Validation Loss:1.4110532027241078e-05,Acc:99.5542%,lr:0.001\n",
      "Episode:71, Validation Loss:1.896476358824663e-05,Acc:99.4943%,lr:0.001\n",
      "Episode:72, Validation Loss:1.7992975419549568e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5670105756687388e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:74, Validation Loss:1.206986630287118e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:75, Validation Loss:1.1515344108293157e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:76, Validation Loss:1.0779899274230161e-05,Acc:99.6806%,lr:0.001\n",
      "Episode:77, Validation Loss:1.0702546645037667e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:78, Validation Loss:1.553748102260088e-05,Acc:99.4544%,lr:0.001\n",
      "Episode:79, Validation Loss:1.3206084553184545e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:80, Validation Loss:1.6032708517547775e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:81, Validation Loss:1.6001121686921466e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:82, Validation Loss:1.381582107099984e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:83, Validation Loss:1.558728403946557e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:84, Validation Loss:1.415859384887312e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:85, Validation Loss:1.656927725427839e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:86, Validation Loss:1.919371771786662e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:87, Validation Loss:2.2493417146141658e-05,Acc:99.3280%,lr:0.001\n",
      "Episode:88, Validation Loss:1.5765098118764198e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:89, Validation Loss:1.3776943558506067e-05,Acc:99.5675%,lr:0.001\n",
      "Episode:90, Validation Loss:1.3519007513077753e-05,Acc:99.5941%,lr:0.001\n",
      "Episode:91, Validation Loss:1.4142832654966407e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:92, Validation Loss:1.573661507707751e-05,Acc:99.4943%,lr:0.001\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:93, Validation Loss:1.5365832478442514e-05,Acc:99.5143%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.072087678351921e-05,Acc:99.6673%,lr:0.0001\n",
      "Episode:95, Validation Loss:9.891584190878961e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.393263255021054e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.23956125969698e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.519118457507151e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.486110662856818e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.24491205798612e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.399488492709593e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.753142470519938e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.550332139461181e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.554958111016018e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.38181127145817e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.482748049273542e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.040465437158376e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.192392156916067e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:109, Validation Loss:8.904571841388484e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.270683358499628e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.915427226109737e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.397101939884488e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.268645850256214e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.63827250593516e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.692041854004184e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.353519234551007e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.207008251609282e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.892656172285537e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.269835563724785e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:120, Validation Loss:9.727914565436775e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.911217537448951e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.366184230137886e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:123, Validation Loss:9.282743397180589e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:124, Validation Loss:8.339261888952074e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:125, Validation Loss:8.807536549196986e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:126, Validation Loss:9.536568331950439e-06,Acc:99.6806%,lr:0.0001\n",
      "Episode:127, Validation Loss:8.814670244654417e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.700853974915947e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:129, Validation Loss:9.819222936383186e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.612351375881705e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:131, Validation Loss:9.080726301380578e-06,Acc:99.6939%,lr:0.0001\n",
      "Episode:132, Validation Loss:9.956282203495304e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:133, Validation Loss:9.682016101425994e-06,Acc:99.6474%,lr:0.0001\n",
      "Episode:134, Validation Loss:9.229474596267768e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:135, Validation Loss:9.249583449331189e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:136, Validation Loss:8.92841270787075e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:137, Validation Loss:9.217550166332952e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:138, Validation Loss:8.978029150399303e-06,Acc:99.6673%,lr:0.0001\n",
      "Episode:139, Validation Loss:9.540320266873457e-06,Acc:99.6474%,lr:0.0001\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:140, Validation Loss:9.039596357666011e-06,Acc:99.6939%,lr:1e-05\n",
      "Episode:141, Validation Loss:8.84909500663509e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:142, Validation Loss:8.827540496796746e-06,Acc:99.6939%,lr:1e-05\n",
      "Episode:143, Validation Loss:8.810119776529863e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:144, Validation Loss:8.86195996083463e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:145, Validation Loss:8.836569275684699e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:146, Validation Loss:8.759631156296788e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:147, Validation Loss:8.836648713844423e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:148, Validation Loss:8.798928910287634e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:149, Validation Loss:8.90373774071138e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:150, Validation Loss:8.892685302588357e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:151, Validation Loss:8.933348531623483e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:152, Validation Loss:8.919578186885087e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:153, Validation Loss:8.82062748699131e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:154, Validation Loss:8.880210258388868e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:155, Validation Loss:8.905550845448208e-06,Acc:99.7139%,lr:1e-05\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:8.339261888952074e-06 Acc:0.9974717232202263==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0036166294526831753,Acc:22.6813%,lr:0.001\n",
      "Episode:2, Validation Loss:0.014281647568611963,Acc:10.2129%,lr:0.001\n",
      "Episode:3, Validation Loss:0.02644248551237369,Acc:10.2129%,lr:0.001\n",
      "Episode:4, Validation Loss:0.02259244772885057,Acc:10.2129%,lr:0.001\n",
      "Episode:5, Validation Loss:0.02104539420710987,Acc:10.2129%,lr:0.001\n",
      "Episode:6, Validation Loss:0.006281120873893489,Acc:30.2728%,lr:0.001\n",
      "Episode:7, Validation Loss:0.002152893563865108,Acc:63.2269%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0006277346206520369,Acc:87.5383%,lr:0.001\n",
      "Episode:9, Validation Loss:5.357475555982101e-05,Acc:98.5163%,lr:0.001\n",
      "Episode:10, Validation Loss:4.622173915088613e-05,Acc:98.7691%,lr:0.001\n",
      "Episode:11, Validation Loss:4.783110074693968e-05,Acc:98.8290%,lr:0.001\n",
      "Episode:12, Validation Loss:4.47299679665667e-05,Acc:98.9088%,lr:0.001\n",
      "Episode:13, Validation Loss:5.7323341687282404e-05,Acc:98.3965%,lr:0.001\n",
      "Episode:14, Validation Loss:4.604562512256269e-05,Acc:98.8357%,lr:0.001\n",
      "Episode:15, Validation Loss:6.456062970998997e-05,Acc:98.7425%,lr:0.001\n",
      "Episode:16, Validation Loss:3.8372047607373655e-05,Acc:98.9421%,lr:0.001\n",
      "Episode:17, Validation Loss:2.8009259303708275e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:18, Validation Loss:3.830805515061199e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:19, Validation Loss:3.0799464310853384e-05,Acc:99.1018%,lr:0.001\n",
      "Episode:20, Validation Loss:4.2439576149165274e-05,Acc:98.8955%,lr:0.001\n",
      "Episode:21, Validation Loss:3.974919274935148e-05,Acc:98.8024%,lr:0.001\n",
      "Episode:22, Validation Loss:2.1617255698460703e-05,Acc:99.2947%,lr:0.001\n",
      "Episode:23, Validation Loss:3.0595339904090044e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:24, Validation Loss:2.5048868139525374e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:25, Validation Loss:5.1593917210698525e-05,Acc:98.6228%,lr:0.001\n",
      "Episode:26, Validation Loss:2.6393655367835077e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6638295776591805e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:28, Validation Loss:2.8563674950770195e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4495716624988055e-05,Acc:99.2681%,lr:0.001\n",
      "Episode:30, Validation Loss:2.6956036146569076e-05,Acc:99.2415%,lr:0.001\n",
      "Episode:31, Validation Loss:2.5010240373913637e-05,Acc:99.2947%,lr:0.001\n",
      "Episode:32, Validation Loss:2.8350878586213112e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:33, Validation Loss:2.266425931862173e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:34, Validation Loss:2.2326990855450006e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:35, Validation Loss:2.547731537542895e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:36, Validation Loss:3.0024069982890044e-05,Acc:99.2415%,lr:0.001\n",
      "Episode:37, Validation Loss:2.947159902163529e-05,Acc:99.1617%,lr:0.001\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:38, Validation Loss:3.0141545017203408e-05,Acc:99.2415%,lr:0.0001\n",
      "Episode:39, Validation Loss:1.6985657852309114e-05,Acc:99.4611%,lr:0.0001\n",
      "Episode:40, Validation Loss:1.556116245508551e-05,Acc:99.4943%,lr:0.0001\n",
      "Episode:41, Validation Loss:1.4830316142417634e-05,Acc:99.5276%,lr:0.0001\n",
      "Episode:42, Validation Loss:1.3734155885394383e-05,Acc:99.5276%,lr:0.0001\n",
      "Episode:43, Validation Loss:1.461575103952182e-05,Acc:99.5276%,lr:0.0001\n",
      "Episode:44, Validation Loss:1.4654083545514923e-05,Acc:99.5077%,lr:0.0001\n",
      "Episode:45, Validation Loss:1.4702936371692958e-05,Acc:99.5143%,lr:0.0001\n",
      "Episode:46, Validation Loss:1.4233446654604025e-05,Acc:99.5476%,lr:0.0001\n",
      "Episode:47, Validation Loss:1.3937620558860853e-05,Acc:99.4877%,lr:0.0001\n",
      "Episode:48, Validation Loss:1.3769644697358508e-05,Acc:99.5476%,lr:0.0001\n",
      "Episode:49, Validation Loss:1.3004611100671852e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:50, Validation Loss:1.3623147098693305e-05,Acc:99.5276%,lr:0.0001\n",
      "Episode:51, Validation Loss:1.2724879163695983e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:52, Validation Loss:1.3190321314457806e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:53, Validation Loss:1.3061444053868809e-05,Acc:99.5476%,lr:0.0001\n",
      "Episode:54, Validation Loss:1.2768800286743455e-05,Acc:99.5808%,lr:0.0001\n",
      "Episode:55, Validation Loss:1.3129709100106598e-05,Acc:99.5675%,lr:0.0001\n",
      "Episode:56, Validation Loss:1.2503502827264115e-05,Acc:99.5941%,lr:0.0001\n",
      "Episode:57, Validation Loss:1.1726357730592559e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:58, Validation Loss:1.3334991773485106e-05,Acc:99.5276%,lr:0.0001\n",
      "Episode:59, Validation Loss:1.3341319964763646e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:60, Validation Loss:1.2900150695187366e-05,Acc:99.5542%,lr:0.0001\n",
      "Episode:61, Validation Loss:1.2770441378741287e-05,Acc:99.5542%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.2516623538877276e-05,Acc:99.6008%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.3644566154696112e-05,Acc:99.5675%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.3762561812580464e-05,Acc:99.5476%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.2140744226332197e-05,Acc:99.6008%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.2651479016699476e-05,Acc:99.6141%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.2375898467140125e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.2510172565450926e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.2981513247429254e-05,Acc:99.6008%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.335881116935712e-05,Acc:99.5808%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.2533354194350268e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.3658741838531104e-05,Acc:99.5675%,lr:0.0001\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:73, Validation Loss:1.3243238313380116e-05,Acc:99.5343%,lr:1e-05\n",
      "Episode:74, Validation Loss:1.2678695075506381e-05,Acc:99.5808%,lr:1e-05\n",
      "Episode:75, Validation Loss:1.2693508712206773e-05,Acc:99.5675%,lr:1e-05\n",
      "Episode:76, Validation Loss:1.253122231456453e-05,Acc:99.5742%,lr:1e-05\n",
      "Episode:77, Validation Loss:1.2284575317721722e-05,Acc:99.5808%,lr:1e-05\n",
      "Episode:78, Validation Loss:1.2258871558233253e-05,Acc:99.6141%,lr:1e-05\n",
      "Episode:79, Validation Loss:1.2300745103847798e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:80, Validation Loss:1.2139981136677747e-05,Acc:99.6141%,lr:1e-05\n",
      "Episode:81, Validation Loss:1.2078172113952126e-05,Acc:99.6274%,lr:1e-05\n",
      "Episode:82, Validation Loss:1.2009695769645179e-05,Acc:99.6208%,lr:1e-05\n",
      "Episode:83, Validation Loss:1.2168608709961592e-05,Acc:99.6274%,lr:1e-05\n",
      "Episode:84, Validation Loss:1.227833923629063e-05,Acc:99.6141%,lr:1e-05\n",
      "Episode:85, Validation Loss:1.2283707384567854e-05,Acc:99.6141%,lr:1e-05\n",
      "Episode:86, Validation Loss:1.2171729415139594e-05,Acc:99.6208%,lr:1e-05\n",
      "Episode:87, Validation Loss:1.2099948145959747e-05,Acc:99.6274%,lr:1e-05\n",
      "Episode:88, Validation Loss:1.2043427368619802e-05,Acc:99.6141%,lr:1e-05\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:1.2375898467140125e-05 Acc:0.9964071856287425==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10155\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10155_s5.npy\n",
      "shape of top1_dig_csv: (10155, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10155_s5.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s5.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10155, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75155, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75155_s5.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75155_s5.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step4\n",
      "Step: 5\n",
      "global_data len: 75155\n",
      "validation rate: 0.2\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.006912160606554316,Acc:10.0858%,lr:0.001\n",
      "Episode:2, Validation Loss:0.01774597662856626,Acc:10.0858%,lr:0.001\n",
      "Episode:3, Validation Loss:0.029828215682746868,Acc:10.0858%,lr:0.001\n",
      "Episode:4, Validation Loss:0.0518712867369838,Acc:10.0858%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0278788378722304,Acc:10.4783%,lr:0.001\n",
      "Episode:6, Validation Loss:0.007512534880509642,Acc:28.9468%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0051289108189571464,Acc:44.9272%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0012256833228686797,Acc:76.1160%,lr:0.001\n",
      "Episode:9, Validation Loss:6.465082472015161e-05,Acc:98.1438%,lr:0.001\n",
      "Episode:10, Validation Loss:5.1959613988074496e-05,Acc:98.5364%,lr:0.001\n",
      "Episode:11, Validation Loss:4.116069000306287e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:12, Validation Loss:4.857167213467192e-05,Acc:98.7160%,lr:0.001\n",
      "Episode:13, Validation Loss:4.7077528607440037e-05,Acc:98.9089%,lr:0.001\n",
      "Episode:14, Validation Loss:4.235057067442032e-05,Acc:98.9089%,lr:0.001\n",
      "Episode:15, Validation Loss:3.355782970763293e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:16, Validation Loss:3.304452015808596e-05,Acc:98.9688%,lr:0.001\n",
      "Episode:17, Validation Loss:3.9040338089148703e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:18, Validation Loss:5.411700541431751e-05,Acc:98.5497%,lr:0.001\n",
      "Episode:19, Validation Loss:2.2740784308073026e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:20, Validation Loss:2.3706494687730686e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:21, Validation Loss:4.274379240186476e-05,Acc:98.8890%,lr:0.001\n",
      "Episode:22, Validation Loss:3.5440936009490984e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:23, Validation Loss:3.115029102319586e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:24, Validation Loss:2.0408912810108064e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:25, Validation Loss:2.7607810157445065e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:26, Validation Loss:3.0469926826714852e-05,Acc:99.1019%,lr:0.001\n",
      "Episode:27, Validation Loss:5.229494129399579e-05,Acc:98.6628%,lr:0.001\n",
      "Episode:28, Validation Loss:2.6822709068571702e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:29, Validation Loss:2.6180664976194673e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:30, Validation Loss:2.357018074921272e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:31, Validation Loss:2.8668453231752297e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:32, Validation Loss:2.7150046678885643e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:33, Validation Loss:2.2827470172614238e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:34, Validation Loss:2.0483362387267743e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:35, Validation Loss:1.865949460783172e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:36, Validation Loss:2.2020908948087335e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:37, Validation Loss:1.859083284946919e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:38, Validation Loss:2.0151400724124165e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:39, Validation Loss:1.7148470386489013e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:40, Validation Loss:1.953514232734872e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:41, Validation Loss:1.940834502965325e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:42, Validation Loss:2.2148010160174963e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:43, Validation Loss:2.2307325058628657e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:44, Validation Loss:2.3995037827256372e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:45, Validation Loss:2.340143998151339e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:46, Validation Loss:1.938244092826096e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:47, Validation Loss:1.8210958633191427e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:48, Validation Loss:2.289441405564961e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:49, Validation Loss:2.109308018075929e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:50, Validation Loss:1.887503314217315e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:51, Validation Loss:1.636526041344035e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:52, Validation Loss:2.637147798358018e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:53, Validation Loss:1.687180150135946e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:54, Validation Loss:1.7641708946289094e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:55, Validation Loss:1.5671280294549686e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:56, Validation Loss:1.7942561021437862e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:57, Validation Loss:1.8891375464794996e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:58, Validation Loss:1.7465652640075964e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:59, Validation Loss:2.1862416198475537e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:60, Validation Loss:2.392336037687798e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5643433495532187e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:62, Validation Loss:1.6795101935355838e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:63, Validation Loss:2.2876388617328333e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:64, Validation Loss:1.8918154783872586e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:65, Validation Loss:3.9559544817105904e-05,Acc:98.7958%,lr:0.001\n",
      "Episode:66, Validation Loss:1.7083927334211487e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:67, Validation Loss:1.344377197650892e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:68, Validation Loss:1.3677802539860747e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:69, Validation Loss:1.9123256910379424e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:70, Validation Loss:1.707794496063526e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:71, Validation Loss:0.0002803504595887549,Acc:91.9433%,lr:0.001\n",
      "Episode:72, Validation Loss:1.5999015781778862e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:73, Validation Loss:1.732256915562802e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:74, Validation Loss:1.615672414724234e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:75, Validation Loss:1.462166497546925e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:76, Validation Loss:1.2949105483766611e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:77, Validation Loss:1.579069414543904e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:78, Validation Loss:1.605208282833621e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:79, Validation Loss:1.6533547044434825e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:80, Validation Loss:1.5514053545104603e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:81, Validation Loss:1.5044945292360696e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4899675266232432e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:83, Validation Loss:2.9162437791405907e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:84, Validation Loss:1.741677499610137e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:85, Validation Loss:1.6285005699629778e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:86, Validation Loss:1.536333719338456e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:87, Validation Loss:1.9279688231284672e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:88, Validation Loss:1.976253219084162e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:89, Validation Loss:0.00019149830317387808,Acc:94.0789%,lr:0.001\n",
      "Episode:90, Validation Loss:1.1890903948016544e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:91, Validation Loss:1.3817714998270173e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:92, Validation Loss:1.700335024189278e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:93, Validation Loss:1.5592381485040994e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:94, Validation Loss:1.622597161462608e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:95, Validation Loss:1.3733426680600412e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:96, Validation Loss:1.8521814076891043e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:97, Validation Loss:2.0169206699697837e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:98, Validation Loss:1.361721350366734e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:99, Validation Loss:1.5970468879867263e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:100, Validation Loss:1.660500760341062e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:101, Validation Loss:1.5751723645947807e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:102, Validation Loss:1.249255944412928e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:103, Validation Loss:1.184544730818753e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:104, Validation Loss:1.509768971256943e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:105, Validation Loss:2.798748213588878e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:106, Validation Loss:1.3175394269444138e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:107, Validation Loss:1.5166415367306456e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:108, Validation Loss:1.8758140107815428e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:109, Validation Loss:1.7701574505132857e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:110, Validation Loss:1.2018927808261888e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:111, Validation Loss:1.3955250077827447e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:112, Validation Loss:1.4430082113583735e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:113, Validation Loss:1.5358508796076774e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:114, Validation Loss:1.3105507822825392e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:115, Validation Loss:1.4820906449057021e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:116, Validation Loss:1.6441685062388318e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:117, Validation Loss:1.6867602216137454e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:118, Validation Loss:1.4085359143975664e-05,Acc:99.6075%,lr:0.001\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:119, Validation Loss:1.5363835352755188e-05,Acc:99.5343%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.1534430458373426e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.0604641644586371e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.0156626475740832e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.0015532716649727e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.0220355000271308e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.0200788211006816e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.011953992019033e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.0216083903269381e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.0390273846726037e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.079564880401017e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0022918641860674e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:131, Validation Loss:9.980660213073145e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:132, Validation Loss:9.699126931805666e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0257091357219473e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.0113625408436325e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:135, Validation Loss:9.87239346809313e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.005862839705858e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:137, Validation Loss:9.85431918970669e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:138, Validation Loss:9.806461533239467e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:139, Validation Loss:9.991781512592203e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.0070989441143191e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:141, Validation Loss:9.653242023622201e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:142, Validation Loss:9.57297978165696e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:143, Validation Loss:9.452914435588213e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:144, Validation Loss:9.545317050668105e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:145, Validation Loss:9.693293711730054e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:146, Validation Loss:9.535378306523173e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:147, Validation Loss:9.861549873835161e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:148, Validation Loss:9.779329986365587e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:149, Validation Loss:9.493770319592983e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:150, Validation Loss:9.618220908696062e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:151, Validation Loss:9.948483656309423e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:152, Validation Loss:9.678540201503893e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:153, Validation Loss:9.848768724642006e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:154, Validation Loss:1.0042498256870153e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:155, Validation Loss:9.385731541387145e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:156, Validation Loss:9.620656653981938e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:157, Validation Loss:1.0175395110220175e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:158, Validation Loss:9.97142299690509e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:159, Validation Loss:9.923786878849517e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:160, Validation Loss:1.062601957464974e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:161, Validation Loss:1.0193973713009256e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:162, Validation Loss:9.769436023897908e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:163, Validation Loss:9.704140729284692e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:164, Validation Loss:1.0020465423820753e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:165, Validation Loss:9.439394210585022e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:166, Validation Loss:9.843604178189257e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:167, Validation Loss:9.968454022820255e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:168, Validation Loss:9.864691794106969e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:169, Validation Loss:1.0077631411184593e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:170, Validation Loss:9.989908767943293e-06,Acc:99.7139%,lr:0.0001\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:171, Validation Loss:9.928655286905262e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:172, Validation Loss:9.796274096659975e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:173, Validation Loss:9.767296339558886e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:174, Validation Loss:9.704103599682348e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:175, Validation Loss:9.69999152333026e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:176, Validation Loss:9.77234243375084e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:177, Validation Loss:9.74891552896519e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:178, Validation Loss:9.716678344223339e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:179, Validation Loss:9.69933745680586e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:180, Validation Loss:9.700526301132238e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:181, Validation Loss:9.673047111511e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:182, Validation Loss:9.691534601942554e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:183, Validation Loss:9.674816026487604e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:184, Validation Loss:9.675480331921957e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:185, Validation Loss:9.64075097171428e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:186, Validation Loss:9.660772331404469e-06,Acc:99.7206%,lr:1e-05\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:9.843604178189257e-06 Acc:0.9975384205974319==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.006826676022355312,Acc:10.1590%,lr:0.001\n",
      "Episode:2, Validation Loss:0.017757912689669864,Acc:10.1590%,lr:0.001\n",
      "Episode:3, Validation Loss:0.025261548597904176,Acc:10.1590%,lr:0.001\n",
      "Episode:4, Validation Loss:0.031336078005520365,Acc:10.1590%,lr:0.001\n",
      "Episode:5, Validation Loss:0.024342521001031462,Acc:10.1657%,lr:0.001\n",
      "Episode:6, Validation Loss:0.010491460424944372,Acc:25.1148%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00499083840214923,Acc:43.4835%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0004034426987000659,Acc:92.8614%,lr:0.001\n",
      "Episode:9, Validation Loss:7.267319883869426e-05,Acc:98.2303%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00026461902385493664,Acc:94.2386%,lr:0.001\n",
      "Episode:11, Validation Loss:3.211862082891729e-05,Acc:99.1085%,lr:0.001\n",
      "Episode:12, Validation Loss:3.328621419700952e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:13, Validation Loss:4.2582655194300425e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:14, Validation Loss:4.3788002103152737e-05,Acc:98.7692%,lr:0.001\n",
      "Episode:15, Validation Loss:9.770028421514152e-05,Acc:96.6868%,lr:0.001\n",
      "Episode:16, Validation Loss:0.00011418623807988444,Acc:96.5272%,lr:0.001\n",
      "Episode:17, Validation Loss:5.5488143355401797e-05,Acc:98.5829%,lr:0.001\n",
      "Episode:18, Validation Loss:3.305772788722028e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:19, Validation Loss:3.612667605192645e-05,Acc:98.9355%,lr:0.001\n",
      "Episode:20, Validation Loss:3.525451523114342e-05,Acc:99.0087%,lr:0.001\n",
      "Episode:21, Validation Loss:2.7078466196096186e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:22, Validation Loss:2.6222065799461217e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:23, Validation Loss:3.981944874963014e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:24, Validation Loss:2.571552997815237e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:25, Validation Loss:3.759624997484621e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:26, Validation Loss:3.209056379921017e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:27, Validation Loss:3.232815310405595e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:28, Validation Loss:3.7920242853923186e-05,Acc:98.8091%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4799016863752068e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:30, Validation Loss:2.223180800152907e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:31, Validation Loss:2.2979847458310488e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:32, Validation Loss:2.5422041739431513e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:33, Validation Loss:2.265582651129883e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:34, Validation Loss:2.086763487369522e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:35, Validation Loss:2.4893215702731772e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:36, Validation Loss:2.067019535531843e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:37, Validation Loss:1.7336441654897595e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:38, Validation Loss:3.1245230285618235e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:39, Validation Loss:2.8710161501137877e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:40, Validation Loss:2.3717328166998946e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:41, Validation Loss:1.6508212170671635e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:42, Validation Loss:2.0681078278763026e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:43, Validation Loss:1.9829442367571318e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:44, Validation Loss:2.1076297600499632e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:45, Validation Loss:1.8421415198431004e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:46, Validation Loss:2.0808003276267314e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:47, Validation Loss:1.824608952596146e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:48, Validation Loss:1.7987079058378075e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:49, Validation Loss:1.9762171211178276e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:50, Validation Loss:1.6201569612440524e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:51, Validation Loss:2.0459015932330415e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:52, Validation Loss:1.8766490597205756e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:53, Validation Loss:1.6621503370271442e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:54, Validation Loss:1.6054551598366432e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:55, Validation Loss:1.5878077092318467e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:56, Validation Loss:1.910694857288379e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:57, Validation Loss:1.595586043377375e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:58, Validation Loss:1.8034343105908696e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:59, Validation Loss:1.7977629179585664e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:60, Validation Loss:1.899959513557329e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5368840491307343e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:62, Validation Loss:2.3627685193736018e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:63, Validation Loss:1.7965704179850652e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:64, Validation Loss:1.748148518580455e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:65, Validation Loss:2.4890108774438144e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:66, Validation Loss:1.8238175359741275e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:67, Validation Loss:1.7807296594424795e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:68, Validation Loss:1.937050996486433e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:69, Validation Loss:1.792972018915842e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:70, Validation Loss:1.6080918448920353e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:71, Validation Loss:1.4578823052734824e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6372717716710375e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:73, Validation Loss:1.7098151581086416e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:74, Validation Loss:1.6021182789469692e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:75, Validation Loss:1.7672704930402557e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:76, Validation Loss:1.382184337013401e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:77, Validation Loss:1.4355835331899186e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:78, Validation Loss:1.7976801237472476e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:79, Validation Loss:2.1769278364603125e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:80, Validation Loss:1.66055053290604e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:81, Validation Loss:1.5199851015683427e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:82, Validation Loss:1.5733714472158218e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:83, Validation Loss:1.5261206746410683e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:84, Validation Loss:2.0418720849378327e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:85, Validation Loss:2.579252837781825e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:86, Validation Loss:1.5522806837239765e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:87, Validation Loss:1.6221507480868037e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:88, Validation Loss:1.6655428426151986e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:89, Validation Loss:2.2158947174804955e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:90, Validation Loss:1.7578652936908967e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:91, Validation Loss:1.777151010161737e-05,Acc:99.4611%,lr:0.001\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:92, Validation Loss:1.564398494060664e-05,Acc:99.5210%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.189824355803725e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.1188727775336454e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0602651454528627e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0968014548572505e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0856013823387097e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0806596909501771e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.1299884262896926e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0668059501071532e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.1907553561857128e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.1569971867923323e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0990944037508976e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0700910416299192e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.1488906003192278e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.0506786167121966e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.1026243926508287e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.1063448562558861e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.16294027765202e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.133542294620151e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.1057888199364891e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.1272797776520843e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.0529103242225192e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.0862374153699746e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.0785270483788754e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0508186403890228e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0987890085118567e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.152351451018448e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.1323098365647946e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.0445552157051874e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.0609331251223735e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.0797784414471254e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.0789574574554969e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.0734202890327198e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.0564289930083938e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.0613325386486022e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.0545434783786034e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.0426782020039602e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.0725763240323144e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0781420405807154e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.0606165522775538e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:132, Validation Loss:9.960343690857854e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0357592113608015e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.0877706464393658e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.0181566074913858e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.0559062633518924e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:137, Validation Loss:1.0815751424398689e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:138, Validation Loss:1.0367040164576867e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:139, Validation Loss:1.1183404998225402e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.0681614206881907e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:141, Validation Loss:1.1051927542810977e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:142, Validation Loss:1.0596928322097512e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:143, Validation Loss:1.0700169435215444e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:144, Validation Loss:1.08397100709404e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:145, Validation Loss:1.179157905530909e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:146, Validation Loss:1.1024452783338371e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:147, Validation Loss:1.0585989262783537e-05,Acc:99.7073%,lr:0.0001\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:148, Validation Loss:1.100619549024534e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:149, Validation Loss:1.0739036399344945e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:150, Validation Loss:1.0655979508094528e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:151, Validation Loss:1.0635770750019208e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:152, Validation Loss:1.0533708304277827e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:153, Validation Loss:1.0555065431230661e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:154, Validation Loss:1.0567750278906181e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:155, Validation Loss:1.0620084801936259e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:156, Validation Loss:1.0562482522382334e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:157, Validation Loss:1.0598815503454551e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:158, Validation Loss:1.0545895798064287e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:159, Validation Loss:1.0550130090754504e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:160, Validation Loss:1.0531862667181734e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:161, Validation Loss:1.0563543186708963e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:162, Validation Loss:1.0556556377615665e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:163, Validation Loss:1.0519254185355009e-05,Acc:99.6740%,lr:1e-05\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:1.0181566074913858e-05 Acc:0.9974718914243896==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.004431798464285464,Acc:15.1154%,lr:0.001\n",
      "Episode:2, Validation Loss:0.010978807986484507,Acc:9.8729%,lr:0.001\n",
      "Episode:3, Validation Loss:0.013663088202309952,Acc:9.8729%,lr:0.001\n",
      "Episode:4, Validation Loss:0.00673833285792289,Acc:24.0902%,lr:0.001\n",
      "Episode:5, Validation Loss:0.005557444636340024,Acc:43.9625%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0016833382145816493,Acc:72.2706%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0002177762139399492,Acc:94.0589%,lr:0.001\n",
      "Episode:8, Validation Loss:7.423325901212001e-05,Acc:97.6781%,lr:0.001\n",
      "Episode:9, Validation Loss:3.8449074838794515e-05,Acc:98.8291%,lr:0.001\n",
      "Episode:10, Validation Loss:3.650200400630615e-05,Acc:99.0819%,lr:0.001\n",
      "Episode:11, Validation Loss:3.2248601327815e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:12, Validation Loss:4.416023310481824e-05,Acc:98.8690%,lr:0.001\n",
      "Episode:13, Validation Loss:4.474161383983705e-05,Acc:98.6495%,lr:0.001\n",
      "Episode:14, Validation Loss:5.897910580585265e-05,Acc:98.2237%,lr:0.001\n",
      "Episode:15, Validation Loss:2.897493395014807e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:16, Validation Loss:2.679875200201307e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:17, Validation Loss:2.478798969714642e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:18, Validation Loss:2.6864840773422318e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:19, Validation Loss:2.3690494230074938e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:20, Validation Loss:3.18980719203935e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:21, Validation Loss:2.782833936265046e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:22, Validation Loss:3.153387863342891e-05,Acc:99.0952%,lr:0.001\n",
      "Episode:23, Validation Loss:2.5283710875063707e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:24, Validation Loss:2.1707209503866384e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:25, Validation Loss:2.7908772769449205e-05,Acc:99.0819%,lr:0.001\n",
      "Episode:26, Validation Loss:1.3885401597272674e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:27, Validation Loss:1.8858271349533996e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:28, Validation Loss:1.697448779257636e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:29, Validation Loss:1.762577298911902e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:30, Validation Loss:1.8207528149147375e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:31, Validation Loss:1.3724193786150776e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:32, Validation Loss:2.114165982753326e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:33, Validation Loss:2.0275220466258085e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:34, Validation Loss:1.5823024564672552e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:35, Validation Loss:2.0353813936291843e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:36, Validation Loss:1.8543717196427706e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:37, Validation Loss:1.82077560384714e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:38, Validation Loss:2.2050980301319216e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:39, Validation Loss:2.6181543013065464e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:40, Validation Loss:1.6872093302548014e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:41, Validation Loss:1.2786596262269007e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:42, Validation Loss:1.832992002029919e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:43, Validation Loss:1.5475230882461417e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:44, Validation Loss:1.9358581882613314e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:45, Validation Loss:1.1184583727562074e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:46, Validation Loss:1.5790990748536952e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:47, Validation Loss:2.1524372251061064e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:48, Validation Loss:1.6427641708085846e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:49, Validation Loss:1.547610365272195e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:50, Validation Loss:1.6740578764001337e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:51, Validation Loss:1.768930435654535e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:52, Validation Loss:1.914374916698712e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:53, Validation Loss:1.569289545442528e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:54, Validation Loss:1.7571670712864603e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:55, Validation Loss:1.5628482890162003e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:56, Validation Loss:1.55991964167594e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:57, Validation Loss:1.3176974391932893e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:58, Validation Loss:1.1937785205921324e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:59, Validation Loss:1.687950209104351e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:60, Validation Loss:1.8401508557904338e-05,Acc:99.3813%,lr:0.001\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:61, Validation Loss:1.4756649125876219e-05,Acc:99.5010%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.028563982362412e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:63, Validation Loss:9.24296419296517e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:64, Validation Loss:8.908579439890377e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:65, Validation Loss:9.205175629246854e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:66, Validation Loss:9.014819329911209e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:67, Validation Loss:8.969587543360305e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:68, Validation Loss:9.18997633144211e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:69, Validation Loss:8.739496280563923e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:70, Validation Loss:8.55092494387615e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:71, Validation Loss:8.219400564284589e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:72, Validation Loss:8.559300170844682e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:73, Validation Loss:8.948563606956667e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:74, Validation Loss:8.873189135584898e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:75, Validation Loss:8.735760178224395e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:76, Validation Loss:8.70749390918959e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:77, Validation Loss:8.737810996260268e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:78, Validation Loss:8.761689466405761e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:79, Validation Loss:8.768720669925557e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:80, Validation Loss:8.630235029176184e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:81, Validation Loss:8.789122092996273e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:82, Validation Loss:8.986855302345299e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:83, Validation Loss:8.809713671677492e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:84, Validation Loss:9.184718968728513e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:85, Validation Loss:8.336850790517962e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.847018652143581e-06,Acc:99.7738%,lr:0.0001\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:87, Validation Loss:8.55595265140228e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:88, Validation Loss:8.45682318091559e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:89, Validation Loss:8.425033766476189e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:90, Validation Loss:8.397722209961573e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:91, Validation Loss:8.403280729841951e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:92, Validation Loss:8.364347731713786e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:93, Validation Loss:8.380137664369343e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:94, Validation Loss:8.313149139066988e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:95, Validation Loss:8.272126086656501e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:96, Validation Loss:8.287674560721592e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:97, Validation Loss:8.281064314262e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:98, Validation Loss:8.232891296270316e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:99, Validation Loss:8.178361014991961e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:100, Validation Loss:8.218372630391734e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:101, Validation Loss:8.214256418201589e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:102, Validation Loss:8.237153362584648e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:103, Validation Loss:8.303637749364725e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:104, Validation Loss:8.29039258082746e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:105, Validation Loss:8.252342111678842e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:106, Validation Loss:8.245223745759213e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:107, Validation Loss:8.199012927340736e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:108, Validation Loss:8.239292504772614e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:109, Validation Loss:8.21794662358169e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:110, Validation Loss:8.216980293538866e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:111, Validation Loss:8.242973090843974e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:112, Validation Loss:8.18987735675073e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:113, Validation Loss:8.16705648390589e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:114, Validation Loss:8.215102003459151e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:115, Validation Loss:8.169404059939974e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:116, Validation Loss:8.243714923879382e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:117, Validation Loss:8.305408801965494e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:118, Validation Loss:8.312113847409796e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:119, Validation Loss:8.316865615538276e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:120, Validation Loss:8.330696570546904e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:121, Validation Loss:8.286808714504553e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:122, Validation Loss:8.298982344714002e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:123, Validation Loss:8.285211413572327e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:124, Validation Loss:8.266102354699691e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:125, Validation Loss:8.237545647598987e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:126, Validation Loss:8.235813351053732e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:127, Validation Loss:8.24344381737115e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:128, Validation Loss:8.223550172979807e-06,Acc:99.7671%,lr:1e-05\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:8.986855302345299e-06 Acc:0.9978710664626439==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.003188596927479636,Acc:23.9172%,lr:0.001\n",
      "Episode:2, Validation Loss:0.006326094778321173,Acc:15.7142%,lr:0.001\n",
      "Episode:3, Validation Loss:0.013852811527461572,Acc:9.9727%,lr:0.001\n",
      "Episode:4, Validation Loss:0.014909127048687595,Acc:10.0858%,lr:0.001\n",
      "Episode:5, Validation Loss:0.025350293033922926,Acc:10.1524%,lr:0.001\n",
      "Episode:6, Validation Loss:0.004145397491840837,Acc:42.6519%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00253419192138209,Acc:55.7847%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0007911071148582359,Acc:80.8130%,lr:0.001\n",
      "Episode:9, Validation Loss:8.23832432212218e-05,Acc:97.9775%,lr:0.001\n",
      "Episode:10, Validation Loss:6.85169250932919e-05,Acc:98.1239%,lr:0.001\n",
      "Episode:11, Validation Loss:5.640839254116157e-05,Acc:98.5896%,lr:0.001\n",
      "Episode:12, Validation Loss:4.303365287551718e-05,Acc:98.9156%,lr:0.001\n",
      "Episode:13, Validation Loss:4.199970054829496e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:14, Validation Loss:3.7660026332589885e-05,Acc:98.9954%,lr:0.001\n",
      "Episode:15, Validation Loss:3.632414134571346e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:16, Validation Loss:4.02595348198664e-05,Acc:98.8490%,lr:0.001\n",
      "Episode:17, Validation Loss:3.493422081363264e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:18, Validation Loss:4.558081237207542e-05,Acc:98.7892%,lr:0.001\n",
      "Episode:19, Validation Loss:3.435124392394383e-05,Acc:99.0952%,lr:0.001\n",
      "Episode:20, Validation Loss:3.886902579055893e-05,Acc:98.9355%,lr:0.001\n",
      "Episode:21, Validation Loss:3.6850607817095755e-05,Acc:99.0154%,lr:0.001\n",
      "Episode:22, Validation Loss:3.1875940260951546e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:23, Validation Loss:0.0001345597255627288,Acc:95.6157%,lr:0.001\n",
      "Episode:24, Validation Loss:4.034009140338514e-05,Acc:98.9555%,lr:0.001\n",
      "Episode:25, Validation Loss:2.9877666514097957e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:26, Validation Loss:2.935908861940599e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:27, Validation Loss:3.790652401575301e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:28, Validation Loss:4.094397010607964e-05,Acc:98.9023%,lr:0.001\n",
      "Episode:29, Validation Loss:3.211481108697428e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:30, Validation Loss:2.6280059109337036e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:31, Validation Loss:2.5145547612822466e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:32, Validation Loss:3.037794839062144e-05,Acc:99.1551%,lr:0.001\n",
      "Episode:33, Validation Loss:2.5951969055317015e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:34, Validation Loss:2.328623963569375e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:35, Validation Loss:3.026095132522102e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:36, Validation Loss:3.4268997997733524e-05,Acc:98.9289%,lr:0.001\n",
      "Episode:37, Validation Loss:2.1672711595689676e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:38, Validation Loss:2.3993197859511326e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:39, Validation Loss:2.28160161007768e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:40, Validation Loss:2.755244488608979e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:41, Validation Loss:2.702196544356851e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:42, Validation Loss:2.8132404070058813e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:43, Validation Loss:2.531113250373279e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:44, Validation Loss:2.5500443102110965e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:45, Validation Loss:2.3034881243019885e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:46, Validation Loss:2.5589063299661084e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:47, Validation Loss:2.3575058621676903e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:48, Validation Loss:2.5727316775838104e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:49, Validation Loss:2.3333463347185776e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:50, Validation Loss:1.858505618349377e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:51, Validation Loss:1.7561885103158043e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:52, Validation Loss:2.0881613262811114e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:53, Validation Loss:2.3096917450773003e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:54, Validation Loss:2.58656488174482e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:55, Validation Loss:2.0222902889321024e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:56, Validation Loss:2.26214995510952e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:57, Validation Loss:2.4298491545914256e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:58, Validation Loss:2.3786922518118566e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:59, Validation Loss:1.801084473012379e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:60, Validation Loss:2.29123002076195e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:61, Validation Loss:1.8623817443657314e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:62, Validation Loss:2.394094459717958e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:63, Validation Loss:1.852736362804395e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:64, Validation Loss:2.372223593522138e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:65, Validation Loss:2.000869652855524e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:66, Validation Loss:2.0471962251715392e-05,Acc:99.4145%,lr:0.001\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:67, Validation Loss:2.682639811219954e-05,Acc:99.2349%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.684504758593137e-05,Acc:99.4744%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.4917929554259608e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.4669323925829309e-05,Acc:99.5476%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.4489910031654157e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.4161979370044698e-05,Acc:99.5875%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.3576981387687937e-05,Acc:99.5875%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.3663399135296743e-05,Acc:99.6008%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.4089990167318882e-05,Acc:99.5809%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.3142401233189565e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.3549569285387416e-05,Acc:99.6008%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.3756536039767346e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.3390512450836542e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.2670178880268058e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.24440959880717e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.2957045952058046e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.302340189550786e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.322244497278907e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.2570578590314011e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.2898895387395827e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.2659091844695762e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.2367690887541821e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.2016290042002388e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.1993229786231128e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.2277693285527925e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.239064581110785e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.2353432872401098e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.2342760597876934e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.2474011139839235e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.2833227418146481e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.3461767673972251e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.2586974725300708e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.2561019940529665e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.2448257229779583e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.2701578054377105e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.1965067889019684e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.2275875065785255e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.2978659222149958e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.266203724295466e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.2735499377160379e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.2495279632839373e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.2785802769982943e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.2115154571012856e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.2923982776946813e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.210344178469133e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.2214352259592464e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.2058681669559445e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.2761632405708716e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.2292094707368067e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.2208855142191724e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.1869465064684413e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.24284057027803e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.219439205454143e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.2570006543499419e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.2877134466336227e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.2513169564376627e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.2326440131687672e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.2286158029380875e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.236585717776897e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.2578672549314512e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.2663868412362562e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.2198916413536821e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.2196507094242434e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.1846985808965189e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.2577756515399685e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.2536706510336684e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.2478889569944508e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.2024663363697207e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.1895959367206667e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.1994860266808002e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:137, Validation Loss:1.2167604835548449e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:138, Validation Loss:1.18955723023325e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:139, Validation Loss:1.1457446619335918e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.1399957417002314e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:141, Validation Loss:1.1646447541030705e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:142, Validation Loss:1.1620242793642628e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:143, Validation Loss:1.2162328993228847e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:144, Validation Loss:1.2104653290931863e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:145, Validation Loss:1.2544249628373911e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:146, Validation Loss:1.181094506280237e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:147, Validation Loss:1.2191280510218808e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:148, Validation Loss:1.2117065854856857e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:149, Validation Loss:1.2243604933749209e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:150, Validation Loss:1.1866621157103261e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:151, Validation Loss:1.1767805731488468e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:152, Validation Loss:1.1762527937425063e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:153, Validation Loss:1.1836324888633147e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:154, Validation Loss:1.1807710186859447e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:155, Validation Loss:1.2492212637843553e-05,Acc:99.6873%,lr:0.0001\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:156, Validation Loss:1.150027212263835e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:157, Validation Loss:1.1182180170558913e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:158, Validation Loss:1.119093714932126e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:159, Validation Loss:1.1068291551475079e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:160, Validation Loss:1.105690690595291e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:161, Validation Loss:1.1056328601166125e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:162, Validation Loss:1.1051199635312702e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:163, Validation Loss:1.1046507240469905e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:164, Validation Loss:1.102446963649121e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:165, Validation Loss:1.1150658237960681e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:166, Validation Loss:1.1114357290270878e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:167, Validation Loss:1.1156437165480509e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:168, Validation Loss:1.1176411032738161e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:169, Validation Loss:1.1220649025422728e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:170, Validation Loss:1.1238661777409288e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:171, Validation Loss:1.1236053597107435e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:172, Validation Loss:1.1297450965035819e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:173, Validation Loss:1.1290415981948657e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:174, Validation Loss:1.1298918738335671e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:175, Validation Loss:1.1287735153405254e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:176, Validation Loss:1.1167387532516516e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:177, Validation Loss:1.1152186701198783e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:178, Validation Loss:1.1182534551469399e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:179, Validation Loss:1.1230654144346987e-05,Acc:99.7139%,lr:1e-05\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:1.1230654144346987e-05 Acc:0.9971392455591777==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0038964238584608653,Acc:10.1856%,lr:0.001\n",
      "Episode:2, Validation Loss:0.008962287532300595,Acc:10.0526%,lr:0.001\n",
      "Episode:3, Validation Loss:0.006443864324835038,Acc:13.5054%,lr:0.001\n",
      "Episode:4, Validation Loss:0.008179012152909297,Acc:17.4040%,lr:0.001\n",
      "Episode:5, Validation Loss:0.003398005528234609,Acc:46.3176%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0015110245849246965,Acc:69.4099%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00027196682698632594,Acc:92.7084%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0001082509115668449,Acc:97.1193%,lr:0.001\n",
      "Episode:9, Validation Loss:4.9737453417073434e-05,Acc:98.7093%,lr:0.001\n",
      "Episode:10, Validation Loss:3.930523953913024e-05,Acc:98.8890%,lr:0.001\n",
      "Episode:11, Validation Loss:3.831358106639458e-05,Acc:98.8890%,lr:0.001\n",
      "Episode:12, Validation Loss:2.8971052768185865e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:13, Validation Loss:3.180745251758807e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:14, Validation Loss:3.5459765070578065e-05,Acc:98.9755%,lr:0.001\n",
      "Episode:15, Validation Loss:3.3834333933741656e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:16, Validation Loss:3.592696804960968e-05,Acc:98.8890%,lr:0.001\n",
      "Episode:17, Validation Loss:2.869989080564616e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:18, Validation Loss:3.042776891273317e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:19, Validation Loss:2.0208795685114144e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:20, Validation Loss:2.901050869424292e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:21, Validation Loss:3.2077593563218594e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:22, Validation Loss:1.8516140202755906e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:23, Validation Loss:2.149012348452979e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:24, Validation Loss:2.751992214264155e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:25, Validation Loss:1.9346986046019654e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:26, Validation Loss:2.3722831310021425e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6715499533641584e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:28, Validation Loss:3.391324467057359e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:29, Validation Loss:2.0949930863683077e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:30, Validation Loss:2.046041393853433e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:31, Validation Loss:2.302408314298056e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:32, Validation Loss:2.587989617544816e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:33, Validation Loss:1.873734034312857e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:34, Validation Loss:1.697448869099811e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:35, Validation Loss:1.9955002383616035e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:36, Validation Loss:2.3906640562220618e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:37, Validation Loss:1.811819974741737e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:38, Validation Loss:1.8389536189657036e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:39, Validation Loss:1.6930237919038646e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:40, Validation Loss:2.0765731045862895e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:41, Validation Loss:1.8959918445606097e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:42, Validation Loss:1.9954554845664038e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:43, Validation Loss:1.5650609128093394e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:44, Validation Loss:1.3357401303101836e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:45, Validation Loss:1.670388879969356e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:46, Validation Loss:2.200323767381612e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:47, Validation Loss:1.4812500288498218e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:48, Validation Loss:1.5279577705345185e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:49, Validation Loss:1.6988798876560486e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:50, Validation Loss:1.6107588098584263e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:51, Validation Loss:1.4993465292335596e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:52, Validation Loss:2.0049932228100054e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:53, Validation Loss:1.499804392839674e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:54, Validation Loss:2.237443592418938e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:55, Validation Loss:1.4847028495173962e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:56, Validation Loss:1.6182031975412835e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:57, Validation Loss:1.4627598617410526e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:58, Validation Loss:1.920542402331617e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:59, Validation Loss:1.3108491357538596e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:60, Validation Loss:2.366672660658542e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:61, Validation Loss:1.49260954644503e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:62, Validation Loss:1.922416079480343e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:63, Validation Loss:1.3648082624433617e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:64, Validation Loss:1.6940195375140037e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:65, Validation Loss:1.1940563435774507e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:66, Validation Loss:1.4583810718532935e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:67, Validation Loss:1.3228891148848985e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:68, Validation Loss:1.327242894569927e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:69, Validation Loss:1.3897531034426016e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:70, Validation Loss:1.2427621721372769e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:71, Validation Loss:1.3013926582085888e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:72, Validation Loss:1.2192239962688234e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5056003903727611e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:74, Validation Loss:1.1770530365837222e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:75, Validation Loss:1.43904976822363e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:76, Validation Loss:1.192231498748871e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:77, Validation Loss:1.3831662345365583e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:78, Validation Loss:1.2429122302556545e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:79, Validation Loss:1.2594121856206383e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:80, Validation Loss:1.6299944098856182e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:81, Validation Loss:1.1705518926027078e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:82, Validation Loss:1.3854931344783565e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:83, Validation Loss:1.8182826817618596e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:84, Validation Loss:1.6019963259393524e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:85, Validation Loss:1.3031502468751248e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:86, Validation Loss:1.2012396127235373e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:87, Validation Loss:1.2486557041944029e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:88, Validation Loss:1.1332862227352133e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:89, Validation Loss:1.1573965786325187e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:90, Validation Loss:1.2187648376961857e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:91, Validation Loss:1.5158743232807851e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:92, Validation Loss:1.1183626877417718e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:93, Validation Loss:1.2941869935768663e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:94, Validation Loss:1.2225815145257077e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:95, Validation Loss:1.2598403176628229e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:96, Validation Loss:1.7001570747225562e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:97, Validation Loss:1.3131070864733152e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:98, Validation Loss:1.28797648283613e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:99, Validation Loss:1.2771957130425704e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:100, Validation Loss:1.2099307371715722e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:101, Validation Loss:1.4874713671216548e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:102, Validation Loss:1.0977294501733831e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:103, Validation Loss:1.4032333734619444e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:104, Validation Loss:1.2945971262039805e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:105, Validation Loss:1.2039564215090451e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:106, Validation Loss:1.1759271143089432e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:107, Validation Loss:1.1105693902270887e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:108, Validation Loss:1.4955403407034733e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:109, Validation Loss:9.649009109544672e-06,Acc:99.6740%,lr:0.001\n",
      "Episode:110, Validation Loss:1.2974774028269935e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:111, Validation Loss:1.2047980072408146e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:112, Validation Loss:1.2087451178694777e-05,Acc:99.6540%,lr:0.001\n",
      "Episode:113, Validation Loss:1.930142782257271e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:114, Validation Loss:1.2379616878638763e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:115, Validation Loss:1.0871773442053587e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:116, Validation Loss:1.0467183163228344e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:117, Validation Loss:1.3609161197357997e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:118, Validation Loss:3.630056192609065e-05,Acc:98.9755%,lr:0.001\n",
      "Episode:119, Validation Loss:1.4440607093410906e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:120, Validation Loss:1.4957325038218894e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:121, Validation Loss:1.2606727735708037e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:122, Validation Loss:1.5232050110441063e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:123, Validation Loss:9.510007619810202e-06,Acc:99.6740%,lr:0.001\n",
      "Episode:124, Validation Loss:1.1075148739995821e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:125, Validation Loss:1.0528844620681287e-05,Acc:99.6873%,lr:0.001\n",
      "Episode:126, Validation Loss:1.1279800447405047e-05,Acc:99.6540%,lr:0.001\n",
      "Episode:127, Validation Loss:1.3687732113907814e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:128, Validation Loss:1.130301393055486e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:129, Validation Loss:1.1074621552308633e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:130, Validation Loss:1.1423924645020746e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:131, Validation Loss:1.24198766753021e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:132, Validation Loss:9.546137371686442e-06,Acc:99.7006%,lr:0.001\n",
      "Episode:133, Validation Loss:1.0207337612627857e-05,Acc:99.6740%,lr:0.001\n",
      "Episode:134, Validation Loss:1.4001458510781277e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:135, Validation Loss:1.2751808566607668e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:136, Validation Loss:1.3779776816350338e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:137, Validation Loss:9.623364559098098e-06,Acc:99.7006%,lr:0.001\n",
      "Episode:138, Validation Loss:1.1553367283600476e-05,Acc:99.6807%,lr:0.001\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:139, Validation Loss:1.2722932114303965e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.0265764643348751e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:141, Validation Loss:9.155448233196576e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:142, Validation Loss:8.884503626760375e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:143, Validation Loss:8.672531176187204e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:144, Validation Loss:8.644221473107771e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:145, Validation Loss:8.663933341994938e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:146, Validation Loss:9.057841091896038e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:147, Validation Loss:8.686371673054422e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:148, Validation Loss:8.346007133238442e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:149, Validation Loss:8.51941944619994e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:150, Validation Loss:8.564694140134445e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:151, Validation Loss:8.383746732971355e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:152, Validation Loss:8.382092955389087e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:153, Validation Loss:8.174739322015352e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:154, Validation Loss:8.453782487991018e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:155, Validation Loss:8.37328547912835e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:156, Validation Loss:8.45727279453163e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:157, Validation Loss:8.016379569802692e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:158, Validation Loss:8.054981468535732e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:159, Validation Loss:8.080026678734534e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:160, Validation Loss:8.094771979244699e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:161, Validation Loss:8.197497057497172e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:162, Validation Loss:8.365836912235349e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:163, Validation Loss:8.282933062483122e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:164, Validation Loss:8.069826060139358e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:165, Validation Loss:8.485925415899216e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:166, Validation Loss:7.984395972344937e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:167, Validation Loss:8.307498112726368e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:168, Validation Loss:8.309956132675642e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:169, Validation Loss:8.64126910433529e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:170, Validation Loss:8.461177180559047e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:171, Validation Loss:7.934735090484259e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:172, Validation Loss:8.269581492928543e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:173, Validation Loss:8.387469235064383e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:174, Validation Loss:8.580611726128724e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:175, Validation Loss:8.6872006375096e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:176, Validation Loss:8.812421236012988e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:177, Validation Loss:8.844191628695327e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:178, Validation Loss:8.486885302089485e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:179, Validation Loss:7.881940234737254e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:180, Validation Loss:8.169298913615105e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:181, Validation Loss:8.82781937933517e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:182, Validation Loss:8.46319212368502e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:183, Validation Loss:8.137813134747315e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:184, Validation Loss:8.033942227982276e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:185, Validation Loss:8.236329014158464e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:186, Validation Loss:8.535165619520233e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:187, Validation Loss:8.611985728938727e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:188, Validation Loss:8.419905946884998e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:189, Validation Loss:8.358625993385389e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:190, Validation Loss:8.40111802731808e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:191, Validation Loss:7.991152971350466e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:192, Validation Loss:8.42251400326661e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:193, Validation Loss:7.919781944749122e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:194, Validation Loss:8.421335490790362e-06,Acc:99.7139%,lr:0.0001\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:195, Validation Loss:8.403626482805625e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:196, Validation Loss:8.27034282791195e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:197, Validation Loss:8.314742211220976e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:198, Validation Loss:8.316309151694046e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:199, Validation Loss:8.307086759484874e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:200, Validation Loss:8.257117935824193e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:201, Validation Loss:8.25415930907952e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:202, Validation Loss:8.244133263124486e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:203, Validation Loss:8.259848239523995e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:204, Validation Loss:8.249682504476786e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:205, Validation Loss:8.321610180802722e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:206, Validation Loss:8.314096431862721e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:207, Validation Loss:8.33864311093017e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:208, Validation Loss:8.329045395289708e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:209, Validation Loss:8.255771945141626e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:210, Validation Loss:8.240226491632421e-06,Acc:99.7339%,lr:1e-05\n",
      "Epoch   210: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:7.991152971350466e-06 Acc:0.9978045372896015==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10157\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10157_s6.npy\n",
      "shape of top1_dig_csv: (10157, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10157_s6.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s6.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10157, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75157, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75157_s6.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75157_s6.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step5\n",
      "Step: 6\n",
      "global_data len: 75157\n",
      "validation rate: 0.19999467780778904\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.002612084481429216,Acc:15.1221%,lr:0.001\n",
      "Episode:2, Validation Loss:0.0025674932913963893,Acc:38.9329%,lr:0.001\n",
      "Episode:3, Validation Loss:0.005334657059086352,Acc:23.5380%,lr:0.001\n",
      "Episode:4, Validation Loss:0.007693162927861683,Acc:19.3400%,lr:0.001\n",
      "Episode:5, Validation Loss:0.008244008886608707,Acc:22.3072%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0034400744555865875,Acc:53.0371%,lr:0.001\n",
      "Episode:7, Validation Loss:0.002900330973245706,Acc:54.6271%,lr:0.001\n",
      "Episode:8, Validation Loss:0.000306088443914658,Acc:91.9034%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0005056502580182709,Acc:88.2110%,lr:0.001\n",
      "Episode:10, Validation Loss:0.000285978755363407,Acc:92.2227%,lr:0.001\n",
      "Episode:11, Validation Loss:7.1940856730658e-05,Acc:98.1438%,lr:0.001\n",
      "Episode:12, Validation Loss:5.1611986978588116e-05,Acc:98.4898%,lr:0.001\n",
      "Episode:13, Validation Loss:7.612865950309241e-05,Acc:97.8578%,lr:0.001\n",
      "Episode:14, Validation Loss:3.701607293909272e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:15, Validation Loss:4.3176489046143244e-05,Acc:98.8224%,lr:0.001\n",
      "Episode:16, Validation Loss:3.3658153366506413e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:17, Validation Loss:2.959550266468186e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:18, Validation Loss:2.8596918599452176e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:19, Validation Loss:3.025361828297311e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:20, Validation Loss:3.376125884892008e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:21, Validation Loss:3.393343524335348e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:22, Validation Loss:2.1503119743772075e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:23, Validation Loss:2.1383064078972192e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:24, Validation Loss:3.176618521838169e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:25, Validation Loss:2.5230333780062255e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:26, Validation Loss:2.96388978603143e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:27, Validation Loss:2.375329592413955e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:28, Validation Loss:2.661731591537782e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:29, Validation Loss:2.394063975338561e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:30, Validation Loss:2.0278922676411577e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:31, Validation Loss:2.656561366439968e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:32, Validation Loss:2.4377708861423533e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:33, Validation Loss:2.4991781924741012e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:34, Validation Loss:2.0062263593286838e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:35, Validation Loss:2.838885632817771e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:36, Validation Loss:2.686812001281168e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:37, Validation Loss:1.781807846091249e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:38, Validation Loss:2.202551100507411e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:39, Validation Loss:1.6283618474486868e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:40, Validation Loss:1.3932635315324198e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:41, Validation Loss:2.2167353242423576e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:42, Validation Loss:2.142954699526083e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:43, Validation Loss:2.032395104788614e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:44, Validation Loss:1.7855634008106788e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:45, Validation Loss:1.668798391552403e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:46, Validation Loss:1.3743490181448422e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:47, Validation Loss:1.9791889949363115e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:48, Validation Loss:1.8228726565250973e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:49, Validation Loss:1.712291995346582e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8028764588399352e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:51, Validation Loss:1.7078748025759974e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:52, Validation Loss:1.7924479261366846e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:53, Validation Loss:1.6484502975575964e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:54, Validation Loss:2.2013092245137046e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:55, Validation Loss:1.7524075178688108e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:56, Validation Loss:1.4546093207583061e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6773075019497965e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:58, Validation Loss:1.576480122784854e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:59, Validation Loss:1.7413592600380697e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:60, Validation Loss:1.6914563154757488e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:61, Validation Loss:1.6911471127872894e-05,Acc:99.4412%,lr:0.001\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:62, Validation Loss:1.7746360891355932e-05,Acc:99.4278%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.2231531353644702e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.1171343314464074e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.0846059155491138e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.0873892818963042e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.0605552334440784e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.0157096660116952e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.067343503722538e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:70, Validation Loss:9.827063908471723e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:71, Validation Loss:9.423179401891625e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.0026028699140399e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:73, Validation Loss:9.864321117684732e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:74, Validation Loss:9.2674723173475e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:75, Validation Loss:9.493273647265253e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:76, Validation Loss:9.104120964869063e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:77, Validation Loss:8.65779284619062e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:78, Validation Loss:8.957329941697245e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:79, Validation Loss:8.770502720447757e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:80, Validation Loss:8.704133997723043e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:81, Validation Loss:9.50053726319789e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:82, Validation Loss:8.540519810412492e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:83, Validation Loss:8.448414294111476e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:84, Validation Loss:8.407519189350286e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:85, Validation Loss:8.75978673305842e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.68962894758099e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:87, Validation Loss:8.989475502910573e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:88, Validation Loss:8.457712417078203e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:89, Validation Loss:8.186739192811242e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:90, Validation Loss:8.660215703771387e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:91, Validation Loss:8.724370513932449e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:92, Validation Loss:8.472743694525573e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:93, Validation Loss:8.398904749845667e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:94, Validation Loss:8.39344542811857e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.827056557308865e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:96, Validation Loss:8.782553530207898e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:97, Validation Loss:8.520137594979201e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.153280511902926e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:99, Validation Loss:8.91455812683942e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.38442590883468e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:101, Validation Loss:8.653992103955146e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.00760339229147e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:103, Validation Loss:8.673225501300046e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:104, Validation Loss:8.75772318221774e-06,Acc:99.7272%,lr:0.0001\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:105, Validation Loss:8.71401835637201e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:106, Validation Loss:8.550156220148347e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:107, Validation Loss:8.494959619731715e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:108, Validation Loss:8.513505770907566e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:109, Validation Loss:8.487387380437749e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:110, Validation Loss:8.494245482870272e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:111, Validation Loss:8.315889821087011e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:112, Validation Loss:8.359072586445544e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:113, Validation Loss:8.344332753916034e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:114, Validation Loss:8.384208661161388e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:115, Validation Loss:8.32904827643532e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:116, Validation Loss:8.469676079928545e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:117, Validation Loss:8.451857092729523e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:118, Validation Loss:8.481832903455248e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:119, Validation Loss:8.425456210579291e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:120, Validation Loss:8.400677552819847e-06,Acc:99.7272%,lr:1e-05\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:8.71401835637201e-06 Acc:0.9974053622513472==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.003686068562577485,Acc:13.9512%,lr:0.001\n",
      "Episode:2, Validation Loss:0.00727595915599907,Acc:10.3120%,lr:0.001\n",
      "Episode:3, Validation Loss:0.01028851991356129,Acc:12.1416%,lr:0.001\n",
      "Episode:4, Validation Loss:0.020994651342182213,Acc:10.3054%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0187478957875079,Acc:10.7644%,lr:0.001\n",
      "Episode:6, Validation Loss:0.016401954297097524,Acc:13.6518%,lr:0.001\n",
      "Episode:7, Validation Loss:0.002285959366735017,Acc:67.1745%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00657795739898773,Acc:37.9150%,lr:0.001\n",
      "Episode:9, Validation Loss:4.630366727034653e-05,Acc:98.7493%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00011642128090350565,Acc:96.6935%,lr:0.001\n",
      "Episode:11, Validation Loss:8.60881853203567e-05,Acc:97.8511%,lr:0.001\n",
      "Episode:12, Validation Loss:3.824650056129301e-05,Acc:98.9555%,lr:0.001\n",
      "Episode:13, Validation Loss:8.627112431168025e-05,Acc:97.3521%,lr:0.001\n",
      "Episode:14, Validation Loss:3.393749809238965e-05,Acc:98.9688%,lr:0.001\n",
      "Episode:15, Validation Loss:2.440029357326823e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:16, Validation Loss:2.874685738263718e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:17, Validation Loss:3.2928826114024384e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:18, Validation Loss:4.551997013584867e-05,Acc:98.5962%,lr:0.001\n",
      "Episode:19, Validation Loss:2.7456496107420454e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:20, Validation Loss:2.4685102190437466e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:21, Validation Loss:2.508948231602324e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:22, Validation Loss:2.6517121567276296e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:23, Validation Loss:1.8545494026809735e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:24, Validation Loss:2.7439125711495476e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:25, Validation Loss:3.8458256337324004e-05,Acc:98.8690%,lr:0.001\n",
      "Episode:26, Validation Loss:3.778096183110406e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:27, Validation Loss:1.7437281844317496e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:28, Validation Loss:1.8864873789018376e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:29, Validation Loss:1.8632814115146686e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:30, Validation Loss:2.2538150177094905e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:31, Validation Loss:1.884758896002012e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:32, Validation Loss:1.536630833607362e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:33, Validation Loss:2.033206546921651e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:34, Validation Loss:1.4755523868123735e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:35, Validation Loss:1.972941202790935e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:36, Validation Loss:1.7531174011679674e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:37, Validation Loss:1.8116861594690075e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:38, Validation Loss:1.6261817341308918e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:39, Validation Loss:2.1115940615141213e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:40, Validation Loss:1.8482531887012505e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:41, Validation Loss:1.74261479514039e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:42, Validation Loss:2.101567333997759e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:43, Validation Loss:1.494856325754719e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:44, Validation Loss:1.582194803855502e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:45, Validation Loss:2.2948220472327567e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:46, Validation Loss:1.7459334845386194e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:47, Validation Loss:2.19197414543297e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:48, Validation Loss:1.5079831969314893e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:49, Validation Loss:1.2358001656803048e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:50, Validation Loss:2.095633877936844e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:51, Validation Loss:1.316116161148282e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:52, Validation Loss:1.7894288387062086e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:53, Validation Loss:2.233036926672865e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:54, Validation Loss:1.4531642093726098e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:55, Validation Loss:1.4547860248266013e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:56, Validation Loss:1.2907279180351048e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:57, Validation Loss:1.2300071081549462e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:58, Validation Loss:1.1420536727579632e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:59, Validation Loss:1.2182676015313565e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:60, Validation Loss:1.2694005691162896e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5812699251334417e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:62, Validation Loss:1.3504518701209573e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:63, Validation Loss:1.5646181395906277e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:64, Validation Loss:1.332400114238401e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:65, Validation Loss:1.1821678662356023e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:66, Validation Loss:1.507094617546156e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:67, Validation Loss:1.1581870100886179e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:68, Validation Loss:1.5831873523234115e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:69, Validation Loss:1.811693631859567e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:70, Validation Loss:1.498701989077719e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:71, Validation Loss:1.3708584389796982e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:72, Validation Loss:1.2142634535135603e-05,Acc:99.6740%,lr:0.001\n",
      "Episode:73, Validation Loss:2.0258955129086236e-05,Acc:99.3480%,lr:0.001\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:74, Validation Loss:1.219254821428884e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:75, Validation Loss:9.969855003109966e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:76, Validation Loss:9.5542012335583e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:77, Validation Loss:9.013649615772104e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:78, Validation Loss:8.45404684084609e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:79, Validation Loss:8.767116863180655e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:80, Validation Loss:8.834221501749248e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:81, Validation Loss:8.918962685941389e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:82, Validation Loss:8.532165324594373e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:83, Validation Loss:8.349059071924926e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:84, Validation Loss:8.108354071428434e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:85, Validation Loss:7.849739869797144e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.195692592901303e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:87, Validation Loss:7.5492967314451615e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:88, Validation Loss:8.09913480820536e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:89, Validation Loss:7.667069072856152e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:90, Validation Loss:7.814445867009304e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:91, Validation Loss:7.5903059357686655e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:92, Validation Loss:7.843724533436691e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:93, Validation Loss:8.226438351067215e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:94, Validation Loss:7.791368324364361e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:95, Validation Loss:7.95627905818114e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:96, Validation Loss:7.310363883341583e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:97, Validation Loss:7.937401761140075e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:98, Validation Loss:7.679154952044624e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:99, Validation Loss:7.531782588040105e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:100, Validation Loss:7.696776193518353e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:101, Validation Loss:7.92072110527901e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:102, Validation Loss:7.643244631935932e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:103, Validation Loss:7.87922077405858e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:104, Validation Loss:7.696130662000581e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:105, Validation Loss:7.914614129900004e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:106, Validation Loss:7.578016238763069e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:107, Validation Loss:7.922662501741681e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:108, Validation Loss:7.853441987010455e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:109, Validation Loss:7.711817322624918e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:110, Validation Loss:7.991319767995459e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:111, Validation Loss:7.231946318090561e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:112, Validation Loss:6.990055369903336e-06,Acc:99.7938%,lr:0.0001\n",
      "Episode:113, Validation Loss:8.057812519391832e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:114, Validation Loss:6.987704757823336e-06,Acc:99.8004%,lr:0.0001\n",
      "Episode:115, Validation Loss:7.396598740164038e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:116, Validation Loss:7.5568142909325885e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:117, Validation Loss:7.3841296995890034e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:118, Validation Loss:7.1097640270470986e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:119, Validation Loss:7.49344454648117e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:120, Validation Loss:7.681465537886635e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:121, Validation Loss:7.614927710502433e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:122, Validation Loss:7.030358693551481e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:123, Validation Loss:7.487821200824484e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:124, Validation Loss:7.589325354898073e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:125, Validation Loss:7.5207542132121046e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:126, Validation Loss:7.822796511299936e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:127, Validation Loss:7.472545428740733e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:128, Validation Loss:7.851431164232511e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:129, Validation Loss:7.597908101800943e-06,Acc:99.7538%,lr:0.0001\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:130, Validation Loss:7.3827616820835195e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:131, Validation Loss:7.388159461920708e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:132, Validation Loss:7.475037712636771e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:133, Validation Loss:7.439087180409728e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:134, Validation Loss:7.482300306227415e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:135, Validation Loss:7.4667431112753325e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:136, Validation Loss:7.401185183200395e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:137, Validation Loss:7.348919528844503e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:138, Validation Loss:7.309199218952317e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:139, Validation Loss:7.2824113493780676e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:140, Validation Loss:7.395963122265582e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:141, Validation Loss:7.4608005160966104e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:142, Validation Loss:7.4973157528639395e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:143, Validation Loss:7.525939934536112e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:144, Validation Loss:7.406325146975247e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:145, Validation Loss:7.433793524555417e-06,Acc:99.7605%,lr:1e-05\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:6.987704757823336e-06 Acc:0.9980041248087286==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0025213616518161863,Acc:15.2551%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005303836362137147,Acc:17.1246%,lr:0.001\n",
      "Episode:3, Validation Loss:0.013486512715639956,Acc:9.9328%,lr:0.001\n",
      "Episode:4, Validation Loss:0.015625005393008908,Acc:10.2255%,lr:0.001\n",
      "Episode:5, Validation Loss:0.009119835722177585,Acc:16.5192%,lr:0.001\n",
      "Episode:6, Validation Loss:0.010556050145089146,Acc:19.5995%,lr:0.001\n",
      "Episode:7, Validation Loss:0.005170488792157016,Acc:41.4876%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00013006509974223157,Acc:96.6735%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0003835571719519782,Acc:91.6839%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00011675741505411902,Acc:96.8864%,lr:0.001\n",
      "Episode:11, Validation Loss:0.00014917508454691125,Acc:96.1080%,lr:0.001\n",
      "Episode:12, Validation Loss:0.00022983707561439624,Acc:95.0768%,lr:0.001\n",
      "Episode:13, Validation Loss:2.9810449696730792e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:14, Validation Loss:3.632539312603247e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:15, Validation Loss:3.265693240245892e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:16, Validation Loss:2.5801410794845005e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:17, Validation Loss:3.2973405677364474e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:18, Validation Loss:2.7103033507883837e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:19, Validation Loss:3.5968177540023426e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:20, Validation Loss:3.158719367536946e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:21, Validation Loss:2.454606925594173e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:22, Validation Loss:2.3240024882807607e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:23, Validation Loss:2.8067531761699758e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:24, Validation Loss:4.2851567322896486e-05,Acc:98.7226%,lr:0.001\n",
      "Episode:25, Validation Loss:2.6914558751534245e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:26, Validation Loss:1.9545551937431103e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:27, Validation Loss:2.3881651054170347e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:28, Validation Loss:1.9770425724341605e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:29, Validation Loss:1.9767288125788218e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:30, Validation Loss:1.9270002145022024e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:31, Validation Loss:2.024453942543827e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:32, Validation Loss:2.5976595941760742e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:33, Validation Loss:2.658316808188321e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:34, Validation Loss:1.9785220778828712e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:35, Validation Loss:2.3645300518018217e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:36, Validation Loss:1.835490711190475e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:37, Validation Loss:2.2074719640013622e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:38, Validation Loss:3.103307771697411e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:39, Validation Loss:1.9887408043233294e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9820199590482427e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:41, Validation Loss:2.2841244031371618e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:42, Validation Loss:1.7466348762032307e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:43, Validation Loss:1.6486603640528958e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:44, Validation Loss:1.70282702306876e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:45, Validation Loss:1.856597423217395e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:46, Validation Loss:1.6463746366113192e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:47, Validation Loss:2.437396386780668e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:48, Validation Loss:1.6333893412123993e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:49, Validation Loss:1.4171621185801087e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:50, Validation Loss:1.738881865159043e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:51, Validation Loss:1.682537252135591e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:52, Validation Loss:2.3986385096397144e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:53, Validation Loss:1.5788139653581795e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:54, Validation Loss:1.7448096580649236e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:55, Validation Loss:1.6474827159203326e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:56, Validation Loss:2.1041104747608872e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6717633939934987e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:58, Validation Loss:1.5679154186691403e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:59, Validation Loss:1.6314924971745343e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:60, Validation Loss:2.093265898435005e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:61, Validation Loss:1.542973192386995e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:62, Validation Loss:1.2702020759439684e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:63, Validation Loss:2.1322804267880254e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:64, Validation Loss:1.4723133843254086e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:65, Validation Loss:1.8777065331009872e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:66, Validation Loss:1.5596259754877527e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:67, Validation Loss:1.1444956233499293e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:68, Validation Loss:1.1454163894689764e-05,Acc:99.6674%,lr:0.001\n",
      "Episode:69, Validation Loss:1.2218474838185014e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:70, Validation Loss:1.545119552929025e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:71, Validation Loss:1.564311289837753e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:72, Validation Loss:2.12213834811491e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5181033448198742e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:74, Validation Loss:1.52831333488331e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:75, Validation Loss:1.2610695073218111e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:76, Validation Loss:1.2805259022392062e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:77, Validation Loss:1.7562849481457062e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:78, Validation Loss:1.3672071755354724e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:79, Validation Loss:1.4388617781193447e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:80, Validation Loss:1.353459143305414e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:81, Validation Loss:1.4667263442014602e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:82, Validation Loss:1.649745691605579e-05,Acc:99.5476%,lr:0.001\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:83, Validation Loss:1.3243038658114396e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0458679802730152e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.828014841424547e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:86, Validation Loss:9.473789931032624e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.474592330086041e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.613411873926001e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:89, Validation Loss:9.170747797966685e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:90, Validation Loss:9.569685656348592e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:91, Validation Loss:9.823685780729683e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.406730879622855e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.097728508233818e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.683998857159694e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:95, Validation Loss:9.333048136407295e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.648464882824285e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.590382505274922e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:98, Validation Loss:8.833173353367006e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:99, Validation Loss:8.757867595769119e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.72330642630915e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:101, Validation Loss:8.757475589575323e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.362399249705842e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.055871472598375e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.057359289997281e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:105, Validation Loss:8.967377085073386e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.023175488652588e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.018057567190683e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:108, Validation Loss:8.767236089942959e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:109, Validation Loss:8.495407390034165e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.7034917655817e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.27546542076149e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:112, Validation Loss:8.749874817645762e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:113, Validation Loss:8.653607656896079e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:114, Validation Loss:8.618764104185906e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.091820300922098e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.079131673679215e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.460817913687575e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:118, Validation Loss:8.517628117149664e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.886514852279104e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.44992409186321e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.462768564299745e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.733784517814962e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:123, Validation Loss:8.993379222866693e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:124, Validation Loss:8.503055112245205e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:125, Validation Loss:8.612634544342897e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:126, Validation Loss:8.373461198030725e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:127, Validation Loss:8.713413052462618e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.102812707900018e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:129, Validation Loss:8.31602308181666e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:130, Validation Loss:8.474068665237185e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:131, Validation Loss:8.792493591005396e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:132, Validation Loss:9.642217041110812e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:133, Validation Loss:9.308117893212499e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:134, Validation Loss:8.728267092984655e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:135, Validation Loss:8.92281093609943e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:136, Validation Loss:9.171020422497875e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:137, Validation Loss:9.002879521707346e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:138, Validation Loss:8.154581247318783e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:139, Validation Loss:8.726309509440442e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:140, Validation Loss:8.311167638916177e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:141, Validation Loss:8.392072221452973e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:142, Validation Loss:9.144215823691029e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:143, Validation Loss:8.620450132011011e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:144, Validation Loss:8.260409288417157e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:145, Validation Loss:8.547856942028368e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:146, Validation Loss:8.338898944268644e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:147, Validation Loss:8.50224441053561e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:148, Validation Loss:8.177780944341736e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:149, Validation Loss:8.202646284310072e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:150, Validation Loss:8.236477129827058e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:151, Validation Loss:8.359123409234567e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:152, Validation Loss:8.576570625094928e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:153, Validation Loss:8.037911672136454e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:154, Validation Loss:8.40224969794306e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:155, Validation Loss:8.46661724817863e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:156, Validation Loss:8.269129617768097e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:157, Validation Loss:8.446859590762248e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:158, Validation Loss:8.122622712729862e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:159, Validation Loss:8.777038227511725e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:160, Validation Loss:8.531149070184274e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:161, Validation Loss:8.41958474561916e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:162, Validation Loss:8.303586384424644e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:163, Validation Loss:8.127272726850083e-06,Acc:99.8004%,lr:0.0001\n",
      "Episode:164, Validation Loss:8.76813802793032e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:165, Validation Loss:8.788359085089606e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:166, Validation Loss:8.727322975645109e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:167, Validation Loss:8.618524101658278e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:168, Validation Loss:8.332325626041003e-06,Acc:99.7472%,lr:0.0001\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:169, Validation Loss:8.390891850173105e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:170, Validation Loss:8.252932870449892e-06,Acc:99.7938%,lr:1e-05\n",
      "Episode:171, Validation Loss:8.187953773822766e-06,Acc:99.7938%,lr:1e-05\n",
      "Episode:172, Validation Loss:8.180693813537252e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:173, Validation Loss:8.192772071630875e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:174, Validation Loss:8.216941413563111e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:175, Validation Loss:8.2002843954881e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:176, Validation Loss:8.203343738409013e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:177, Validation Loss:8.236657309858126e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:178, Validation Loss:8.213407672977869e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:179, Validation Loss:8.117954606254391e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:180, Validation Loss:8.117311646081629e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:181, Validation Loss:8.158346501895113e-06,Acc:99.7938%,lr:1e-05\n",
      "Episode:182, Validation Loss:8.172787299391974e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:183, Validation Loss:8.229640666966698e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:184, Validation Loss:8.193255267632349e-06,Acc:99.7871%,lr:1e-05\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:8.127272726850083e-06 Acc:0.9980041248087286==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.002829955458664845,Acc:23.1921%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005894656540129159,Acc:15.6077%,lr:0.001\n",
      "Episode:3, Validation Loss:0.009703512510911694,Acc:11.4164%,lr:0.001\n",
      "Episode:4, Validation Loss:0.008904258058532873,Acc:18.1159%,lr:0.001\n",
      "Episode:5, Validation Loss:0.008234724536261534,Acc:24.4162%,lr:0.001\n",
      "Episode:6, Validation Loss:0.001122786901833237,Acc:75.7235%,lr:0.001\n",
      "Episode:7, Validation Loss:0.002586379164461683,Acc:58.6521%,lr:0.001\n",
      "Episode:8, Validation Loss:8.314307356505692e-05,Acc:97.9376%,lr:0.001\n",
      "Episode:9, Validation Loss:6.698606003307073e-05,Acc:98.1838%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00018588864896898775,Acc:95.4294%,lr:0.001\n",
      "Episode:11, Validation Loss:3.7010153888759876e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:12, Validation Loss:4.2536988850442814e-05,Acc:98.7426%,lr:0.001\n",
      "Episode:13, Validation Loss:7.952459433598874e-05,Acc:97.8178%,lr:0.001\n",
      "Episode:14, Validation Loss:5.5190627832754066e-05,Acc:98.6029%,lr:0.001\n",
      "Episode:15, Validation Loss:3.062022095119221e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:16, Validation Loss:4.017109009337817e-05,Acc:98.8158%,lr:0.001\n",
      "Episode:17, Validation Loss:3.92260937875604e-05,Acc:98.9089%,lr:0.001\n",
      "Episode:18, Validation Loss:2.83443846374078e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:19, Validation Loss:3.081893059008374e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:20, Validation Loss:3.601240077070923e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:21, Validation Loss:3.176301583428637e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:22, Validation Loss:3.635343472766952e-05,Acc:98.9688%,lr:0.001\n",
      "Episode:23, Validation Loss:2.780424455874346e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:24, Validation Loss:2.4738664360319527e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:25, Validation Loss:2.4226250816078357e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:26, Validation Loss:3.065536435990663e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:27, Validation Loss:4.969039991003304e-05,Acc:98.4299%,lr:0.001\n",
      "Episode:28, Validation Loss:3.528163616734663e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:29, Validation Loss:3.093744350983769e-05,Acc:99.0087%,lr:0.001\n",
      "Episode:30, Validation Loss:2.9339634442660918e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:31, Validation Loss:4.0167160458601555e-05,Acc:98.8956%,lr:0.001\n",
      "Episode:32, Validation Loss:3.960966336739832e-05,Acc:98.8890%,lr:0.001\n",
      "Episode:33, Validation Loss:2.570056270550971e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:34, Validation Loss:2.0950912002194753e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:35, Validation Loss:2.3994414198641274e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:36, Validation Loss:3.092704121104956e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:37, Validation Loss:2.4094298622218936e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:38, Validation Loss:2.499749582511414e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:39, Validation Loss:2.668914888565923e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:40, Validation Loss:2.354919677708695e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:41, Validation Loss:2.0288494182920974e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:42, Validation Loss:2.1469920643646e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:43, Validation Loss:2.3232355025343437e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:44, Validation Loss:2.063313043934009e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:45, Validation Loss:2.051316975940528e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:46, Validation Loss:2.106749740455308e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:47, Validation Loss:1.979239820823342e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:48, Validation Loss:2.1103518292497205e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:49, Validation Loss:2.291858389326281e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:50, Validation Loss:2.5143160413291177e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:51, Validation Loss:2.145482520649362e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:52, Validation Loss:2.3538989714639217e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:53, Validation Loss:2.5528079112797754e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:54, Validation Loss:1.6716456759601334e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:55, Validation Loss:3.554756144636303e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:56, Validation Loss:1.649689193269496e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:57, Validation Loss:2.4605110435379248e-05,Acc:99.2083%,lr:0.001\n",
      "Episode:58, Validation Loss:1.7853763370101987e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:59, Validation Loss:1.8212142257377635e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:60, Validation Loss:2.2760158370382003e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:61, Validation Loss:1.954493716911327e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:62, Validation Loss:2.271959877967454e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:63, Validation Loss:1.801400667900462e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:64, Validation Loss:2.4443557909125697e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:65, Validation Loss:2.0271986767557455e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:66, Validation Loss:1.8171125741759886e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:67, Validation Loss:1.844189955512331e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:68, Validation Loss:1.859224823548697e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:69, Validation Loss:2.064128764413382e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:70, Validation Loss:1.6091156057707605e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:71, Validation Loss:1.8507852788768473e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:72, Validation Loss:1.7511258913596528e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:73, Validation Loss:1.844188561409615e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:74, Validation Loss:1.763648668398389e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:75, Validation Loss:1.6993196000447966e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:76, Validation Loss:2.112193091961289e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:77, Validation Loss:1.8613440610478796e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:78, Validation Loss:1.7566130951410774e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:79, Validation Loss:1.4117142207502691e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:80, Validation Loss:1.88122417954487e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:81, Validation Loss:1.3105225222714765e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:82, Validation Loss:1.6076173295034762e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:83, Validation Loss:1.9146584709951975e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:84, Validation Loss:2.1914543495881852e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:85, Validation Loss:1.618136209356762e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:86, Validation Loss:3.0991287660229176e-05,Acc:98.9156%,lr:0.001\n",
      "Episode:87, Validation Loss:1.9761334873468733e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:88, Validation Loss:1.9449024141433593e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:89, Validation Loss:2.14998156583743e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:90, Validation Loss:4.732894295010292e-05,Acc:98.4964%,lr:0.001\n",
      "Episode:91, Validation Loss:1.621032804726571e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:92, Validation Loss:1.913291389087536e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:93, Validation Loss:2.1455564111913323e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:94, Validation Loss:2.3361149669490596e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:95, Validation Loss:2.1285988307666988e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:96, Validation Loss:2.162608133823395e-05,Acc:99.3946%,lr:0.001\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:97, Validation Loss:1.8842016266762128e-05,Acc:99.4145%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.294041746661863e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.2667407698378608e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.206745141210666e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.1510829011927694e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.2070905317076349e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.1806574024125714e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.1851882827106678e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.1742593631704493e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.149223648360148e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.1149622791403187e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.159624153402789e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.1598243031807664e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.128498666441002e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.1404189665008548e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.1190119306707754e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.1614535631432631e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.155187514448315e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.1675270057049318e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.1189349638088109e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.1247550452408236e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.0681564267024603e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.0737972637012281e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.0403312703551318e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.0825162825956132e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.0718305193531672e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.1084161706996942e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.1382849360228489e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.1161301592598497e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.1291860334322874e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.1230342639840043e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.061570580138409e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.0639113684412677e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0106730579142243e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.0587732975481038e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.1244038552765551e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.119699573384598e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.089236437015354e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.0667189023335468e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.1103358439440405e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:137, Validation Loss:1.1414299543006923e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:138, Validation Loss:1.1015050427958554e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:139, Validation Loss:1.0876172734545294e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.1148501870859153e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:141, Validation Loss:1.1087842200128121e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:142, Validation Loss:1.0738081841725059e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:143, Validation Loss:1.0411468235421789e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:144, Validation Loss:1.0592929880606835e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:145, Validation Loss:1.1164290455882084e-05,Acc:99.6607%,lr:0.0001\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:146, Validation Loss:1.0991205726078858e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:147, Validation Loss:1.072797255234783e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:148, Validation Loss:1.0698089248082347e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:149, Validation Loss:1.0701221208264749e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:150, Validation Loss:1.073229433272851e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:151, Validation Loss:1.074584082882289e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:152, Validation Loss:1.0685456168087694e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:153, Validation Loss:1.0631560931576677e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:154, Validation Loss:1.0542111428790714e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:155, Validation Loss:1.0508693795318844e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:156, Validation Loss:1.0637484597938519e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:157, Validation Loss:1.0615687585108596e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:158, Validation Loss:1.0581009434940699e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:159, Validation Loss:1.058153268816022e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:160, Validation Loss:1.0656205135874148e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:161, Validation Loss:1.0664687693261806e-05,Acc:99.6807%,lr:1e-05\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:1.089236437015354e-05 Acc:0.997006187213093==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0033981312646511174,Acc:10.9507%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005284748980880188,Acc:19.8323%,lr:0.001\n",
      "Episode:3, Validation Loss:0.003917189417195633,Acc:26.9244%,lr:0.001\n",
      "Episode:4, Validation Loss:0.001878180758268341,Acc:57.1219%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0016281316320178086,Acc:63.2094%,lr:0.001\n",
      "Episode:6, Validation Loss:0.00024008664468766909,Acc:92.3957%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00016663538113729134,Acc:95.0569%,lr:0.001\n",
      "Episode:8, Validation Loss:8.309259316765948e-05,Acc:97.6515%,lr:0.001\n",
      "Episode:9, Validation Loss:6.385858105444146e-05,Acc:98.3966%,lr:0.001\n",
      "Episode:10, Validation Loss:9.102784788669619e-05,Acc:97.5052%,lr:0.001\n",
      "Episode:11, Validation Loss:7.315442797809484e-05,Acc:98.1106%,lr:0.001\n",
      "Episode:12, Validation Loss:5.2215219065462724e-05,Acc:98.6295%,lr:0.001\n",
      "Episode:13, Validation Loss:6.167640681911091e-05,Acc:98.5563%,lr:0.001\n",
      "Episode:14, Validation Loss:4.45420867610728e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:15, Validation Loss:3.187102917786265e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:16, Validation Loss:3.867723777871369e-05,Acc:98.8557%,lr:0.001\n",
      "Episode:17, Validation Loss:3.2750943812073434e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:18, Validation Loss:6.551818115317364e-05,Acc:98.4831%,lr:0.001\n",
      "Episode:19, Validation Loss:2.7113164173502717e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:20, Validation Loss:2.949088281495756e-05,Acc:99.1617%,lr:0.001\n",
      "Episode:21, Validation Loss:2.394302174826676e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:22, Validation Loss:2.4433274449849113e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:23, Validation Loss:6.156936277966325e-05,Acc:97.9709%,lr:0.001\n",
      "Episode:24, Validation Loss:2.4014306309519633e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:25, Validation Loss:3.6949632110277513e-05,Acc:99.0021%,lr:0.001\n",
      "Episode:26, Validation Loss:3.550330333212925e-05,Acc:99.0021%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6201173032633156e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:28, Validation Loss:1.8653543926857242e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:29, Validation Loss:2.9878525281371206e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:30, Validation Loss:2.6200692593857055e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:31, Validation Loss:2.443513591775605e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:32, Validation Loss:2.3117977633847265e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:33, Validation Loss:2.4629450601364324e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:34, Validation Loss:2.5819025127765274e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:35, Validation Loss:2.4508173082983746e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:36, Validation Loss:2.3346545607075626e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:37, Validation Loss:2.0161633438061876e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:38, Validation Loss:1.744251756745893e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:39, Validation Loss:2.1870600510822084e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:40, Validation Loss:2.3957403249928086e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:41, Validation Loss:1.907022341522745e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:42, Validation Loss:2.4622615346726318e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:43, Validation Loss:2.1339619717983958e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:44, Validation Loss:2.3885269184440017e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:45, Validation Loss:2.4968922807011654e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:46, Validation Loss:2.5265324983740114e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:47, Validation Loss:2.8131205513483512e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:48, Validation Loss:0.00012325457611465302,Acc:95.9484%,lr:0.001\n",
      "Episode:49, Validation Loss:2.188329446663535e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:50, Validation Loss:1.809493520912808e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:51, Validation Loss:2.0062758066030283e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:52, Validation Loss:2.107637282008619e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:53, Validation Loss:2.0408955903372027e-05,Acc:99.4012%,lr:0.001\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:54, Validation Loss:1.9899780518960177e-05,Acc:99.4811%,lr:0.0001\n",
      "Episode:55, Validation Loss:1.50222033257296e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:56, Validation Loss:1.3718548537591412e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:57, Validation Loss:1.2355255894053125e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:58, Validation Loss:1.2693213685919732e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:59, Validation Loss:1.2366992627961313e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:60, Validation Loss:1.2375355199575186e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:61, Validation Loss:1.25472481419463e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.2138519701558145e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.2170942224511113e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.1920852930009996e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.192121922275369e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.184901243157392e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.2953247192546435e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.2187946033381819e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.2021230587128687e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.2028847344769395e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.2376909081952816e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.221367322313941e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.1659942920025488e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.2382056418982033e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.2365403195964418e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.2033768589318088e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.2799418738862687e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.1990438792593076e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.2366338917707606e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.2480519725230748e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.2221802452938633e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.2400133454593845e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.1906399972839441e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.2108158808682115e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.1844684253810773e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.265054044961398e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.3158926493067853e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.261860769043528e-05,Acc:99.6474%,lr:0.0001\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:89, Validation Loss:1.2131322073154079e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:90, Validation Loss:1.2022717087875027e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:91, Validation Loss:1.1913988987836095e-05,Acc:99.6407%,lr:1e-05\n",
      "Episode:92, Validation Loss:1.1762589835585666e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:93, Validation Loss:1.1780800643098124e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:94, Validation Loss:1.177922575623957e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:95, Validation Loss:1.178261763912841e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:96, Validation Loss:1.1781752397022548e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:97, Validation Loss:1.1847362480029106e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:98, Validation Loss:1.188065307976346e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:99, Validation Loss:1.1790520652526867e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:100, Validation Loss:1.1799945995111474e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:101, Validation Loss:1.1836517724018873e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:102, Validation Loss:1.1878092500324354e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:103, Validation Loss:1.1771830041329546e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:104, Validation Loss:1.1786237395851248e-05,Acc:99.6740%,lr:1e-05\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:1.1790520652526867e-05 Acc:0.9968731288670082==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10158\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10158_s7.npy\n",
      "shape of top1_dig_csv: (10158, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10158_s7.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s7.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10158, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75158, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75158_s7.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75158_s7.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step6\n",
      "Step: 7\n",
      "global_data len: 75158\n",
      "validation rate: 0.19999201681790363\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.007857095012724436,Acc:10.5449%,lr:0.001\n",
      "Episode:2, Validation Loss:0.006837504391152815,Acc:18.0693%,lr:0.001\n",
      "Episode:3, Validation Loss:0.01103386502408369,Acc:10.7178%,lr:0.001\n",
      "Episode:4, Validation Loss:0.011621921507075481,Acc:19.6727%,lr:0.001\n",
      "Episode:5, Validation Loss:0.010500686403901014,Acc:14.4634%,lr:0.001\n",
      "Episode:6, Validation Loss:0.011519696579096236,Acc:22.1875%,lr:0.001\n",
      "Episode:7, Validation Loss:0.008182680541015609,Acc:27.7826%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0021796572764360314,Acc:69.7492%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0008874625259035481,Acc:81.2720%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00019546274962471867,Acc:95.4694%,lr:0.001\n",
      "Episode:11, Validation Loss:0.0032934453639510814,Acc:56.2970%,lr:0.001\n",
      "Episode:12, Validation Loss:0.001827971313965867,Acc:73.7343%,lr:0.001\n",
      "Episode:13, Validation Loss:9.566667770944458e-05,Acc:97.4652%,lr:0.001\n",
      "Episode:14, Validation Loss:3.4930087949660046e-05,Acc:98.9156%,lr:0.001\n",
      "Episode:15, Validation Loss:4.280545610537208e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:16, Validation Loss:0.0005289169396320572,Acc:88.4572%,lr:0.001\n",
      "Episode:17, Validation Loss:3.189305346041539e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:18, Validation Loss:3.182749141199242e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:19, Validation Loss:3.2101097825214966e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:20, Validation Loss:2.8548001951581585e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:21, Validation Loss:2.9896809589076872e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:22, Validation Loss:4.332715759563014e-05,Acc:98.7759%,lr:0.001\n",
      "Episode:23, Validation Loss:2.337580336196227e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:24, Validation Loss:2.852793827312894e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:25, Validation Loss:2.6103432491192694e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:26, Validation Loss:1.9910065929980568e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:27, Validation Loss:2.4410758080017575e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:28, Validation Loss:1.9780611193687265e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:29, Validation Loss:1.8282333067599412e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:30, Validation Loss:2.0021015006036914e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:31, Validation Loss:2.3951699634935e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:32, Validation Loss:2.3638826181083436e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:33, Validation Loss:2.4778859315716524e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:34, Validation Loss:1.987321669718247e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:35, Validation Loss:3.211623672739204e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:36, Validation Loss:2.2290000451232898e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:37, Validation Loss:1.901470246906885e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:38, Validation Loss:1.8607028047784378e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:39, Validation Loss:2.1221927367088824e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:40, Validation Loss:1.5225414801112636e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:41, Validation Loss:2.1931882168225016e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:42, Validation Loss:1.8920911265723394e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:43, Validation Loss:2.0212714786670234e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:44, Validation Loss:2.7061666174062546e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:45, Validation Loss:1.826744085964301e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:46, Validation Loss:1.6787772269934508e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:47, Validation Loss:1.6848283360296045e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:48, Validation Loss:1.7294689393826297e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:49, Validation Loss:2.3505131296868508e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:50, Validation Loss:1.659404676511421e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:51, Validation Loss:1.4890333383930442e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:52, Validation Loss:1.8806368130904282e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:53, Validation Loss:1.5853937088503395e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:54, Validation Loss:1.65121892049406e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:55, Validation Loss:1.7765591206184825e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:56, Validation Loss:1.4867130898702058e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:57, Validation Loss:2.0570845089941536e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:58, Validation Loss:1.8911526011336897e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:59, Validation Loss:1.791290411945351e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:60, Validation Loss:1.5038328694988729e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:61, Validation Loss:1.4011755074623395e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:62, Validation Loss:2.116279442471251e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:63, Validation Loss:2.141379239536412e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:64, Validation Loss:1.7891721348280393e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:65, Validation Loss:1.1907710413902741e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:66, Validation Loss:1.4064211721051423e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:67, Validation Loss:1.3846589653730376e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:68, Validation Loss:1.3251954781446824e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:69, Validation Loss:1.3599598272325322e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:70, Validation Loss:1.1261703259263969e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:71, Validation Loss:1.7069259762672773e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:72, Validation Loss:1.8086775371029216e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:73, Validation Loss:1.4929804459237012e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:74, Validation Loss:1.6416840572000605e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:75, Validation Loss:1.3055407271948049e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:76, Validation Loss:1.3970709251868543e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:77, Validation Loss:1.150025846043173e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:78, Validation Loss:1.2881154160148313e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:79, Validation Loss:1.1606772152226046e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:80, Validation Loss:1.35137149462478e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:81, Validation Loss:1.1095096150281924e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:82, Validation Loss:1.709769982984621e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:83, Validation Loss:1.3985682875423579e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:84, Validation Loss:1.4214795756933654e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:85, Validation Loss:1.3551620568124194e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:86, Validation Loss:1.586573838485738e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:87, Validation Loss:1.859413228785791e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:88, Validation Loss:1.2763186830237402e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:89, Validation Loss:1.3711437126695336e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:90, Validation Loss:1.1895089075350966e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:91, Validation Loss:1.588051516110887e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:92, Validation Loss:1.3657583589345568e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:93, Validation Loss:1.358092042491287e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:94, Validation Loss:1.2672001700549693e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:95, Validation Loss:1.191602893187078e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:96, Validation Loss:1.3945285031611267e-05,Acc:99.4811%,lr:0.001\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:97, Validation Loss:1.933339472177793e-05,Acc:99.3613%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.1042732444034984e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.317724515620317e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.895555205653586e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:101, Validation Loss:8.879490247512163e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:102, Validation Loss:8.815440707596213e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:103, Validation Loss:8.701381140539297e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.097468182786593e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.10849894307924e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:106, Validation Loss:8.967726726034636e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:107, Validation Loss:8.577823412265895e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:108, Validation Loss:8.712732327596274e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.444960955671427e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.29527844614722e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:111, Validation Loss:8.729741573467574e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:112, Validation Loss:8.787466952291349e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:113, Validation Loss:8.738100876685079e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:114, Validation Loss:8.825091708940498e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.299847664270015e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:116, Validation Loss:8.479079380200204e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:117, Validation Loss:8.779258940198624e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:118, Validation Loss:8.614927487040533e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.659933506401545e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.470380039840162e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.648141194265067e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.71338582098956e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:123, Validation Loss:8.627940769825984e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:124, Validation Loss:8.587973719243042e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:125, Validation Loss:8.72202673295576e-06,Acc:99.7139%,lr:0.0001\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:126, Validation Loss:8.672781247234449e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:127, Validation Loss:8.589829533288963e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:128, Validation Loss:8.532022878276827e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:129, Validation Loss:8.48710532247818e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:130, Validation Loss:8.496590797359949e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:131, Validation Loss:8.44704962245251e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:132, Validation Loss:8.375570971121466e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:133, Validation Loss:8.38172395189011e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:134, Validation Loss:8.389920222539957e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:135, Validation Loss:8.374816684101793e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:136, Validation Loss:8.398890870778624e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:137, Validation Loss:8.417842984665465e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:138, Validation Loss:8.354459361147004e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:139, Validation Loss:8.327950823287013e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:140, Validation Loss:8.357139167348415e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:141, Validation Loss:8.307633464610091e-06,Acc:99.7272%,lr:1e-05\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:8.354459361147004e-06 Acc:0.9974718914243896==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.005595198553817634,Acc:9.9395%,lr:0.001\n",
      "Episode:2, Validation Loss:0.015464613818494188,Acc:9.9395%,lr:0.001\n",
      "Episode:3, Validation Loss:0.021194711415784006,Acc:9.9395%,lr:0.001\n",
      "Episode:4, Validation Loss:0.040397705967400444,Acc:9.9395%,lr:0.001\n",
      "Episode:5, Validation Loss:0.01874531183832222,Acc:10.2987%,lr:0.001\n",
      "Episode:6, Validation Loss:0.006995022221562011,Acc:26.9310%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0038259720962511216,Acc:49.8370%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00011715387357827011,Acc:96.8731%,lr:0.001\n",
      "Episode:9, Validation Loss:8.870970637972313e-05,Acc:97.8178%,lr:0.001\n",
      "Episode:10, Validation Loss:4.166214751091699e-05,Acc:98.9355%,lr:0.001\n",
      "Episode:11, Validation Loss:4.207862683711719e-05,Acc:98.8424%,lr:0.001\n",
      "Episode:12, Validation Loss:5.684083725558919e-05,Acc:98.4565%,lr:0.001\n",
      "Episode:13, Validation Loss:4.6887420954068864e-05,Acc:98.9289%,lr:0.001\n",
      "Episode:14, Validation Loss:2.7710342384821782e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:15, Validation Loss:4.317416492201486e-05,Acc:98.8490%,lr:0.001\n",
      "Episode:16, Validation Loss:3.8612339632984296e-05,Acc:98.8956%,lr:0.001\n",
      "Episode:17, Validation Loss:3.94597024024901e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:18, Validation Loss:2.840876330948504e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:19, Validation Loss:3.253020648282252e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:20, Validation Loss:3.308816740748951e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:21, Validation Loss:2.5419213445800783e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:22, Validation Loss:3.1237281948391466e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:23, Validation Loss:3.196759669029755e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:24, Validation Loss:2.3996250324858835e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:25, Validation Loss:2.7279320956327333e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:26, Validation Loss:3.44259169602789e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:27, Validation Loss:2.436274239426244e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:28, Validation Loss:3.0225289805977098e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:29, Validation Loss:2.6210521048987097e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:30, Validation Loss:2.630504093433234e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:31, Validation Loss:1.9975511896117353e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:32, Validation Loss:3.3035025637026564e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:33, Validation Loss:2.5591527515622434e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:34, Validation Loss:4.377776889353406e-05,Acc:98.8757%,lr:0.001\n",
      "Episode:35, Validation Loss:2.127486188094794e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:36, Validation Loss:2.573849955528695e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:37, Validation Loss:2.4016676098256995e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:38, Validation Loss:1.899956589039631e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:39, Validation Loss:2.4471793693781105e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:40, Validation Loss:2.5091647977142877e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:41, Validation Loss:2.6216197277606822e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:42, Validation Loss:2.003020025315371e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:43, Validation Loss:2.2103138021144804e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:44, Validation Loss:2.106009958299895e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:45, Validation Loss:1.8587211621193486e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:46, Validation Loss:1.683225567116724e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:47, Validation Loss:1.8263891876868072e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:48, Validation Loss:2.2411094412755828e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:49, Validation Loss:1.560739429837239e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:50, Validation Loss:3.106039122523253e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:51, Validation Loss:1.616668055002168e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:52, Validation Loss:1.973018984428487e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:53, Validation Loss:1.5509348541377238e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:54, Validation Loss:1.810019977470571e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:55, Validation Loss:2.2797991344016848e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:56, Validation Loss:2.2359331316939135e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6834176032168922e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:58, Validation Loss:2.0260460945900213e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:59, Validation Loss:6.881073031999038e-05,Acc:97.9842%,lr:0.001\n",
      "Episode:60, Validation Loss:3.0389449056469665e-05,Acc:98.9755%,lr:0.001\n",
      "Episode:61, Validation Loss:1.8781724236407416e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:62, Validation Loss:1.7961771447068003e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:63, Validation Loss:2.3972898453779385e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:64, Validation Loss:2.0564767514639817e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:65, Validation Loss:1.9595848065429515e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:66, Validation Loss:1.9317973095569995e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:67, Validation Loss:1.8615339471318593e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:68, Validation Loss:1.7468883488611042e-05,Acc:99.5343%,lr:0.001\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:69, Validation Loss:2.445066405341151e-05,Acc:99.3746%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.563000930871612e-05,Acc:99.5809%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.3776287470191596e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.3165941772836625e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.2616236662495501e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.1950685303056242e-05,Acc:99.6141%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.1743522692734702e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.1256100732207845e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.161743669722515e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.265872157101431e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.266956443724086e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.1855404640368681e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.2230343268329802e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.2607069166953293e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.1738225598093692e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.1572302095123604e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.1842914719232961e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.2189156207479758e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.3050378247769354e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.2228898420274618e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.1832795516236418e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.2246791449817909e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.246612699329754e-05,Acc:99.6740%,lr:0.0001\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:92, Validation Loss:1.2236925229994283e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:93, Validation Loss:1.2099810890636792e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:94, Validation Loss:1.1998858801238861e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:95, Validation Loss:1.205958393283744e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:96, Validation Loss:1.2076098442634782e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:97, Validation Loss:1.2055884789709924e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:98, Validation Loss:1.2013950458823877e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:99, Validation Loss:1.2035872228356879e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:100, Validation Loss:1.2102999451389475e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:101, Validation Loss:1.192965929098856e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:102, Validation Loss:1.1991485206091938e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:103, Validation Loss:1.1970145458952965e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:104, Validation Loss:1.2028911659374706e-05,Acc:99.6474%,lr:1e-05\n",
      "Episode:105, Validation Loss:1.2028491228975529e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:106, Validation Loss:1.1953503837967956e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:107, Validation Loss:1.1984098847160145e-05,Acc:99.6540%,lr:1e-05\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:1.2099810890636792e-05 Acc:0.9968731288670082==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.007915852288906068,Acc:10.0725%,lr:0.001\n",
      "Episode:2, Validation Loss:0.01570442912345573,Acc:10.0725%,lr:0.001\n",
      "Episode:3, Validation Loss:0.021588074693850483,Acc:10.0725%,lr:0.001\n",
      "Episode:4, Validation Loss:0.018108188745131804,Acc:10.0925%,lr:0.001\n",
      "Episode:5, Validation Loss:0.00954343125647425,Acc:14.6630%,lr:0.001\n",
      "Episode:6, Validation Loss:0.006290898860139322,Acc:27.4300%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00019109127276608842,Acc:94.5246%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0002331725068850857,Acc:93.8860%,lr:0.001\n",
      "Episode:9, Validation Loss:0.00033539374005841317,Acc:92.9279%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00013240460286826624,Acc:96.5871%,lr:0.001\n",
      "Episode:11, Validation Loss:5.064012017937511e-05,Acc:98.7626%,lr:0.001\n",
      "Episode:12, Validation Loss:3.4409671698186176e-05,Acc:99.0819%,lr:0.001\n",
      "Episode:13, Validation Loss:5.0001406753287645e-05,Acc:98.8158%,lr:0.001\n",
      "Episode:14, Validation Loss:3.20020250792188e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:15, Validation Loss:3.9866784918741285e-05,Acc:98.9755%,lr:0.001\n",
      "Episode:16, Validation Loss:2.545552585611292e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:17, Validation Loss:3.2517296162267684e-05,Acc:99.1551%,lr:0.001\n",
      "Episode:18, Validation Loss:3.4422252266978516e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:19, Validation Loss:3.7468849743215965e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:20, Validation Loss:3.012286266296513e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:21, Validation Loss:2.8517837038567407e-05,Acc:99.1551%,lr:0.001\n",
      "Episode:22, Validation Loss:3.693703970710212e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:23, Validation Loss:2.4602728936179066e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:24, Validation Loss:2.6008210009058492e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:25, Validation Loss:2.914724863957093e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:26, Validation Loss:3.186071684516981e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:27, Validation Loss:3.1363286497322324e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:28, Validation Loss:3.436036513527586e-05,Acc:99.0819%,lr:0.001\n",
      "Episode:29, Validation Loss:2.639738970606732e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:30, Validation Loss:2.4181224520267837e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:31, Validation Loss:2.3703050758340436e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:32, Validation Loss:2.3894497246000233e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:33, Validation Loss:2.9500353729210964e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:34, Validation Loss:2.420736803556661e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:35, Validation Loss:2.18215562251028e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:36, Validation Loss:2.0594105662783102e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:37, Validation Loss:2.4688806662135365e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:38, Validation Loss:2.175075135910458e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:39, Validation Loss:2.04347169078655e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:40, Validation Loss:1.651568607925401e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:41, Validation Loss:2.3889026043419985e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:42, Validation Loss:1.7340034474457946e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:43, Validation Loss:2.090382612099128e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:44, Validation Loss:1.9683080139414976e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:45, Validation Loss:1.9631851511599657e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:46, Validation Loss:1.887121469483318e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:47, Validation Loss:2.1344310439903494e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:48, Validation Loss:0.00012285538638838036,Acc:96.0681%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7467630469089622e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:50, Validation Loss:2.2897147488335507e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:51, Validation Loss:1.753814852168901e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:52, Validation Loss:1.5955831250556888e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:53, Validation Loss:2.1093471118141002e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:54, Validation Loss:1.7112674475743236e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:55, Validation Loss:1.997398938105084e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:56, Validation Loss:2.284342112413353e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:57, Validation Loss:2.3700487468146046e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:58, Validation Loss:1.6697749697991962e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:59, Validation Loss:5.514698386723692e-05,Acc:98.2037%,lr:0.001\n",
      "Episode:60, Validation Loss:1.3340415834426864e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:61, Validation Loss:1.9108149452963623e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:62, Validation Loss:1.4408997239401364e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:63, Validation Loss:1.537326184160203e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:64, Validation Loss:2.074326697037325e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:65, Validation Loss:1.997714928524769e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:66, Validation Loss:2.2235897121656425e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:67, Validation Loss:2.1810591080578e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:68, Validation Loss:1.4685885308457978e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:69, Validation Loss:1.8794113162546353e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:70, Validation Loss:1.8557684804482593e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:71, Validation Loss:1.9530622615362385e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:72, Validation Loss:1.887217811275033e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:73, Validation Loss:1.755468936453766e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:74, Validation Loss:1.7744944854756885e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:75, Validation Loss:1.9818068688990516e-05,Acc:99.5077%,lr:0.001\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:76, Validation Loss:1.6703503283822413e-05,Acc:99.5276%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.1767891546255671e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.1200745049181253e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.0892997075926321e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.0743071985927998e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.148794030824069e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.1216096180261835e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.1536529822163887e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0748779674799021e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.099119660245108e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.065542316817054e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.1208849309051825e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0488388642785706e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.0534032835900153e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0690710448285284e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0603972816063206e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.0320569593842281e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.029611255557949e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0617396708568702e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0239849698935336e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.048082177853221e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0666254602754816e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0684729809592436e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0965818341113351e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.942310523011515e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0719972199599715e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0269656513431783e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0382003936472708e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.005637173201163e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.90591363007477e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.767481786200216e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.90154745526759e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.946041869911778e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.533408826635782e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.534169232217377e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.740374651613901e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.561305302180071e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.962974610524013e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.0668375776507772e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.0967571735079715e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.988948293131877e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0038652531587034e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.487949259191064e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.0264794905499287e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.0023509524551966e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:121, Validation Loss:9.681442227678284e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.0517398928950174e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.0024340409770887e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.702249024838842e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.0496179647775921e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:126, Validation Loss:9.60173460624368e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:127, Validation Loss:9.930633611599887e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.592070484843831e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:129, Validation Loss:9.659828229554953e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.409901332530257e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.0571624614275047e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.0263637459464087e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.005506649559847e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:134, Validation Loss:9.87517828120914e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.0184976205058253e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:136, Validation Loss:1.056141968945148e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:137, Validation Loss:1.0648858028678836e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:138, Validation Loss:1.0292332508024338e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:139, Validation Loss:1.0019714017946693e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.0051219871893598e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:141, Validation Loss:1.0455266016938636e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:142, Validation Loss:1.0369896123401499e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:143, Validation Loss:1.030329692451772e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:144, Validation Loss:1.1085764584340034e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:145, Validation Loss:9.981121552642033e-06,Acc:99.6940%,lr:0.0001\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:146, Validation Loss:9.623482453717807e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:147, Validation Loss:9.399342909727924e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:148, Validation Loss:9.387719965581448e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:149, Validation Loss:9.313608411860382e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:150, Validation Loss:9.437674910175088e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:151, Validation Loss:9.489223004372865e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:152, Validation Loss:9.397247821185793e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:153, Validation Loss:9.485300417559984e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:154, Validation Loss:9.540668941821598e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:155, Validation Loss:9.652112908852203e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:156, Validation Loss:9.62937115908153e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:157, Validation Loss:9.67233773008882e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:158, Validation Loss:9.68980244480757e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:159, Validation Loss:9.693050007085212e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:160, Validation Loss:9.63094074834976e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:161, Validation Loss:9.737342772516502e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:162, Validation Loss:9.701961282038195e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:163, Validation Loss:9.591266397377123e-06,Acc:99.7405%,lr:1e-05\n",
      "Episode:164, Validation Loss:9.599029830113617e-06,Acc:99.7405%,lr:1e-05\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:9.399342909727924e-06 Acc:0.9976049497704743==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0030259499173306806,Acc:18.5084%,lr:0.001\n",
      "Episode:2, Validation Loss:0.008860000679889653,Acc:9.9195%,lr:0.001\n",
      "Episode:3, Validation Loss:0.0073853821329676805,Acc:15.4215%,lr:0.001\n",
      "Episode:4, Validation Loss:0.02215248847957873,Acc:9.8862%,lr:0.001\n",
      "Episode:5, Validation Loss:0.007284769524310403,Acc:23.3717%,lr:0.001\n",
      "Episode:6, Validation Loss:0.00638149956982417,Acc:25.5805%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0015336045025430923,Acc:69.4298%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00016209241750037137,Acc:96.2278%,lr:0.001\n",
      "Episode:9, Validation Loss:0.001194314279842421,Acc:72.9825%,lr:0.001\n",
      "Episode:10, Validation Loss:6.345736597574255e-05,Acc:98.4964%,lr:0.001\n",
      "Episode:11, Validation Loss:6.657428050594775e-05,Acc:98.1372%,lr:0.001\n",
      "Episode:12, Validation Loss:5.7135566431607925e-05,Acc:98.4299%,lr:0.001\n",
      "Episode:13, Validation Loss:4.1580443302042174e-05,Acc:98.7759%,lr:0.001\n",
      "Episode:14, Validation Loss:3.766332917878525e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:15, Validation Loss:7.837404892335323e-05,Acc:97.6515%,lr:0.001\n",
      "Episode:16, Validation Loss:2.808198123361352e-05,Acc:99.2216%,lr:0.001\n",
      "Episode:17, Validation Loss:3.1453554524283125e-05,Acc:99.1484%,lr:0.001\n",
      "Episode:18, Validation Loss:3.361799998635042e-05,Acc:99.1218%,lr:0.001\n",
      "Episode:19, Validation Loss:2.4405506711945658e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:20, Validation Loss:2.092840213817589e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:21, Validation Loss:2.2522146249672395e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:22, Validation Loss:2.556004725120539e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:23, Validation Loss:2.6183366809219002e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:24, Validation Loss:3.036521967518045e-05,Acc:99.1085%,lr:0.001\n",
      "Episode:25, Validation Loss:2.6473363161416167e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:26, Validation Loss:3.9126548038002625e-05,Acc:98.7958%,lr:0.001\n",
      "Episode:27, Validation Loss:3.642327159070166e-05,Acc:98.8956%,lr:0.001\n",
      "Episode:28, Validation Loss:2.2891852438378482e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:29, Validation Loss:2.1768208003517604e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:30, Validation Loss:1.9864453987108955e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:31, Validation Loss:2.1482581079033952e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:32, Validation Loss:2.1205553413825347e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:33, Validation Loss:2.3634499877613943e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:34, Validation Loss:2.6769885091567956e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:35, Validation Loss:1.8013563540221197e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:36, Validation Loss:2.4938094223654362e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:37, Validation Loss:2.6848311362215942e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:38, Validation Loss:2.0698243214927677e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:39, Validation Loss:2.2817525201477173e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:40, Validation Loss:1.6755972322274583e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:41, Validation Loss:0.0005924222605106764,Acc:84.1394%,lr:0.001\n",
      "Episode:42, Validation Loss:1.6163069514185834e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:43, Validation Loss:2.074288244586403e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:44, Validation Loss:1.557672314019183e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:45, Validation Loss:1.7982246788562745e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:46, Validation Loss:2.858811189769295e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:47, Validation Loss:1.9483976651016058e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:48, Validation Loss:1.7194380667341912e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:49, Validation Loss:1.731058253655295e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:50, Validation Loss:2.201521419339151e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:51, Validation Loss:1.6285180520110403e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:52, Validation Loss:1.5504319641118786e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:53, Validation Loss:2.0263318174907322e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:54, Validation Loss:1.5716978145128682e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:55, Validation Loss:1.7026848369837203e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:56, Validation Loss:1.548790470123545e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6192428604849925e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:58, Validation Loss:1.6182086314438712e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:59, Validation Loss:1.6452522600044485e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:60, Validation Loss:1.539935324843927e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:61, Validation Loss:8.010417971454943e-05,Acc:97.5783%,lr:0.001\n",
      "Episode:62, Validation Loss:1.781350385225919e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:63, Validation Loss:1.8370561026605284e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:64, Validation Loss:1.8369594262841616e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:65, Validation Loss:1.5760980054263257e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:66, Validation Loss:1.9108724226023526e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:67, Validation Loss:1.6716531328606625e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:68, Validation Loss:1.8010977758502986e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:69, Validation Loss:2.7053221598228892e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:70, Validation Loss:1.616696773518124e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:71, Validation Loss:1.54969373405749e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6642491245884815e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:73, Validation Loss:1.7972704186449667e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:74, Validation Loss:1.7004486466586633e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:75, Validation Loss:1.7552500809153415e-05,Acc:99.4744%,lr:0.001\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:76, Validation Loss:1.707956738639644e-05,Acc:99.5343%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.0405147156845618e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:78, Validation Loss:9.629765039568976e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:79, Validation Loss:9.939942732488044e-06,Acc:99.6341%,lr:0.0001\n",
      "Episode:80, Validation Loss:9.5855732846245e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:81, Validation Loss:9.329270505296851e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:82, Validation Loss:9.103240139792838e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:83, Validation Loss:9.747186407876121e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:84, Validation Loss:9.767623396056132e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.213813148896444e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:86, Validation Loss:9.529351476560325e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.635386464461922e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.156022758415998e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:89, Validation Loss:8.857911334307193e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:90, Validation Loss:8.84919397904205e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:91, Validation Loss:8.979936122723773e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:92, Validation Loss:8.75155942038809e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:93, Validation Loss:8.839989137037073e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:94, Validation Loss:8.977694932216973e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.959635075048632e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.111096961921295e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.17332447154715e-06,Acc:99.6474%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.24278043473713e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:99, Validation Loss:8.892577743032213e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.07281787541723e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.066020013712082e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:102, Validation Loss:8.952310955058108e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:103, Validation Loss:8.709791359486009e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:104, Validation Loss:8.839619901187642e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:105, Validation Loss:8.820397145493477e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.136381028385491e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.130913636352668e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:108, Validation Loss:8.720776083408958e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.843476927591318e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.918940225397627e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.463112204017837e-06,Acc:99.6540%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.125852671731741e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.150277599161965e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:114, Validation Loss:8.807948520778221e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.545850487438935e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:116, Validation Loss:8.658461271973001e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:117, Validation Loss:8.447622102987948e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:118, Validation Loss:8.719202977903874e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.494535518195384e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.432829310045247e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.696599461162538e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.509672716469133e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:123, Validation Loss:8.790753379054717e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.207709333483596e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:125, Validation Loss:9.133265921355928e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:126, Validation Loss:8.981316780093885e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:127, Validation Loss:8.885559179377043e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.187062765195233e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:129, Validation Loss:9.148904810727186e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:130, Validation Loss:8.784424927224181e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:131, Validation Loss:8.913412608127458e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:132, Validation Loss:8.648521505486076e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:133, Validation Loss:8.559143008998463e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:134, Validation Loss:7.961426054429694e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:135, Validation Loss:8.398964169601443e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:136, Validation Loss:8.262563332014159e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:137, Validation Loss:8.411223846928547e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:138, Validation Loss:8.423950703565918e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:139, Validation Loss:8.48105606295163e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:140, Validation Loss:8.578041403460635e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:141, Validation Loss:8.252627840775564e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:142, Validation Loss:8.759441924986587e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:143, Validation Loss:9.33634368679844e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:144, Validation Loss:9.255579196094603e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:145, Validation Loss:8.95716466307521e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:146, Validation Loss:8.504657664297663e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:147, Validation Loss:8.530299147718261e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:148, Validation Loss:9.035953059648771e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:149, Validation Loss:9.21846536260095e-06,Acc:99.7073%,lr:0.0001\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:150, Validation Loss:9.099420050509667e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:151, Validation Loss:9.006725944041825e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:152, Validation Loss:8.912359255095076e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:153, Validation Loss:8.799812165565115e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:154, Validation Loss:8.773938331691798e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:155, Validation Loss:8.708953627673747e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:156, Validation Loss:8.731010718110412e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:157, Validation Loss:8.715551575049376e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:158, Validation Loss:8.701548370905134e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:159, Validation Loss:8.639573410731354e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:160, Validation Loss:8.596577671997228e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:161, Validation Loss:8.606702079643913e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:162, Validation Loss:8.558060255888797e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:163, Validation Loss:8.511398553671804e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:164, Validation Loss:8.532072353433226e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:165, Validation Loss:8.454602747049233e-06,Acc:99.7206%,lr:1e-05\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:8.578041403460635e-06 Acc:0.9975384205974319==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.005820870153617339,Acc:10.0126%,lr:0.001\n",
      "Episode:2, Validation Loss:0.010699159600493453,Acc:10.1989%,lr:0.001\n",
      "Episode:3, Validation Loss:0.01238960756940539,Acc:10.1989%,lr:0.001\n",
      "Episode:4, Validation Loss:0.0240619585317541,Acc:10.1989%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0116365241255718,Acc:16.1466%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0042189998498545715,Acc:44.0423%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00013435968904785192,Acc:96.1679%,lr:0.001\n",
      "Episode:8, Validation Loss:7.130072813541318e-05,Acc:97.8977%,lr:0.001\n",
      "Episode:9, Validation Loss:3.727746887132402e-05,Acc:98.9422%,lr:0.001\n",
      "Episode:10, Validation Loss:5.694497648065703e-05,Acc:98.6228%,lr:0.001\n",
      "Episode:11, Validation Loss:4.505828433380688e-05,Acc:98.8025%,lr:0.001\n",
      "Episode:12, Validation Loss:3.781934197456503e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:13, Validation Loss:5.531590078755947e-05,Acc:98.5630%,lr:0.001\n",
      "Episode:14, Validation Loss:8.505286689639274e-05,Acc:97.6116%,lr:0.001\n",
      "Episode:15, Validation Loss:3.827938143423904e-05,Acc:99.0087%,lr:0.001\n",
      "Episode:16, Validation Loss:3.8963946279064715e-05,Acc:98.9023%,lr:0.001\n",
      "Episode:17, Validation Loss:3.289658141661789e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:18, Validation Loss:2.916001725732967e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:19, Validation Loss:3.4714117522297104e-05,Acc:99.0686%,lr:0.001\n",
      "Episode:20, Validation Loss:2.68852600410078e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:21, Validation Loss:3.9840069449568104e-05,Acc:98.9954%,lr:0.001\n",
      "Episode:22, Validation Loss:3.4763752535807384e-05,Acc:98.9621%,lr:0.001\n",
      "Episode:23, Validation Loss:2.291748806656767e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:24, Validation Loss:2.8983738607223316e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:25, Validation Loss:2.959045917281498e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:26, Validation Loss:2.4147324496276062e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:27, Validation Loss:1.8193710794385247e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:28, Validation Loss:2.1249852266838496e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:29, Validation Loss:2.741362952455798e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:30, Validation Loss:2.1808197437194156e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:31, Validation Loss:2.08238649742327e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:32, Validation Loss:3.102339824495435e-05,Acc:99.0619%,lr:0.001\n",
      "Episode:33, Validation Loss:2.0745118989361775e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:34, Validation Loss:2.4675087452204465e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:35, Validation Loss:1.70865848657495e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:36, Validation Loss:2.3713586643148852e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:37, Validation Loss:3.2859989225380624e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:38, Validation Loss:2.1393522761470186e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:39, Validation Loss:1.7324966950339953e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:40, Validation Loss:2.100615353918894e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:41, Validation Loss:2.0803519098410213e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:42, Validation Loss:1.8381467030194854e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:43, Validation Loss:2.112938453625573e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:44, Validation Loss:1.7615834740655053e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:45, Validation Loss:2.7764910910984656e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:46, Validation Loss:1.8123185957152643e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:47, Validation Loss:2.2829863320317115e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:48, Validation Loss:1.5347686748450788e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7596802977033022e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:50, Validation Loss:2.082617633457622e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:51, Validation Loss:2.038249394403279e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:52, Validation Loss:1.9059333583229387e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:53, Validation Loss:1.6315856108439594e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:54, Validation Loss:1.4102565887731775e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:55, Validation Loss:1.722942475398281e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:56, Validation Loss:2.0756908048591915e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:57, Validation Loss:1.9962673883023405e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:58, Validation Loss:1.9021257973761784e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:59, Validation Loss:1.7759343023690687e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:60, Validation Loss:1.9129674646743922e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:61, Validation Loss:1.6755460283836912e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:62, Validation Loss:2.0317675850779366e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:63, Validation Loss:1.0800217836252603e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:64, Validation Loss:1.4770299745953477e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:65, Validation Loss:1.539741519782312e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:66, Validation Loss:1.6205733983134503e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:67, Validation Loss:2.0355185051803366e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:68, Validation Loss:1.538039332757722e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:69, Validation Loss:1.678479016030408e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:70, Validation Loss:1.741563079404197e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:71, Validation Loss:1.2365857348159302e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:72, Validation Loss:1.69233414168213e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5241702443927946e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:74, Validation Loss:1.3069303099203074e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:75, Validation Loss:1.538212015614182e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:76, Validation Loss:1.4714699800640957e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:77, Validation Loss:2.2021704887798167e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:78, Validation Loss:1.6469557481915738e-05,Acc:99.5409%,lr:0.001\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:79, Validation Loss:1.467629409863019e-05,Acc:99.5543%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.2161887961089527e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.1321052488931701e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.09553206237393e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0437878380610069e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0205804502380702e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.0498808212957492e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.0122280540250231e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.974262768648181e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.613210348633344e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:89, Validation Loss:9.515052087548988e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:90, Validation Loss:9.93640959601398e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0363103869087277e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.990967217195605e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.638937321530513e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.493073980776217e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:95, Validation Loss:9.770036216097339e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.982354621004577e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.902797841483878e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.639135268626199e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0227499590812032e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0831997879223746e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.585563541395517e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.051158531925277e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0088700261461458e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0181242193872799e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.978746048083532e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.041450107490106e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.548257244276862e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.0435903835482809e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.0599593784530976e-05,Acc:99.7272%,lr:0.0001\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:110, Validation Loss:1.0686399975626635e-05,Acc:99.7139%,lr:1e-05\n",
      "Episode:111, Validation Loss:1.0473413780028254e-05,Acc:99.7405%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.0402778576330609e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.0311251209916076e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.0175091087397809e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.0224537029599693e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:116, Validation Loss:1.019993368800184e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:117, Validation Loss:1.0189025949528891e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:118, Validation Loss:1.0201194127247717e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:119, Validation Loss:1.0051996836317457e-05,Acc:99.7206%,lr:1e-05\n",
      "Episode:120, Validation Loss:9.97479691135892e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:121, Validation Loss:9.978231515751001e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:122, Validation Loss:1.008815938058759e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:123, Validation Loss:1.0150733882379535e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:124, Validation Loss:1.0176125062402434e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:125, Validation Loss:1.0104234809989415e-05,Acc:99.7073%,lr:1e-05\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:1.0473413780028254e-05 Acc:0.9974053622513472==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10159\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10159_s8.npy\n",
      "shape of top1_dig_csv: (10159, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10159_s8.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s8.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10159, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75159, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75159_s8.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75159_s8.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step7\n",
      "Step: 8\n",
      "global_data len: 75159\n",
      "validation rate: 0.19998935589882783\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.003765183939809103,Acc:10.5316%,lr:0.001\n",
      "Episode:2, Validation Loss:0.006390002092497608,Acc:10.3519%,lr:0.001\n",
      "Episode:3, Validation Loss:0.0037493931462796305,Acc:36.0588%,lr:0.001\n",
      "Episode:4, Validation Loss:0.0013564073684948202,Acc:59.0047%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0006463385716414755,Acc:79.6221%,lr:0.001\n",
      "Episode:6, Validation Loss:0.00015131573335717247,Acc:95.3829%,lr:0.001\n",
      "Episode:7, Validation Loss:7.320009680035728e-05,Acc:98.0773%,lr:0.001\n",
      "Episode:8, Validation Loss:6.834619373279405e-05,Acc:97.4187%,lr:0.001\n",
      "Episode:9, Validation Loss:6.710814873335184e-05,Acc:98.3767%,lr:0.001\n",
      "Episode:10, Validation Loss:3.244662097880214e-05,Acc:99.0619%,lr:0.001\n",
      "Episode:11, Validation Loss:3.3768081773494056e-05,Acc:99.0486%,lr:0.001\n",
      "Episode:12, Validation Loss:4.684268314458044e-05,Acc:98.5896%,lr:0.001\n",
      "Episode:13, Validation Loss:3.375323389800403e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:14, Validation Loss:4.082561400739124e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:15, Validation Loss:2.5514536117450198e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:16, Validation Loss:2.5227390798248062e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:17, Validation Loss:3.7030228224353285e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:18, Validation Loss:3.428998965291426e-05,Acc:98.9755%,lr:0.001\n",
      "Episode:19, Validation Loss:3.9766640944217905e-05,Acc:98.7692%,lr:0.001\n",
      "Episode:20, Validation Loss:2.3912227227485835e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:21, Validation Loss:2.4010926632774573e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:22, Validation Loss:3.9757886970521416e-05,Acc:98.7626%,lr:0.001\n",
      "Episode:23, Validation Loss:2.2695022049948536e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:24, Validation Loss:1.805470072317406e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:25, Validation Loss:2.0523212658513147e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:26, Validation Loss:2.5524119551282832e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:27, Validation Loss:2.7115697536958794e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:28, Validation Loss:1.7564167837925788e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:29, Validation Loss:2.6122378532987702e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:30, Validation Loss:1.8697744727979345e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:31, Validation Loss:2.0750276085110007e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:32, Validation Loss:2.114409179325177e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:33, Validation Loss:1.9441829239274837e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:34, Validation Loss:1.8304658569279056e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:35, Validation Loss:1.6697885018895625e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:36, Validation Loss:2.1394781977003677e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:37, Validation Loss:2.1460454066601052e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:38, Validation Loss:1.6726291008002664e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:39, Validation Loss:2.75595145358645e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:40, Validation Loss:1.756513999221996e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:41, Validation Loss:1.6731784113485587e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:42, Validation Loss:1.8327096931318602e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:43, Validation Loss:1.5006929102648868e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:44, Validation Loss:1.774093553926502e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:45, Validation Loss:1.596220623443809e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:46, Validation Loss:1.5885349196787644e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:47, Validation Loss:1.7025322725784597e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:48, Validation Loss:1.7067773649177186e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:49, Validation Loss:1.900904792649138e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:50, Validation Loss:1.609370977506334e-05,Acc:99.4877%,lr:0.001\n",
      "Episode:51, Validation Loss:1.5698938394019517e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:52, Validation Loss:1.6819976445422043e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:53, Validation Loss:1.984935390294752e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:54, Validation Loss:1.6701370058825974e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:55, Validation Loss:1.4967952871846467e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:56, Validation Loss:1.757297574790737e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:57, Validation Loss:1.7780438400113523e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:58, Validation Loss:1.9329648612878905e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:59, Validation Loss:1.8155030144338765e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:60, Validation Loss:4.4237913747373417e-05,Acc:98.5297%,lr:0.001\n",
      "Episode:61, Validation Loss:1.7471330944359735e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:62, Validation Loss:1.281478204510699e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:63, Validation Loss:1.3685038893340265e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:64, Validation Loss:1.887165225720574e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:65, Validation Loss:1.7470940533639046e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:66, Validation Loss:1.4403505063320252e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:67, Validation Loss:1.5203479493293257e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:68, Validation Loss:1.7634183362966034e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:69, Validation Loss:1.5694316478814044e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:70, Validation Loss:1.3630582545975964e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:71, Validation Loss:1.2790440268158778e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:72, Validation Loss:1.618980577097952e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:73, Validation Loss:1.5857309175133667e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:74, Validation Loss:1.2809832732623609e-05,Acc:99.6807%,lr:0.001\n",
      "Episode:75, Validation Loss:1.3600064119492991e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:76, Validation Loss:1.2272030347354096e-05,Acc:99.6674%,lr:0.001\n",
      "Episode:77, Validation Loss:1.545478230773883e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:78, Validation Loss:1.2074184060784746e-05,Acc:99.6674%,lr:0.001\n",
      "Episode:79, Validation Loss:1.5754316831900446e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:80, Validation Loss:1.5743427123822627e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:81, Validation Loss:1.3253647005284001e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4862183971683324e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:83, Validation Loss:1.0033200149393456e-05,Acc:99.7139%,lr:0.001\n",
      "Episode:84, Validation Loss:1.353061063470784e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:85, Validation Loss:9.992539904469875e-06,Acc:99.6940%,lr:0.001\n",
      "Episode:86, Validation Loss:1.418381132838271e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:87, Validation Loss:1.2481950508338527e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:88, Validation Loss:1.4594312835075559e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:89, Validation Loss:1.6752838596228742e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:90, Validation Loss:1.448711330670494e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:91, Validation Loss:1.2337383466249977e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:92, Validation Loss:1.2998097568084186e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:93, Validation Loss:1.3374213717159624e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:94, Validation Loss:1.5657683300956916e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:95, Validation Loss:1.2111515343322081e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:96, Validation Loss:1.3681191510623915e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:97, Validation Loss:5.661785418176261e-05,Acc:97.8578%,lr:0.001\n",
      "Episode:98, Validation Loss:1.4233463628766669e-05,Acc:99.6274%,lr:0.001\n",
      "Episode:99, Validation Loss:1.3620926525861899e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:100, Validation Loss:1.4757004250308153e-05,Acc:99.6008%,lr:0.001\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:101, Validation Loss:1.3407881793439464e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0791385606923635e-05,Acc:99.7671%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0084660260219805e-05,Acc:99.7538%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.525752941178836e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.343048128131565e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.379671407859408e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.24742699458062e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.09644658431608e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:109, Validation Loss:8.916709970852134e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.235546884953075e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.632960725735542e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.385640274129318e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.307834270759881e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.427841188434783e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.205385736016232e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.093801104021552e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.29756908971891e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.250186961688218e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.340992585636488e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:120, Validation Loss:9.790028206690304e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.0030681656366353e-05,Acc:99.7405%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.353123587282877e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:123, Validation Loss:9.294767702270606e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.168184228951755e-06,Acc:99.7472%,lr:0.0001\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:125, Validation Loss:9.051538570376025e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:126, Validation Loss:9.010010078280726e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:127, Validation Loss:9.000206531119215e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:128, Validation Loss:9.021987000596903e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:129, Validation Loss:9.050793035223403e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:130, Validation Loss:9.04870361603232e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:131, Validation Loss:9.064615873456215e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:132, Validation Loss:9.038672551307506e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:133, Validation Loss:9.043435952448654e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:134, Validation Loss:9.010333757951393e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:135, Validation Loss:9.004227061392931e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:136, Validation Loss:9.034389062281434e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:137, Validation Loss:8.991729643082604e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:138, Validation Loss:8.95050246305439e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:139, Validation Loss:8.972134042361977e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:140, Validation Loss:8.981296612074589e-06,Acc:99.7671%,lr:1e-05\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:9.000206531119215e-06 Acc:0.9978045372896015==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.002788468421112237,Acc:10.3253%,lr:0.001\n",
      "Episode:2, Validation Loss:0.007072612043467914,Acc:14.4435%,lr:0.001\n",
      "Episode:3, Validation Loss:0.008533484254813815,Acc:18.5350%,lr:0.001\n",
      "Episode:4, Validation Loss:0.004745736520896771,Acc:31.9939%,lr:0.001\n",
      "Episode:5, Validation Loss:0.010253347280488488,Acc:21.3825%,lr:0.001\n",
      "Episode:6, Validation Loss:0.002400194890373331,Acc:59.9561%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00022753341914444623,Acc:93.4602%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00018124019054347872,Acc:95.2166%,lr:0.001\n",
      "Episode:9, Validation Loss:5.491926034849392e-05,Acc:98.5430%,lr:0.001\n",
      "Episode:10, Validation Loss:3.0186812818847438e-05,Acc:99.1351%,lr:0.001\n",
      "Episode:11, Validation Loss:3.5906549525545644e-05,Acc:98.9755%,lr:0.001\n",
      "Episode:12, Validation Loss:6.0800280302761004e-05,Acc:98.4565%,lr:0.001\n",
      "Episode:13, Validation Loss:4.131896601617237e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:14, Validation Loss:3.6171280399314834e-05,Acc:99.0353%,lr:0.001\n",
      "Episode:15, Validation Loss:3.052746534930455e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:16, Validation Loss:3.976235714539123e-05,Acc:98.8357%,lr:0.001\n",
      "Episode:17, Validation Loss:2.8505207521279694e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:18, Validation Loss:3.400277766462223e-05,Acc:99.0752%,lr:0.001\n",
      "Episode:19, Validation Loss:2.3752456209603425e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:20, Validation Loss:3.1568520846726785e-05,Acc:99.1617%,lr:0.001\n",
      "Episode:21, Validation Loss:4.5275076352370636e-05,Acc:98.8091%,lr:0.001\n",
      "Episode:22, Validation Loss:4.5345955446593486e-05,Acc:98.9023%,lr:0.001\n",
      "Episode:23, Validation Loss:1.830926446779332e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:24, Validation Loss:2.8554997373131663e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:25, Validation Loss:2.0426790721381896e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:26, Validation Loss:2.4200849149305025e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:27, Validation Loss:2.2910789186155383e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:28, Validation Loss:2.7434758514346306e-05,Acc:99.2615%,lr:0.001\n",
      "Episode:29, Validation Loss:2.355360424831459e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:30, Validation Loss:2.3828233685090423e-05,Acc:99.3014%,lr:0.001\n",
      "Episode:31, Validation Loss:2.728435775650118e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:32, Validation Loss:1.611211332502134e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:33, Validation Loss:3.628044496193418e-05,Acc:98.9355%,lr:0.001\n",
      "Episode:34, Validation Loss:1.6788006355270608e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:35, Validation Loss:2.2755085695298258e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:36, Validation Loss:1.566235323525595e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:37, Validation Loss:1.9012712650771833e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:38, Validation Loss:1.8410508203479504e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:39, Validation Loss:2.3408718591795243e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:40, Validation Loss:2.1940455466209473e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:41, Validation Loss:1.889171602859856e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:42, Validation Loss:2.477203682486339e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:43, Validation Loss:3.695730872139484e-05,Acc:98.8490%,lr:0.001\n",
      "Episode:44, Validation Loss:1.4645732331042772e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:45, Validation Loss:1.8155856630389112e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:46, Validation Loss:1.892790984723963e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:47, Validation Loss:1.8227876038673783e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:48, Validation Loss:1.7607922897939395e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:49, Validation Loss:2.0584853932456764e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:50, Validation Loss:2.721129233745843e-05,Acc:99.2881%,lr:0.001\n",
      "Episode:51, Validation Loss:1.518219904198982e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:52, Validation Loss:1.6565436152708474e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:53, Validation Loss:2.111052622999167e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:54, Validation Loss:1.3668072911123262e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:55, Validation Loss:1.7895350538431612e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:56, Validation Loss:1.640056098400099e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:57, Validation Loss:1.6998067088278935e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:58, Validation Loss:1.4102969480468147e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:59, Validation Loss:2.1184075619537398e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:60, Validation Loss:1.47772356548076e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:61, Validation Loss:1.8924175665663846e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:62, Validation Loss:1.7049800009516833e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:63, Validation Loss:1.7389483111925084e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:64, Validation Loss:1.768648275460766e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:65, Validation Loss:1.4708975521947609e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:66, Validation Loss:1.5500175562364343e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:67, Validation Loss:2.0514221532454582e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:68, Validation Loss:1.4879023307413567e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:69, Validation Loss:1.5625615375774857e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:70, Validation Loss:1.1825482796908107e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:71, Validation Loss:1.344912973010812e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6039497457634513e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:73, Validation Loss:1.87296053036174e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:74, Validation Loss:1.5865443919383632e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:75, Validation Loss:1.520676378243246e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:76, Validation Loss:1.3975290366334517e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:77, Validation Loss:1.514053987599991e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:78, Validation Loss:1.451385266150466e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:79, Validation Loss:1.1742603886104473e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:80, Validation Loss:1.5314834965781438e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:81, Validation Loss:1.579300558323271e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:82, Validation Loss:1.8515927772482e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:83, Validation Loss:1.6243935805368025e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:84, Validation Loss:1.2500536453401914e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:85, Validation Loss:1.460657142810055e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:86, Validation Loss:1.2283003670614832e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:87, Validation Loss:1.1533816929258008e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:88, Validation Loss:1.2968336913877678e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:89, Validation Loss:1.6718791231069885e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:90, Validation Loss:1.962286571411147e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:91, Validation Loss:1.2720380596532514e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:92, Validation Loss:1.0863651337668248e-05,Acc:99.6407%,lr:0.001\n",
      "Episode:93, Validation Loss:1.189289432395465e-05,Acc:99.6674%,lr:0.001\n",
      "Episode:94, Validation Loss:1.1717182887773475e-05,Acc:99.6141%,lr:0.001\n",
      "Episode:95, Validation Loss:1.5349011362891705e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:96, Validation Loss:1.6010495938827126e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:97, Validation Loss:1.0781464893173834e-05,Acc:99.7073%,lr:0.001\n",
      "Episode:98, Validation Loss:1.241416667841658e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:99, Validation Loss:1.1535337461600656e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:100, Validation Loss:1.3332026093300052e-05,Acc:99.6008%,lr:0.001\n",
      "Episode:101, Validation Loss:1.2776949288332569e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:102, Validation Loss:1.5736187780767284e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:103, Validation Loss:1.1290440332276103e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:104, Validation Loss:1.1031129110266718e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:105, Validation Loss:1.2614789738776275e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:106, Validation Loss:1.3358011796171338e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:107, Validation Loss:1.194248946612724e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:108, Validation Loss:3.656853498709701e-05,Acc:98.7493%,lr:0.001\n",
      "Episode:109, Validation Loss:1.5212565356376412e-05,Acc:99.5409%,lr:0.001\n",
      "Episode:110, Validation Loss:1.6553647620139362e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:111, Validation Loss:1.3212473823500999e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:112, Validation Loss:1.5505735213016926e-05,Acc:99.5476%,lr:0.001\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:113, Validation Loss:1.2111650323445082e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.664249285539066e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.56595782568518e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.429000214453063e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.051541978182665e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.350374277316042e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.007344584867202e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:120, Validation Loss:9.40921005895336e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.589881486850191e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.985650580737985e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:123, Validation Loss:9.273916324803188e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.030848846863578e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:125, Validation Loss:9.286122375645804e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:126, Validation Loss:9.447002231848706e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:127, Validation Loss:9.575614682260875e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:128, Validation Loss:8.582758737252023e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:129, Validation Loss:8.963127271372927e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.09248634123983e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:131, Validation Loss:8.945319436995635e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:132, Validation Loss:8.455749040262705e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:133, Validation Loss:8.532948097779551e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:134, Validation Loss:8.69509699019508e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:135, Validation Loss:8.588165160526052e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:136, Validation Loss:8.615162858049135e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:137, Validation Loss:9.051163184984614e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:138, Validation Loss:9.00882397568969e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:139, Validation Loss:8.967198639925698e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:140, Validation Loss:8.872459291832849e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:141, Validation Loss:8.789603151373581e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:142, Validation Loss:8.367919144052429e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:143, Validation Loss:8.708831752116282e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:144, Validation Loss:8.865909146690359e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:145, Validation Loss:9.278447158631193e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:146, Validation Loss:8.778359991787088e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:147, Validation Loss:8.493865388509685e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:148, Validation Loss:8.617341344913761e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:149, Validation Loss:8.161730237028078e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:150, Validation Loss:8.800821186131119e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:151, Validation Loss:9.12714763825489e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:152, Validation Loss:8.690086739932965e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:153, Validation Loss:8.946499157694237e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:154, Validation Loss:8.708941529960176e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:155, Validation Loss:8.665838243946503e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:156, Validation Loss:8.825475985609234e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:157, Validation Loss:8.464947608805457e-06,Acc:99.7538%,lr:0.0001\n",
      "Episode:158, Validation Loss:8.348631934342679e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:159, Validation Loss:8.277238849938357e-06,Acc:99.7671%,lr:0.0001\n",
      "Episode:160, Validation Loss:8.798785966555639e-06,Acc:99.7405%,lr:0.0001\n",
      "Episode:161, Validation Loss:9.02287820399335e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:162, Validation Loss:8.420703187758365e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:163, Validation Loss:8.894608873239725e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:164, Validation Loss:8.6540386824759e-06,Acc:99.7538%,lr:0.0001\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:165, Validation Loss:8.601262228884753e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:166, Validation Loss:8.498649856091878e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:167, Validation Loss:8.509245098695952e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:168, Validation Loss:8.526052989664925e-06,Acc:99.7538%,lr:1e-05\n",
      "Episode:169, Validation Loss:8.516488670529532e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:170, Validation Loss:8.431078735264378e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:171, Validation Loss:8.489342454597072e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:172, Validation Loss:8.577873894274254e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:173, Validation Loss:8.558544737562775e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:174, Validation Loss:8.537942966441696e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:175, Validation Loss:8.574487370935857e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:176, Validation Loss:8.54415254778062e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:177, Validation Loss:8.532225890612382e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:178, Validation Loss:8.485984262523873e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:179, Validation Loss:8.524545221107145e-06,Acc:99.7671%,lr:1e-05\n",
      "Episode:180, Validation Loss:8.546778216326549e-06,Acc:99.7671%,lr:1e-05\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:8.431078735264378e-06 Acc:0.9978045372896015==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.003926207622553201,Acc:13.8846%,lr:0.001\n",
      "Episode:2, Validation Loss:0.010546376800181806,Acc:9.8596%,lr:0.001\n",
      "Episode:3, Validation Loss:0.02808817392115377,Acc:9.8596%,lr:0.001\n",
      "Episode:4, Validation Loss:0.05040545016576744,Acc:9.8596%,lr:0.001\n",
      "Episode:5, Validation Loss:0.023787897366438788,Acc:9.8796%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0275827276755074,Acc:9.9661%,lr:0.001\n",
      "Episode:7, Validation Loss:0.017021755045675786,Acc:16.5924%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0021105874806898305,Acc:67.7533%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0008926425625103993,Acc:86.9470%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00013120119506335211,Acc:96.9130%,lr:0.001\n",
      "Episode:11, Validation Loss:7.772593540343035e-05,Acc:98.0440%,lr:0.001\n",
      "Episode:12, Validation Loss:7.060643301126875e-05,Acc:98.2769%,lr:0.001\n",
      "Episode:13, Validation Loss:3.188223912682443e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:14, Validation Loss:5.6265648443274896e-05,Acc:98.5696%,lr:0.001\n",
      "Episode:15, Validation Loss:4.955875472857181e-05,Acc:98.7293%,lr:0.001\n",
      "Episode:16, Validation Loss:4.3629352470515264e-05,Acc:98.9488%,lr:0.001\n",
      "Episode:17, Validation Loss:6.20365819922465e-05,Acc:98.5563%,lr:0.001\n",
      "Episode:18, Validation Loss:3.201513553096358e-05,Acc:99.0619%,lr:0.001\n",
      "Episode:19, Validation Loss:2.9900851495592238e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:20, Validation Loss:3.2858255271402143e-05,Acc:99.0752%,lr:0.001\n",
      "Episode:21, Validation Loss:4.1173905229371795e-05,Acc:98.9222%,lr:0.001\n",
      "Episode:22, Validation Loss:3.588435832242767e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:23, Validation Loss:2.955068895404555e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:24, Validation Loss:2.9250455922462946e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:25, Validation Loss:3.251539237559829e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:26, Validation Loss:2.735306682141588e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:27, Validation Loss:4.0956261259148076e-05,Acc:98.7892%,lr:0.001\n",
      "Episode:28, Validation Loss:2.7534050599169837e-05,Acc:99.1883%,lr:0.001\n",
      "Episode:29, Validation Loss:2.7842336835483536e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:30, Validation Loss:3.553629362664849e-05,Acc:99.0819%,lr:0.001\n",
      "Episode:31, Validation Loss:2.6053453660972516e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:32, Validation Loss:2.1738030264758436e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:33, Validation Loss:2.231443461072111e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:34, Validation Loss:3.0427677924295885e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:35, Validation Loss:2.316708511888969e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:36, Validation Loss:1.978836119656759e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:37, Validation Loss:2.3040651155342147e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:38, Validation Loss:2.0306449792186195e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:39, Validation Loss:1.6222661085375754e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:40, Validation Loss:2.1003264896400627e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:41, Validation Loss:2.068455232077195e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:42, Validation Loss:2.7171016152343163e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:43, Validation Loss:1.7164234249423773e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:44, Validation Loss:2.1972667851413006e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:45, Validation Loss:2.2084064496401405e-05,Acc:99.4278%,lr:0.001\n",
      "Episode:46, Validation Loss:2.468043194633783e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:47, Validation Loss:2.5832235830985385e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:48, Validation Loss:2.679787328358095e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:49, Validation Loss:1.739910090264466e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:50, Validation Loss:2.1178793952966447e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:51, Validation Loss:2.5642266100842942e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:52, Validation Loss:1.9925723624248467e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:53, Validation Loss:2.1370419877135868e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:54, Validation Loss:1.6847318331415755e-05,Acc:99.4678%,lr:0.001\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:55, Validation Loss:2.2119535023573194e-05,Acc:99.4079%,lr:0.0001\n",
      "Episode:56, Validation Loss:1.5945813166477368e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:57, Validation Loss:1.3812434385021277e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:58, Validation Loss:1.3106750990687615e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:59, Validation Loss:1.3127351429666099e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:60, Validation Loss:1.3555338299287927e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:61, Validation Loss:1.3128510889405222e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.301978190643457e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.2657251257349508e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.345894164188593e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.3669437582782227e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.3422670187213593e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.2313563734298932e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.2504315834885767e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.1485501976119775e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.3431232951977528e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.3268783955717267e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.2748814157893276e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.2785507375107388e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.3332383355356152e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.2954639730769696e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.2501622366477737e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.312282298130274e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.283162196945838e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.3184588640188712e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.2365657294419511e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.2458457259753612e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.310761979550042e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.2631159943452449e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.3561363270447153e-05,Acc:99.6607%,lr:0.0001\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:85, Validation Loss:1.2446773315868281e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:86, Validation Loss:1.2577858099017613e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:87, Validation Loss:1.2615030546785472e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:88, Validation Loss:1.2641570854697365e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:89, Validation Loss:1.2545702066543882e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:90, Validation Loss:1.260115814045608e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:91, Validation Loss:1.2482155178107313e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:92, Validation Loss:1.2386384472824937e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:93, Validation Loss:1.2407028098007565e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:94, Validation Loss:1.2373025746876414e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:95, Validation Loss:1.2318090881499755e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:96, Validation Loss:1.2381851129612041e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:97, Validation Loss:1.2247229476891372e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:98, Validation Loss:1.2341399876175665e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:99, Validation Loss:1.2272165947078303e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:100, Validation Loss:1.222143972290188e-05,Acc:99.6873%,lr:1e-05\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:1.3106750990687615e-05 Acc:0.9970727163861354==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.008231928451484283,Acc:9.4804%,lr:0.001\n",
      "Episode:2, Validation Loss:0.01755654014804138,Acc:9.4804%,lr:0.001\n",
      "Episode:3, Validation Loss:0.020530422277439776,Acc:9.4804%,lr:0.001\n",
      "Episode:4, Validation Loss:0.019869052089305148,Acc:9.4804%,lr:0.001\n",
      "Episode:5, Validation Loss:0.017716433218191517,Acc:9.5802%,lr:0.001\n",
      "Episode:6, Validation Loss:0.010612639812372789,Acc:16.2132%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0034163808736978165,Acc:44.6876%,lr:0.001\n",
      "Episode:8, Validation Loss:0.001281076582849688,Acc:73.4216%,lr:0.001\n",
      "Episode:9, Validation Loss:0.00031434962844810563,Acc:90.7658%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00014139514129704784,Acc:96.3076%,lr:0.001\n",
      "Episode:11, Validation Loss:0.00024319101625887524,Acc:93.3205%,lr:0.001\n",
      "Episode:12, Validation Loss:4.2307225976286274e-05,Acc:98.7892%,lr:0.001\n",
      "Episode:13, Validation Loss:4.017468638270528e-05,Acc:98.8690%,lr:0.001\n",
      "Episode:14, Validation Loss:0.0005469358766017881,Acc:89.1092%,lr:0.001\n",
      "Episode:15, Validation Loss:4.056325131139628e-05,Acc:98.7759%,lr:0.001\n",
      "Episode:16, Validation Loss:3.407868562812347e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:17, Validation Loss:4.4680325614661325e-05,Acc:98.8291%,lr:0.001\n",
      "Episode:18, Validation Loss:2.951472655645539e-05,Acc:99.1950%,lr:0.001\n",
      "Episode:19, Validation Loss:5.6365045240702453e-05,Acc:98.3501%,lr:0.001\n",
      "Episode:20, Validation Loss:3.376771583702106e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:21, Validation Loss:4.289810148020497e-05,Acc:98.8025%,lr:0.001\n",
      "Episode:22, Validation Loss:3.517291709799529e-05,Acc:99.0752%,lr:0.001\n",
      "Episode:23, Validation Loss:2.349145917662936e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:24, Validation Loss:2.9353077248493265e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:25, Validation Loss:2.9935839074603036e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:26, Validation Loss:2.1724722346108907e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:27, Validation Loss:2.4305935001097297e-05,Acc:99.2482%,lr:0.001\n",
      "Episode:28, Validation Loss:2.7455185836747484e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:29, Validation Loss:2.181273397135327e-05,Acc:99.3347%,lr:0.001\n",
      "Episode:30, Validation Loss:2.4760036388681395e-05,Acc:99.2748%,lr:0.001\n",
      "Episode:31, Validation Loss:2.1605433344862812e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:32, Validation Loss:2.1963671241883755e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:33, Validation Loss:2.5962362555768007e-05,Acc:99.0952%,lr:0.001\n",
      "Episode:34, Validation Loss:2.1068444341078115e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:35, Validation Loss:1.958913003933992e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:36, Validation Loss:2.116669543391335e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:37, Validation Loss:2.7980651652180072e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:38, Validation Loss:1.5573965326198427e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:39, Validation Loss:2.2074332079458488e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:40, Validation Loss:1.7442046484661057e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:41, Validation Loss:1.615872775166622e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:42, Validation Loss:2.1065844897153284e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:43, Validation Loss:1.7399381922772207e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:44, Validation Loss:2.1867322913375922e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:45, Validation Loss:2.823773305336481e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:46, Validation Loss:1.3905068947813101e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:47, Validation Loss:1.7601320334534773e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:48, Validation Loss:1.700024814648857e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:49, Validation Loss:1.8896135334209263e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:50, Validation Loss:1.9087482995476505e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:51, Validation Loss:1.8505969232078497e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:52, Validation Loss:1.7111503925142502e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:53, Validation Loss:1.5361153563829917e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:54, Validation Loss:2.5499582723874577e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:55, Validation Loss:1.4064909484950965e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:56, Validation Loss:1.5402343041124667e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:57, Validation Loss:2.9000644426163098e-05,Acc:99.0619%,lr:0.001\n",
      "Episode:58, Validation Loss:1.87315644206746e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:59, Validation Loss:1.4930986131679417e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:60, Validation Loss:1.4305863007491685e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5108271478847245e-05,Acc:99.5676%,lr:0.001\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:62, Validation Loss:1.59973387071912e-05,Acc:99.5077%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.1838277871638396e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.0892662119513682e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.071747926512241e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:66, Validation Loss:9.89505101405974e-06,Acc:99.6540%,lr:0.0001\n",
      "Episode:67, Validation Loss:9.189391412412435e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.025820569450068e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:69, Validation Loss:9.486711079118558e-06,Acc:99.6274%,lr:0.0001\n",
      "Episode:70, Validation Loss:9.250007339298238e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:71, Validation Loss:9.238466120550998e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:72, Validation Loss:9.280448966211572e-06,Acc:99.6540%,lr:0.0001\n",
      "Episode:73, Validation Loss:9.294877805405134e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:74, Validation Loss:9.107249842535457e-06,Acc:99.6474%,lr:0.0001\n",
      "Episode:75, Validation Loss:9.09486251186963e-06,Acc:99.6407%,lr:0.0001\n",
      "Episode:76, Validation Loss:9.016607777815871e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:77, Validation Loss:9.103429706782195e-06,Acc:99.6540%,lr:0.0001\n",
      "Episode:78, Validation Loss:8.882602163595509e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:79, Validation Loss:8.827158853468183e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:80, Validation Loss:8.210171743712892e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:81, Validation Loss:8.437613328416565e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:82, Validation Loss:8.045462535188771e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:83, Validation Loss:8.255649635863315e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:84, Validation Loss:8.37485406154462e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:85, Validation Loss:7.849392986061267e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.015856161682867e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:87, Validation Loss:8.441680561131278e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:88, Validation Loss:8.20572322390527e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:89, Validation Loss:8.626715353538348e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:90, Validation Loss:7.952512874203e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:91, Validation Loss:7.810385496377961e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:92, Validation Loss:8.21907491738009e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:93, Validation Loss:8.050474768174748e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:94, Validation Loss:8.484735626680996e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.171368133806832e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:96, Validation Loss:7.86402366034809e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:97, Validation Loss:7.409334116318008e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:98, Validation Loss:8.36498062336693e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:99, Validation Loss:8.5049839462934e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.394201481001684e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:101, Validation Loss:8.084100432751953e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:102, Validation Loss:7.909971767854694e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:103, Validation Loss:7.826902546540252e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:104, Validation Loss:8.32573248057473e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:105, Validation Loss:8.548248375091048e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:106, Validation Loss:7.88086711642636e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:107, Validation Loss:8.242404575756262e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:108, Validation Loss:8.170950429652965e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:109, Validation Loss:8.437948610119838e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.44818900711252e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:111, Validation Loss:8.146481448576904e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:112, Validation Loss:8.14938480689389e-06,Acc:99.7073%,lr:0.0001\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:113, Validation Loss:7.853781125731244e-06,Acc:99.6740%,lr:1e-05\n",
      "Episode:114, Validation Loss:7.72073880550779e-06,Acc:99.6674%,lr:1e-05\n",
      "Episode:115, Validation Loss:7.754663675507975e-06,Acc:99.6607%,lr:1e-05\n",
      "Episode:116, Validation Loss:7.912349363567269e-06,Acc:99.6607%,lr:1e-05\n",
      "Episode:117, Validation Loss:7.861788541933122e-06,Acc:99.6740%,lr:1e-05\n",
      "Episode:118, Validation Loss:7.660765993695053e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:119, Validation Loss:7.735672340864716e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:120, Validation Loss:7.712231061331059e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:121, Validation Loss:7.758143696668548e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:122, Validation Loss:7.78149724067126e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:123, Validation Loss:7.744117319439154e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:124, Validation Loss:7.685991631765405e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:125, Validation Loss:7.718626987733064e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:126, Validation Loss:7.683547862643895e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:127, Validation Loss:7.655060674798646e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:128, Validation Loss:7.724245531480395e-06,Acc:99.6873%,lr:1e-05\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:7.88086711642636e-06 Acc:0.9972723039052624==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0020774289857571127,Acc:42.9712%,lr:0.001\n",
      "Episode:2, Validation Loss:0.004359939539157323,Acc:13.0131%,lr:0.001\n",
      "Episode:3, Validation Loss:0.0030959692553967568,Acc:30.4903%,lr:0.001\n",
      "Episode:4, Validation Loss:0.002722413071487789,Acc:44.6876%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0007465594099251764,Acc:77.3002%,lr:0.001\n",
      "Episode:6, Validation Loss:0.001397976538400737,Acc:72.1642%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0002532336226671361,Acc:93.2606%,lr:0.001\n",
      "Episode:8, Validation Loss:5.8114717262613344e-05,Acc:98.3501%,lr:0.001\n",
      "Episode:9, Validation Loss:7.234224504985445e-05,Acc:98.1571%,lr:0.001\n",
      "Episode:10, Validation Loss:8.155272381485409e-05,Acc:98.0906%,lr:0.001\n",
      "Episode:11, Validation Loss:7.086802690608576e-05,Acc:98.3035%,lr:0.001\n",
      "Episode:12, Validation Loss:4.198126233164941e-05,Acc:98.8956%,lr:0.001\n",
      "Episode:13, Validation Loss:4.864367995641402e-05,Acc:98.7493%,lr:0.001\n",
      "Episode:14, Validation Loss:5.282380872005617e-05,Acc:98.5763%,lr:0.001\n",
      "Episode:15, Validation Loss:5.626597422958967e-05,Acc:98.5231%,lr:0.001\n",
      "Episode:16, Validation Loss:5.562752921474518e-05,Acc:98.5763%,lr:0.001\n",
      "Episode:17, Validation Loss:3.408443949277446e-05,Acc:99.0752%,lr:0.001\n",
      "Episode:18, Validation Loss:3.264469465901455e-05,Acc:99.0220%,lr:0.001\n",
      "Episode:19, Validation Loss:3.3702114134120825e-05,Acc:98.9621%,lr:0.001\n",
      "Episode:20, Validation Loss:4.753554339624912e-05,Acc:98.7559%,lr:0.001\n",
      "Episode:21, Validation Loss:3.329274516549465e-05,Acc:99.0353%,lr:0.001\n",
      "Episode:22, Validation Loss:2.7017431387814226e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:23, Validation Loss:3.740697562313867e-05,Acc:98.9023%,lr:0.001\n",
      "Episode:24, Validation Loss:2.5007833313615997e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:25, Validation Loss:3.00465110649995e-05,Acc:99.1750%,lr:0.001\n",
      "Episode:26, Validation Loss:2.1745843002260997e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:27, Validation Loss:3.039153252748916e-05,Acc:99.2349%,lr:0.001\n",
      "Episode:28, Validation Loss:1.9786277725548098e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:29, Validation Loss:2.579337555854892e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:30, Validation Loss:2.7977613375700207e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:31, Validation Loss:2.122152778627027e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:32, Validation Loss:2.0935556859196353e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:33, Validation Loss:2.3804004427721445e-05,Acc:99.3746%,lr:0.001\n",
      "Episode:34, Validation Loss:2.4764890468459225e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:35, Validation Loss:2.307918495990251e-05,Acc:99.3147%,lr:0.001\n",
      "Episode:36, Validation Loss:2.79250558891757e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:37, Validation Loss:2.0686301021259167e-05,Acc:99.4012%,lr:0.001\n",
      "Episode:38, Validation Loss:1.840656825234279e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:39, Validation Loss:3.095580966686284e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:40, Validation Loss:2.5249889757285677e-05,Acc:99.3613%,lr:0.001\n",
      "Episode:41, Validation Loss:1.8285957548781455e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:42, Validation Loss:2.1323168903190722e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:43, Validation Loss:2.8423000629945442e-05,Acc:99.2016%,lr:0.001\n",
      "Episode:44, Validation Loss:2.2332609372933335e-05,Acc:99.3480%,lr:0.001\n",
      "Episode:45, Validation Loss:1.8737303662737103e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:46, Validation Loss:1.7519441491059697e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:47, Validation Loss:2.292303808242148e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:48, Validation Loss:2.1651594161463865e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:49, Validation Loss:2.0768314101335794e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:50, Validation Loss:1.982061261664718e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:51, Validation Loss:1.596233021663966e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:52, Validation Loss:2.8786891923281622e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:53, Validation Loss:1.7806853052900584e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:54, Validation Loss:1.760624885939765e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:55, Validation Loss:1.739526299982678e-05,Acc:99.4744%,lr:0.001\n",
      "Episode:56, Validation Loss:2.0442025537825847e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:57, Validation Loss:1.5188660274359069e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:58, Validation Loss:1.781097346288891e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:59, Validation Loss:2.4711568641885455e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:60, Validation Loss:2.4642545315238436e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:61, Validation Loss:1.946254402565612e-05,Acc:99.5010%,lr:0.001\n",
      "Episode:62, Validation Loss:2.0307602312391796e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:63, Validation Loss:1.790838140240132e-05,Acc:99.5276%,lr:0.001\n",
      "Episode:64, Validation Loss:1.812212331010215e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:65, Validation Loss:1.93386166587925e-05,Acc:99.4145%,lr:0.001\n",
      "Episode:66, Validation Loss:1.602230172728986e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:67, Validation Loss:2.018190635584221e-05,Acc:99.3879%,lr:0.001\n",
      "Episode:68, Validation Loss:2.0225491397284548e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:69, Validation Loss:1.5944698163124862e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:70, Validation Loss:1.80977854676216e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:71, Validation Loss:1.5880202789160237e-05,Acc:99.5143%,lr:0.001\n",
      "Episode:72, Validation Loss:1.7827584661454644e-05,Acc:99.4545%,lr:0.001\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:73, Validation Loss:2.1477057458191574e-05,Acc:99.3879%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.3771818937264979e-05,Acc:99.5476%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.166884649643347e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.1376649041927612e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.070175387942262e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.0996436306530269e-05,Acc:99.6274%,lr:0.0001\n",
      "Episode:79, Validation Loss:9.909618922744267e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:80, Validation Loss:9.991945056330855e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.0315348663679671e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:82, Validation Loss:9.924325684059342e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0428267885694707e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:84, Validation Loss:9.791053398847818e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.88858216059564e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.0050208729193459e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.0327707229359455e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0074655931287085e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.0126868206998972e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0354747276625053e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0067455638597829e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.0377818437377561e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.0302355533423486e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0648571710960966e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0162544999412653e-05,Acc:99.6540%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0214306515246267e-05,Acc:99.6407%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0203662293166761e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.920276961930695e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0770355474507924e-05,Acc:99.6474%,lr:0.0001\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:100, Validation Loss:1.129321038339335e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:101, Validation Loss:1.0932284873195786e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:102, Validation Loss:1.075421003016968e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:103, Validation Loss:1.0694007191408752e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:104, Validation Loss:1.073287892646755e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:105, Validation Loss:1.0692087666868695e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:106, Validation Loss:1.072261479874863e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:107, Validation Loss:1.0763376255529415e-05,Acc:99.6474%,lr:1e-05\n",
      "Episode:108, Validation Loss:1.0628044694725542e-05,Acc:99.6540%,lr:1e-05\n",
      "Episode:109, Validation Loss:1.0616471380635766e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:110, Validation Loss:1.063261859083745e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:111, Validation Loss:1.0509287156414965e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.0476566822141731e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.0509553151213236e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.0546442874950228e-05,Acc:99.6474%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.0500148162528288e-05,Acc:99.6674%,lr:1e-05\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:1.0126868206998972e-05 Acc:0.9970727163861354==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10161\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10161_s9.npy\n",
      "shape of top1_dig_csv: (10161, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10161_s9.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s9.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10161, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75161, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75161_s9.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75161_s9.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step8\n",
      "Step: 9\n",
      "global_data len: 75161\n",
      "validation rate: 0.19999733904551562\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.003340049650264332,Acc:10.2581%,lr:0.001\n",
      "Episode:2, Validation Loss:0.001821488554392678,Acc:49.2150%,lr:0.001\n",
      "Episode:3, Validation Loss:0.0007809842914390463,Acc:75.3127%,lr:0.001\n",
      "Episode:4, Validation Loss:0.0052481740633815825,Acc:16.3052%,lr:0.001\n",
      "Episode:5, Validation Loss:0.002163163821959889,Acc:52.3616%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0003583991464907467,Acc:89.0234%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00010040318647904115,Acc:97.6051%,lr:0.001\n",
      "Episode:8, Validation Loss:6.641654080615644e-05,Acc:98.4965%,lr:0.001\n",
      "Episode:9, Validation Loss:5.407960978378762e-05,Acc:98.7693%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00012478227526377717,Acc:97.1195%,lr:0.001\n",
      "Episode:11, Validation Loss:5.510660059880931e-05,Acc:98.7560%,lr:0.001\n",
      "Episode:12, Validation Loss:4.5575767169652495e-05,Acc:98.8358%,lr:0.001\n",
      "Episode:13, Validation Loss:4.8994790750767334e-05,Acc:98.8824%,lr:0.001\n",
      "Episode:14, Validation Loss:4.6213226741801366e-05,Acc:98.8757%,lr:0.001\n",
      "Episode:15, Validation Loss:4.76406922116836e-05,Acc:98.8491%,lr:0.001\n",
      "Episode:16, Validation Loss:4.0569678846074586e-05,Acc:98.9622%,lr:0.001\n",
      "Episode:17, Validation Loss:3.86534474577959e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:18, Validation Loss:3.483171360155824e-05,Acc:99.0687%,lr:0.001\n",
      "Episode:19, Validation Loss:3.258708586639756e-05,Acc:99.0021%,lr:0.001\n",
      "Episode:20, Validation Loss:3.938371724012432e-05,Acc:98.8491%,lr:0.001\n",
      "Episode:21, Validation Loss:2.6994018293540486e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:22, Validation Loss:3.132210799580625e-05,Acc:99.1951%,lr:0.001\n",
      "Episode:23, Validation Loss:3.3641905271551784e-05,Acc:98.9489%,lr:0.001\n",
      "Episode:24, Validation Loss:3.2808254718257115e-05,Acc:98.9223%,lr:0.001\n",
      "Episode:25, Validation Loss:2.4003630908956518e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:26, Validation Loss:2.6897239801635e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:27, Validation Loss:2.5300543317635716e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:28, Validation Loss:2.2432367176614493e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4994726772576238e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:30, Validation Loss:3.313343102601121e-05,Acc:99.0687%,lr:0.001\n",
      "Episode:31, Validation Loss:2.3589168850951068e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:32, Validation Loss:2.1685266613508235e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:33, Validation Loss:2.5487722736793734e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:34, Validation Loss:2.5413704400623397e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:35, Validation Loss:3.9776171195286585e-05,Acc:98.9556%,lr:0.001\n",
      "Episode:36, Validation Loss:2.4554445419436742e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:37, Validation Loss:3.308354758723436e-05,Acc:99.1352%,lr:0.001\n",
      "Episode:38, Validation Loss:2.200996747092721e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:39, Validation Loss:2.434486782246682e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:40, Validation Loss:2.1617453170622074e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:41, Validation Loss:1.8599667821075528e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:42, Validation Loss:2.6480660490303073e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:43, Validation Loss:1.9799793404767397e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:44, Validation Loss:2.2279413180557606e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:45, Validation Loss:1.924384779139695e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:46, Validation Loss:2.1663596263792744e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:47, Validation Loss:2.2540609541875986e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:48, Validation Loss:2.460259876792389e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:49, Validation Loss:2.375455614587787e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8381131448628833e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:51, Validation Loss:1.8558057552692244e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:52, Validation Loss:2.152512284063156e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:53, Validation Loss:2.1878728618772978e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:54, Validation Loss:2.055811958943611e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:55, Validation Loss:1.8873902202790534e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:56, Validation Loss:2.0205000413709605e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:57, Validation Loss:1.5764951419943728e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:58, Validation Loss:3.43634167060597e-05,Acc:98.8491%,lr:0.001\n",
      "Episode:59, Validation Loss:2.341640894705189e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:60, Validation Loss:2.0970956913327888e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:61, Validation Loss:2.3689645775229514e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:62, Validation Loss:2.7810624689597312e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:63, Validation Loss:1.7785737211674753e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:64, Validation Loss:2.0328150197720834e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:65, Validation Loss:1.9962673650200997e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:66, Validation Loss:2.036826329939206e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:67, Validation Loss:2.3023981292211134e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:68, Validation Loss:1.8787261694887807e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:69, Validation Loss:1.5975749674002864e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:70, Validation Loss:2.2825410581149753e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:71, Validation Loss:1.592601858502717e-05,Acc:99.6142%,lr:0.001\n",
      "Episode:72, Validation Loss:1.7296253347163698e-05,Acc:99.4878%,lr:0.001\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:73, Validation Loss:1.6551000900524943e-05,Acc:99.5011%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.3313768704150698e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.2863336139402693e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.2649338012893286e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.2324733311184515e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.2451849456285704e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.2080994756330259e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.2200223376152678e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.2482535116326911e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.1546653726382529e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.1815356707498787e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.2352533122755592e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.2248289893307446e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.1189277492019488e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.2199664316197116e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.1853708462078895e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.1387139209608104e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.1513652677730543e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.1838343931969697e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.1239806729150285e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.1921956774120939e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.1520644164376037e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.1505495024296818e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.144141377980299e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.2365957717607001e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.2629111083060851e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.2125582103391969e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.2427356824954895e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.1788087332211812e-05,Acc:99.6740%,lr:0.0001\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:102, Validation Loss:1.182694635153245e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:103, Validation Loss:1.1760293623306622e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:104, Validation Loss:1.1845751979773415e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:105, Validation Loss:1.1831339000872456e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:106, Validation Loss:1.1806297749171888e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:107, Validation Loss:1.1818053776040444e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:108, Validation Loss:1.1749911191910426e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:109, Validation Loss:1.1831287980107408e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:110, Validation Loss:1.1864470188100011e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:111, Validation Loss:1.186744624450446e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.1807068202995505e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.1793040900187346e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.1785338747257117e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.1687832024541226e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:116, Validation Loss:1.1737677701136782e-05,Acc:99.7073%,lr:1e-05\n",
      "Episode:117, Validation Loss:1.1762038768904047e-05,Acc:99.7073%,lr:1e-05\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:1.1762038768904047e-05 Acc:0.9970729111229377==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.002772599141479744,Acc:19.6514%,lr:0.001\n",
      "Episode:2, Validation Loss:0.004500576224080929,Acc:20.3965%,lr:0.001\n",
      "Episode:3, Validation Loss:0.011124356431235272,Acc:14.9015%,lr:0.001\n",
      "Episode:4, Validation Loss:0.011641462538203005,Acc:14.4159%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0038651221130933454,Acc:45.5894%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0034493241080456177,Acc:58.8744%,lr:0.001\n",
      "Episode:7, Validation Loss:0.001293927288359946,Acc:70.4364%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00020480823285278963,Acc:95.0439%,lr:0.001\n",
      "Episode:9, Validation Loss:0.00011492329647148969,Acc:97.2924%,lr:0.001\n",
      "Episode:10, Validation Loss:7.809335841713527e-05,Acc:97.9643%,lr:0.001\n",
      "Episode:11, Validation Loss:7.959145546046706e-05,Acc:97.9111%,lr:0.001\n",
      "Episode:12, Validation Loss:4.6343856628442964e-05,Acc:98.7094%,lr:0.001\n",
      "Episode:13, Validation Loss:5.5500100742968045e-05,Acc:98.4633%,lr:0.001\n",
      "Episode:14, Validation Loss:4.893530258326977e-05,Acc:98.5697%,lr:0.001\n",
      "Episode:15, Validation Loss:3.931228432778572e-05,Acc:99.1086%,lr:0.001\n",
      "Episode:16, Validation Loss:3.063034374284706e-05,Acc:99.1751%,lr:0.001\n",
      "Episode:17, Validation Loss:3.7189320021246013e-05,Acc:99.0021%,lr:0.001\n",
      "Episode:18, Validation Loss:3.8764410899548595e-05,Acc:99.0354%,lr:0.001\n",
      "Episode:19, Validation Loss:3.667455711791083e-05,Acc:98.8757%,lr:0.001\n",
      "Episode:20, Validation Loss:2.2250581832583786e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:21, Validation Loss:2.3184496243476884e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:22, Validation Loss:2.6460022513396313e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:23, Validation Loss:2.213373635025688e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:24, Validation Loss:2.7769701699109203e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:25, Validation Loss:2.6106737450482902e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:26, Validation Loss:2.5848310615246825e-05,Acc:99.2084%,lr:0.001\n",
      "Episode:27, Validation Loss:2.08716071855144e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:28, Validation Loss:1.838728225432602e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4133548859215405e-05,Acc:99.2084%,lr:0.001\n",
      "Episode:30, Validation Loss:2.304466570513903e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:31, Validation Loss:2.2628763665808457e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:32, Validation Loss:1.9477592781681753e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:33, Validation Loss:2.8971393747297832e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:34, Validation Loss:2.036048165691532e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:35, Validation Loss:2.4701983562832724e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:36, Validation Loss:2.0923597469009925e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:37, Validation Loss:1.8708097479321528e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:38, Validation Loss:2.4339011369720143e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:39, Validation Loss:1.821791084791559e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9389941275789897e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:41, Validation Loss:2.5739498037949974e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:42, Validation Loss:2.082080317352873e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:43, Validation Loss:1.701271360811439e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:44, Validation Loss:1.8550944260553026e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:45, Validation Loss:1.9239352790746855e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:46, Validation Loss:1.7164594433337308e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:47, Validation Loss:2.5068412466988784e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:48, Validation Loss:1.616506604849499e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7597296306424283e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:50, Validation Loss:1.700962565917603e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:51, Validation Loss:2.5014665761904046e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:52, Validation Loss:2.4912607379777117e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:53, Validation Loss:0.0002062659484630192,Acc:93.7600%,lr:0.001\n",
      "Episode:54, Validation Loss:2.2296556746195595e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:55, Validation Loss:1.707076467524078e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:56, Validation Loss:1.8131512897748337e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:57, Validation Loss:1.569943109248676e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:58, Validation Loss:1.8187863985200458e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:59, Validation Loss:2.0385795112296803e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:60, Validation Loss:4.3543021329948725e-05,Acc:98.6296%,lr:0.001\n",
      "Episode:61, Validation Loss:1.9663982168920515e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:62, Validation Loss:1.834248428784624e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:63, Validation Loss:1.2738674412173689e-05,Acc:99.6142%,lr:0.001\n",
      "Episode:64, Validation Loss:1.6334762135317363e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:65, Validation Loss:1.6888973817126176e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:66, Validation Loss:1.4916698643149627e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:67, Validation Loss:1.5879515961195208e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:68, Validation Loss:1.580170102337174e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:69, Validation Loss:1.9424079464844656e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:70, Validation Loss:1.756473179974015e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:71, Validation Loss:1.482412724236761e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:72, Validation Loss:2.1118802327500133e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:73, Validation Loss:2.0055442102037335e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:74, Validation Loss:1.713564667004166e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:75, Validation Loss:2.873491556812405e-05,Acc:99.0620%,lr:0.001\n",
      "Episode:76, Validation Loss:1.7396116597273602e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:77, Validation Loss:1.65145475087274e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:78, Validation Loss:1.146232873100258e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:79, Validation Loss:1.4224783527333251e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:80, Validation Loss:1.2351515991122577e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:81, Validation Loss:1.9592511060708633e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:82, Validation Loss:0.0001461928578499088,Acc:95.7025%,lr:0.001\n",
      "Episode:83, Validation Loss:1.753282641194971e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:84, Validation Loss:1.539902370884031e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:85, Validation Loss:1.4530733153878246e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:86, Validation Loss:1.82208085299815e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:87, Validation Loss:1.809508967852223e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:88, Validation Loss:1.7578577788317692e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:89, Validation Loss:1.5031462187069394e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:90, Validation Loss:1.2888094221210547e-05,Acc:99.6142%,lr:0.001\n",
      "Episode:91, Validation Loss:1.4361895467419853e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:92, Validation Loss:1.3407950000584665e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:93, Validation Loss:1.5528663817422388e-05,Acc:99.5543%,lr:0.001\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:94, Validation Loss:1.389626556082553e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.114383447065775e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0215667996579358e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.537023329089271e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.175457908886427e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.207405147954084e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.327015323795383e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.324124271021348e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.746357655829733e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.115498318193662e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.56905392995337e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:105, Validation Loss:8.907566520377018e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:106, Validation Loss:8.720741923224377e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:107, Validation Loss:8.721494285896333e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.225170287150472e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.549575087828972e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.463168339909884e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.129558147901214e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.149192747406706e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:113, Validation Loss:8.795147639277483e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:114, Validation Loss:8.99116384255055e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.712963006811583e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.057691419658713e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.254264514427383e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.031567362966359e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.743339258594564e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.709659481975247e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:121, Validation Loss:9.14117759277032e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.05505218704198e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.0029905944806883e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.991975336128915e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:125, Validation Loss:9.857279741953208e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:126, Validation Loss:9.815628458698691e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:127, Validation Loss:9.450951732145924e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.477867741393498e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:129, Validation Loss:9.170316366410401e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.170389009819046e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:131, Validation Loss:9.252372688002698e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:132, Validation Loss:9.313378870405926e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:133, Validation Loss:9.329514876612725e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:134, Validation Loss:8.93264928259681e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:135, Validation Loss:9.292272475169909e-06,Acc:99.6940%,lr:0.0001\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:136, Validation Loss:9.219551435659355e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:137, Validation Loss:9.234068345748376e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:138, Validation Loss:9.213822054666304e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:139, Validation Loss:9.21812080969006e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:140, Validation Loss:9.172795442770126e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:141, Validation Loss:9.092968638774212e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:142, Validation Loss:9.046216115420918e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:143, Validation Loss:9.061611747441536e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:144, Validation Loss:9.09823585899389e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:145, Validation Loss:9.124270017531925e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:146, Validation Loss:9.131235389723905e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:147, Validation Loss:9.098477673257377e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:148, Validation Loss:9.07892166493642e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:149, Validation Loss:9.07518602798615e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:150, Validation Loss:9.122275963709146e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:151, Validation Loss:9.070308789801191e-06,Acc:99.7139%,lr:1e-05\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:8.907566520377018e-06 Acc:0.9976051091005854==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0037731757628403804,Acc:10.1783%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005535553623349696,Acc:23.1373%,lr:0.001\n",
      "Episode:3, Validation Loss:0.010718585773628402,Acc:15.1610%,lr:0.001\n",
      "Episode:4, Validation Loss:0.013196867409381795,Acc:14.2696%,lr:0.001\n",
      "Episode:5, Validation Loss:0.012168436623939242,Acc:17.8419%,lr:0.001\n",
      "Episode:6, Validation Loss:0.005435587688606428,Acc:39.1631%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0015522429383517961,Acc:76.3172%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0015177634674034708,Acc:77.9005%,lr:0.001\n",
      "Episode:9, Validation Loss:0.00010202852330066981,Acc:97.5053%,lr:0.001\n",
      "Episode:10, Validation Loss:3.498950028943692e-05,Acc:98.9023%,lr:0.001\n",
      "Episode:11, Validation Loss:4.0421284068060597e-05,Acc:98.8890%,lr:0.001\n",
      "Episode:12, Validation Loss:2.815868388792027e-05,Acc:99.1618%,lr:0.001\n",
      "Episode:13, Validation Loss:4.20173579562275e-05,Acc:98.7094%,lr:0.001\n",
      "Episode:14, Validation Loss:3.436745413068034e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:15, Validation Loss:3.4704675056345606e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:16, Validation Loss:3.3207805795042896e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:17, Validation Loss:2.7335446155439228e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:18, Validation Loss:2.8485217527697033e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:19, Validation Loss:4.999649868569297e-05,Acc:98.5165%,lr:0.001\n",
      "Episode:20, Validation Loss:2.118436128452238e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:21, Validation Loss:3.511367281209906e-05,Acc:99.0154%,lr:0.001\n",
      "Episode:22, Validation Loss:2.401843585248416e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:23, Validation Loss:2.0361552163641335e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:24, Validation Loss:3.3494439957432446e-05,Acc:98.9822%,lr:0.001\n",
      "Episode:25, Validation Loss:2.332292258007895e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:26, Validation Loss:2.05741541736728e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:27, Validation Loss:2.4321400562916874e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:28, Validation Loss:1.994642934490822e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:29, Validation Loss:1.702923937950991e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:30, Validation Loss:1.4490700440115517e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:31, Validation Loss:2.0157980364353304e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:32, Validation Loss:1.960852758477166e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:33, Validation Loss:1.800253293033394e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:34, Validation Loss:2.016204464689944e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:35, Validation Loss:1.4437936295216438e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:36, Validation Loss:1.851323158210099e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:37, Validation Loss:1.7678814044518635e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:38, Validation Loss:2.4556628222209998e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:39, Validation Loss:1.5014719197941927e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:40, Validation Loss:1.8664749840818675e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:41, Validation Loss:1.6222155961233323e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:42, Validation Loss:1.5839574043948784e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:43, Validation Loss:1.4904520138324957e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:44, Validation Loss:1.961288030347041e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:45, Validation Loss:1.2090710634112898e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:46, Validation Loss:2.1708983865513517e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:47, Validation Loss:1.3308380050173287e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:48, Validation Loss:1.4952474143385824e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:49, Validation Loss:1.4926309009866234e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:50, Validation Loss:1.78245903141975e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:51, Validation Loss:1.2870489671963161e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:52, Validation Loss:1.2702240939229774e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:53, Validation Loss:1.3520421977975207e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:54, Validation Loss:1.3272583391963484e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:55, Validation Loss:1.3898331452628966e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:56, Validation Loss:1.7737296821044966e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:57, Validation Loss:1.4629049982257016e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:58, Validation Loss:1.4970120791734422e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:59, Validation Loss:1.4442893890331897e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:60, Validation Loss:1.3452008862976241e-05,Acc:99.6075%,lr:0.001\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:61, Validation Loss:1.4408888596894657e-05,Acc:99.5809%,lr:0.0001\n",
      "Episode:62, Validation Loss:9.59415196432688e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:63, Validation Loss:8.765060071471113e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:64, Validation Loss:8.630787714212506e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:65, Validation Loss:8.43998569682411e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:66, Validation Loss:8.548097861554035e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:67, Validation Loss:7.917576060199663e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:68, Validation Loss:8.268280284025247e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:69, Validation Loss:7.920456766321891e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:70, Validation Loss:7.762579421327907e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:71, Validation Loss:8.070134900895925e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:72, Validation Loss:7.70531081199991e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:73, Validation Loss:7.906998521618608e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:74, Validation Loss:7.92788293625527e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:75, Validation Loss:7.975097233156945e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:76, Validation Loss:7.809113983477268e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:77, Validation Loss:8.389799401635911e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:78, Validation Loss:8.169568408708852e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:79, Validation Loss:7.80732622764164e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:80, Validation Loss:7.578343872432936e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:81, Validation Loss:7.976929829646736e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:82, Validation Loss:8.035050736672823e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:83, Validation Loss:8.05084124525207e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:84, Validation Loss:7.697849760839181e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:85, Validation Loss:8.222801498563176e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.329702082757717e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:87, Validation Loss:8.397451974278065e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:88, Validation Loss:7.804608698131367e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:89, Validation Loss:8.460475072267645e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:90, Validation Loss:7.899588498967428e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:91, Validation Loss:7.64394093239447e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:92, Validation Loss:8.248061625318658e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:93, Validation Loss:7.738885309888192e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:94, Validation Loss:7.574710710704755e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:95, Validation Loss:7.87853465790743e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:96, Validation Loss:7.945991969967738e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:97, Validation Loss:7.413218992139238e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:98, Validation Loss:7.636373115558735e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:99, Validation Loss:7.6075616399715435e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:100, Validation Loss:7.666158462002747e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:101, Validation Loss:7.247841486260255e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:102, Validation Loss:7.4128613356469145e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:103, Validation Loss:7.179602049415046e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:104, Validation Loss:7.320457208317275e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:105, Validation Loss:7.118966534263898e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:106, Validation Loss:7.635891825870718e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:107, Validation Loss:7.5476649655956035e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:108, Validation Loss:7.656204371149055e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:109, Validation Loss:7.83543118799602e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:110, Validation Loss:7.17233320125173e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:111, Validation Loss:7.540547832184456e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:112, Validation Loss:8.017003821593696e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:113, Validation Loss:7.494661840919986e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:114, Validation Loss:7.8126694678719e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:115, Validation Loss:7.793787664730358e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:116, Validation Loss:7.932305944034707e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:117, Validation Loss:7.911552434679103e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:118, Validation Loss:7.89990817643246e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.067057190186375e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.37844548468885e-06,Acc:99.7272%,lr:0.0001\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:121, Validation Loss:8.087577295805338e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:122, Validation Loss:7.985901538438267e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:123, Validation Loss:7.916623362805446e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:124, Validation Loss:7.876072294178392e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:125, Validation Loss:7.832986714061649e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:126, Validation Loss:7.827316888272485e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:127, Validation Loss:7.848939779692861e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:128, Validation Loss:7.792178946242387e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:129, Validation Loss:7.72827491139425e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:130, Validation Loss:7.74721853113364e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:131, Validation Loss:7.756108194693701e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:132, Validation Loss:7.764078524164924e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:133, Validation Loss:7.743320182241408e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:134, Validation Loss:7.691443804849758e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:135, Validation Loss:7.612058019142612e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:136, Validation Loss:7.549565434882129e-06,Acc:99.7472%,lr:1e-05\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:8.248061625318658e-06 Acc:0.9977381585949974==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0036399723875706596,Acc:10.2315%,lr:0.001\n",
      "Episode:2, Validation Loss:0.007226984763538793,Acc:18.2877%,lr:0.001\n",
      "Episode:3, Validation Loss:0.014849487805125433,Acc:9.6927%,lr:0.001\n",
      "Episode:4, Validation Loss:0.009335506971114616,Acc:17.0969%,lr:0.001\n",
      "Episode:5, Validation Loss:0.006299995532246458,Acc:24.6740%,lr:0.001\n",
      "Episode:6, Validation Loss:0.007333301527186744,Acc:29.8962%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0023615557408954565,Acc:57.3576%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00018535169389667885,Acc:95.5695%,lr:0.001\n",
      "Episode:9, Validation Loss:0.00010253508099934216,Acc:97.1794%,lr:0.001\n",
      "Episode:10, Validation Loss:7.239706787524101e-05,Acc:97.9045%,lr:0.001\n",
      "Episode:11, Validation Loss:3.448575787135202e-05,Acc:99.1086%,lr:0.001\n",
      "Episode:12, Validation Loss:5.431789429010769e-05,Acc:98.6495%,lr:0.001\n",
      "Episode:13, Validation Loss:3.8628576213356153e-05,Acc:99.0088%,lr:0.001\n",
      "Episode:14, Validation Loss:4.236719820364921e-05,Acc:98.8558%,lr:0.001\n",
      "Episode:15, Validation Loss:3.462951251678863e-05,Acc:99.0088%,lr:0.001\n",
      "Episode:16, Validation Loss:0.00015151468831738491,Acc:95.8821%,lr:0.001\n",
      "Episode:17, Validation Loss:2.9217697528328207e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:18, Validation Loss:9.364693288301266e-05,Acc:96.9931%,lr:0.001\n",
      "Episode:19, Validation Loss:4.74996585498042e-05,Acc:98.6429%,lr:0.001\n",
      "Episode:20, Validation Loss:3.502104592972007e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:21, Validation Loss:3.579510224684716e-05,Acc:99.0221%,lr:0.001\n",
      "Episode:22, Validation Loss:3.1866653085829505e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:23, Validation Loss:4.653094528206268e-05,Acc:98.7028%,lr:0.001\n",
      "Episode:24, Validation Loss:3.403033047593325e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:25, Validation Loss:3.56599005031389e-05,Acc:99.0487%,lr:0.001\n",
      "Episode:26, Validation Loss:2.9619028662916762e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:27, Validation Loss:3.627953905178043e-05,Acc:98.9955%,lr:0.001\n",
      "Episode:28, Validation Loss:3.265236592849101e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:29, Validation Loss:3.362134250922762e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:30, Validation Loss:2.0961738356347967e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:31, Validation Loss:2.3068016673279148e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:32, Validation Loss:2.051734808136517e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:33, Validation Loss:2.2935034843987453e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:34, Validation Loss:2.1141434884855662e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:35, Validation Loss:2.888954398700568e-05,Acc:99.1751%,lr:0.001\n",
      "Episode:36, Validation Loss:2.4465910637847376e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:37, Validation Loss:3.192078689199502e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:38, Validation Loss:2.671178133425686e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:39, Validation Loss:2.5217260019442324e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:40, Validation Loss:2.4527587153180094e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:41, Validation Loss:1.9434131391965024e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:42, Validation Loss:2.2328561387496182e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:43, Validation Loss:2.1598793138978393e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:44, Validation Loss:2.022926768009462e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:45, Validation Loss:2.5622762775345012e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:46, Validation Loss:3.194261206975162e-05,Acc:99.1352%,lr:0.001\n",
      "Episode:47, Validation Loss:2.1485585712903578e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:48, Validation Loss:1.9736023520145757e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:49, Validation Loss:2.0063242826961722e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:50, Validation Loss:3.474978261695161e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:51, Validation Loss:2.2566764111897772e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:52, Validation Loss:2.7362983366509204e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:53, Validation Loss:2.109647335453894e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:54, Validation Loss:1.669073646031657e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:55, Validation Loss:2.2425118882353793e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:56, Validation Loss:2.3161873413213174e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:57, Validation Loss:2.140700989345831e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:58, Validation Loss:1.6168479018603285e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:59, Validation Loss:2.2576608424466013e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:60, Validation Loss:1.563669946649374e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:61, Validation Loss:2.34848893772436e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:62, Validation Loss:1.795636790473968e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:63, Validation Loss:2.084278324128244e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:64, Validation Loss:1.9396552290646493e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:65, Validation Loss:1.837936694178177e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:66, Validation Loss:1.6553395995528234e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:67, Validation Loss:1.687503898364629e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:68, Validation Loss:2.0422765310058702e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:69, Validation Loss:2.5744221439389804e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:70, Validation Loss:1.6828205328912512e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:71, Validation Loss:1.8271247868957976e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:72, Validation Loss:2.10571910518342e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:73, Validation Loss:1.7191758080712257e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:74, Validation Loss:2.0557761112026804e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:75, Validation Loss:1.895823553125233e-05,Acc:99.4212%,lr:0.001\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:76, Validation Loss:2.2947786379845426e-05,Acc:99.3680%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.4662672945225394e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.263831439886506e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.2083009317588653e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.2562580036416753e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.1969357357222137e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.143620111184029e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.124350293110729e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.1291269023623664e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.1757169089350946e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.1916338046541821e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.132499975905203e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.1209571210418675e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.1901507112472662e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.1913420569534281e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.2305087993291225e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.140612745315566e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.1307227340025779e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.1576998318650102e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.1528114756760586e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.1088049165387066e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.1473824108984002e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.1509722591877903e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.1050434780127194e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.1752869497921205e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.1605971948575266e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.1430568939809424e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.128103922083062e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.101534596920418e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.1338856713841369e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.111124285822412e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.1024869101874415e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.144459376437763e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.128651802078635e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.1664920200520909e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.1103930594394614e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.2079799841958564e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.1263367604214486e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.0856006973774477e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.0452261475866989e-05,Acc:99.7406%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0516254309150467e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.0809715279140582e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.100190638100105e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.0991575837753884e-05,Acc:99.7406%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.1050136740794758e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.1172677218535357e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.1030076317709215e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.1333349785862165e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.102560554185467e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.160837652284638e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.0942392811543958e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.1448649899709916e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.2134253248144109e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.2203081499313329e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.1288386303931475e-05,Acc:99.7339%,lr:0.0001\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:131, Validation Loss:1.0865299258393025e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:132, Validation Loss:1.0930661721964936e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:133, Validation Loss:1.097824727470068e-05,Acc:99.7539%,lr:1e-05\n",
      "Episode:134, Validation Loss:1.0936031789142695e-05,Acc:99.7406%,lr:1e-05\n",
      "Episode:135, Validation Loss:1.0988943730077016e-05,Acc:99.7272%,lr:1e-05\n",
      "Episode:136, Validation Loss:1.094222069777917e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:137, Validation Loss:1.0884383007112797e-05,Acc:99.7406%,lr:1e-05\n",
      "Episode:138, Validation Loss:1.0857905274601043e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:139, Validation Loss:1.091783481663437e-05,Acc:99.7472%,lr:1e-05\n",
      "Episode:140, Validation Loss:1.0904300559665007e-05,Acc:99.7472%,lr:1e-05\n",
      "Episode:141, Validation Loss:1.0900440700937056e-05,Acc:99.7406%,lr:1e-05\n",
      "Episode:142, Validation Loss:1.0852347418790788e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:143, Validation Loss:1.100058312477775e-05,Acc:99.7472%,lr:1e-05\n",
      "Episode:144, Validation Loss:1.1127417246172202e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:145, Validation Loss:1.0947393280210617e-05,Acc:99.7339%,lr:1e-05\n",
      "Episode:146, Validation Loss:1.085170558562077e-05,Acc:99.7339%,lr:1e-05\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:1.097824727470068e-05 Acc:0.9975385843533795==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0025935319112043802,Acc:35.1251%,lr:0.001\n",
      "Episode:2, Validation Loss:0.00961953563345056,Acc:16.8773%,lr:0.001\n",
      "Episode:3, Validation Loss:0.019714750337626086,Acc:10.0652%,lr:0.001\n",
      "Episode:4, Validation Loss:0.02077980927167388,Acc:10.0785%,lr:0.001\n",
      "Episode:5, Validation Loss:0.023996954334740184,Acc:10.0918%,lr:0.001\n",
      "Episode:6, Validation Loss:0.007908917761280412,Acc:34.0008%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0009623969319718134,Acc:83.6815%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0039014068926313318,Acc:58.8544%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0005856775393696653,Acc:89.0234%,lr:0.001\n",
      "Episode:10, Validation Loss:0.0002750822587286684,Acc:92.4894%,lr:0.001\n",
      "Episode:11, Validation Loss:3.752192584455743e-05,Acc:98.9689%,lr:0.001\n",
      "Episode:12, Validation Loss:4.8201581480069764e-05,Acc:98.6762%,lr:0.001\n",
      "Episode:13, Validation Loss:4.2631551935602656e-05,Acc:98.9356%,lr:0.001\n",
      "Episode:14, Validation Loss:3.826610660730619e-05,Acc:98.9955%,lr:0.001\n",
      "Episode:15, Validation Loss:4.215533359391598e-05,Acc:98.8957%,lr:0.001\n",
      "Episode:16, Validation Loss:3.15748579887363e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:17, Validation Loss:3.6403568518041235e-05,Acc:99.0487%,lr:0.001\n",
      "Episode:18, Validation Loss:2.847054981670683e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:19, Validation Loss:4.958592532693293e-05,Acc:98.5032%,lr:0.001\n",
      "Episode:20, Validation Loss:3.5227597440816484e-05,Acc:99.0687%,lr:0.001\n",
      "Episode:21, Validation Loss:4.0725323591161246e-05,Acc:98.8957%,lr:0.001\n",
      "Episode:22, Validation Loss:2.183206806909997e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:23, Validation Loss:2.725059555634309e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:24, Validation Loss:2.911079071755578e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:25, Validation Loss:2.2456799524758424e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:26, Validation Loss:4.289364353012633e-05,Acc:98.8824%,lr:0.001\n",
      "Episode:27, Validation Loss:2.574027031947556e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:28, Validation Loss:2.3119595445030353e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:29, Validation Loss:2.046140249592548e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:30, Validation Loss:2.559486095322184e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:31, Validation Loss:2.7609567374522347e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:32, Validation Loss:2.502502740706263e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:33, Validation Loss:2.5870081333680443e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:34, Validation Loss:1.764911165715707e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:35, Validation Loss:1.8984360083592673e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:36, Validation Loss:2.640628950058732e-05,Acc:99.1751%,lr:0.001\n",
      "Episode:37, Validation Loss:2.2952695835149784e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:38, Validation Loss:1.8780520572433643e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:39, Validation Loss:2.7429378264845846e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:40, Validation Loss:2.267579341127858e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:41, Validation Loss:2.33851384223816e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:42, Validation Loss:0.0006363957470055905,Acc:83.1160%,lr:0.001\n",
      "Episode:43, Validation Loss:2.145971663612446e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:44, Validation Loss:2.2696295580635876e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:45, Validation Loss:1.8802341351314325e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:46, Validation Loss:1.93860143187152e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:47, Validation Loss:1.8584538228113944e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:48, Validation Loss:2.388355618703589e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:49, Validation Loss:1.8641891144067366e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:50, Validation Loss:1.728476351424417e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:51, Validation Loss:1.7564452873833354e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:52, Validation Loss:2.6421782589394116e-05,Acc:99.2084%,lr:0.001\n",
      "Episode:53, Validation Loss:2.0176452607364495e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:54, Validation Loss:1.6889144010255e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:55, Validation Loss:1.770996734843911e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:56, Validation Loss:1.868298866460422e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:57, Validation Loss:1.7600497541906527e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:58, Validation Loss:2.2043960063384687e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:59, Validation Loss:1.5787031701525566e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:60, Validation Loss:5.921552293775816e-05,Acc:98.1373%,lr:0.001\n",
      "Episode:61, Validation Loss:3.429040515487057e-05,Acc:98.9356%,lr:0.001\n",
      "Episode:62, Validation Loss:3.768235483187478e-05,Acc:98.8691%,lr:0.001\n",
      "Episode:63, Validation Loss:2.5753516202248304e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:64, Validation Loss:2.0003542831904113e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:65, Validation Loss:1.7139229523498782e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:66, Validation Loss:1.8362618345636407e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:67, Validation Loss:1.827661393997381e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:68, Validation Loss:1.461481091384481e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:69, Validation Loss:2.162615513848364e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:70, Validation Loss:1.6091668821213062e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:71, Validation Loss:1.6423214422494268e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6405496586703e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:73, Validation Loss:1.7796821759427843e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:74, Validation Loss:1.5682303480518473e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:75, Validation Loss:1.4776399748438514e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:76, Validation Loss:2.0549616438374835e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:77, Validation Loss:1.5657676466626173e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:78, Validation Loss:1.4602719983824506e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:79, Validation Loss:1.8855781931808776e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:80, Validation Loss:1.8849650766163225e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:81, Validation Loss:1.8265414556776862e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4082467748013787e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:83, Validation Loss:1.8369045258242442e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:84, Validation Loss:1.9351747292160845e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:85, Validation Loss:1.4366116498643061e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:86, Validation Loss:1.6034884320571028e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:87, Validation Loss:1.94052251391886e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:88, Validation Loss:1.4146202875320076e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:89, Validation Loss:1.6123633284048395e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:90, Validation Loss:1.5720583737875916e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:91, Validation Loss:1.698229445180221e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:92, Validation Loss:1.844632340929193e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:93, Validation Loss:1.4088838683374864e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:94, Validation Loss:2.5952279472554092e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:95, Validation Loss:1.5895264680453237e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:96, Validation Loss:1.3362385762311189e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:97, Validation Loss:1.6794947193843323e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:98, Validation Loss:1.5680689216968605e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:99, Validation Loss:2.428269497762737e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:100, Validation Loss:1.2550670017913071e-05,Acc:99.6142%,lr:0.001\n",
      "Episode:101, Validation Loss:1.840716061970896e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:102, Validation Loss:1.6342246853669647e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:103, Validation Loss:1.639266221567457e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:104, Validation Loss:1.4231053877130206e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:105, Validation Loss:1.0981072034555953e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:106, Validation Loss:1.362821290085113e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:107, Validation Loss:1.5878997017748894e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:108, Validation Loss:1.4353031918313305e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:109, Validation Loss:1.6264299360986655e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:110, Validation Loss:1.3413749175010414e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:111, Validation Loss:1.7646369577582256e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:112, Validation Loss:1.7293596983713283e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:113, Validation Loss:1.793496037237128e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:114, Validation Loss:1.5748140496063526e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:115, Validation Loss:1.5407548048853194e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:116, Validation Loss:1.6489112092962192e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:117, Validation Loss:3.921489395843566e-05,Acc:98.7493%,lr:0.001\n",
      "Episode:118, Validation Loss:1.4407595668132791e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:119, Validation Loss:1.7588768527853466e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:120, Validation Loss:2.2384433678989243e-05,Acc:99.1884%,lr:0.001\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:121, Validation Loss:1.6383144535132234e-05,Acc:99.5144%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.1969119446186578e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:123, Validation Loss:1.0860002330271898e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:124, Validation Loss:1.1288165028081604e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:125, Validation Loss:1.0850525137974805e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.0714892954964582e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.0645847145305425e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.0801962384247301e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.1041105507777338e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0826986536092189e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.035091614533075e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.0032337996563485e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0296746931311899e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.0097861669644389e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.0033871655358857e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:136, Validation Loss:9.67414279682973e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:137, Validation Loss:9.630219618075623e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:138, Validation Loss:9.942425065735843e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:139, Validation Loss:1.0049033248593843e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:140, Validation Loss:1.028625694430171e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:141, Validation Loss:9.64655605193868e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:142, Validation Loss:9.485466427805657e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:143, Validation Loss:1.0127957539554605e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:144, Validation Loss:1.01282684347568e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:145, Validation Loss:1.0298690010836629e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:146, Validation Loss:9.956084752624865e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:147, Validation Loss:9.883632664105292e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:148, Validation Loss:9.858224973649564e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:149, Validation Loss:9.816910297336764e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:150, Validation Loss:9.47929313208089e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:151, Validation Loss:9.622735829063319e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:152, Validation Loss:9.665338942328068e-06,Acc:99.6474%,lr:0.0001\n",
      "Episode:153, Validation Loss:9.518475344869495e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:154, Validation Loss:9.810442989419486e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:155, Validation Loss:9.489190169204147e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:156, Validation Loss:9.442645879962966e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:157, Validation Loss:9.643025923036574e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:158, Validation Loss:9.954095500391998e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:159, Validation Loss:9.496135467652504e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:160, Validation Loss:9.724636811975185e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:161, Validation Loss:9.828165812668662e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:162, Validation Loss:9.303130202011233e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:163, Validation Loss:9.749642222130422e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:164, Validation Loss:9.87824766553181e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:165, Validation Loss:9.184110373904915e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:166, Validation Loss:9.360385227486483e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:167, Validation Loss:9.013538012412902e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:168, Validation Loss:8.741081705908705e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:169, Validation Loss:9.184627396715264e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:170, Validation Loss:9.428346063693893e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:171, Validation Loss:9.219683494870891e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:172, Validation Loss:9.664453405236598e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:173, Validation Loss:9.583782264888445e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:174, Validation Loss:9.703863863924943e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:175, Validation Loss:9.460156565872103e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:176, Validation Loss:9.345733687011975e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:177, Validation Loss:9.975382156606651e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:178, Validation Loss:9.438519145769998e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:179, Validation Loss:9.794367111509565e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:180, Validation Loss:9.414437034887526e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:181, Validation Loss:9.709111258224994e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:182, Validation Loss:9.439016311682716e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:183, Validation Loss:9.539207835652493e-06,Acc:99.7006%,lr:0.0001\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:184, Validation Loss:9.490168516381885e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:185, Validation Loss:9.239028264213792e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:186, Validation Loss:9.163729018745364e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:187, Validation Loss:9.103291809257514e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:188, Validation Loss:9.063756571187499e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:189, Validation Loss:9.007721180527482e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:190, Validation Loss:8.998849577141084e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:191, Validation Loss:8.985339761813264e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:192, Validation Loss:9.003999545632952e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:193, Validation Loss:9.015532809707667e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:194, Validation Loss:8.964448849541225e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:195, Validation Loss:8.990880238965844e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:196, Validation Loss:8.98490501656938e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:197, Validation Loss:8.94158835606595e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:198, Validation Loss:8.918128004609872e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:199, Validation Loss:8.917205975435084e-06,Acc:99.6873%,lr:1e-05\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:9.360385227486483e-06 Acc:0.9971394358701436==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10162\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10162_s10.npy\n",
      "shape of top1_dig_csv: (10162, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10162_s10.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s10.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10162, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75162, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75162_s10.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75162_s10.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step9\n",
      "Step: 10\n",
      "global_data len: 75162\n",
      "validation rate: 0.1999946781618371\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.003277209542291224,Acc:13.6376%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005114637644383551,Acc:18.3209%,lr:0.001\n",
      "Episode:3, Validation Loss:0.014139555184494758,Acc:9.7060%,lr:0.001\n",
      "Episode:4, Validation Loss:0.014379769452649778,Acc:10.8635%,lr:0.001\n",
      "Episode:5, Validation Loss:0.02582267778486949,Acc:9.7924%,lr:0.001\n",
      "Episode:6, Validation Loss:0.005709600137737979,Acc:39.9282%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0007106685151503148,Acc:86.8015%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00011587041683451428,Acc:96.9997%,lr:0.001\n",
      "Episode:9, Validation Loss:7.474209127938766e-05,Acc:98.1107%,lr:0.001\n",
      "Episode:10, Validation Loss:4.721637416240413e-05,Acc:98.7560%,lr:0.001\n",
      "Episode:11, Validation Loss:4.8004046921133045e-05,Acc:98.8092%,lr:0.001\n",
      "Episode:12, Validation Loss:5.684922508272863e-05,Acc:98.7028%,lr:0.001\n",
      "Episode:13, Validation Loss:4.8522721726235207e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:14, Validation Loss:3.7443376914015665e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:15, Validation Loss:3.865402364858514e-05,Acc:98.9223%,lr:0.001\n",
      "Episode:16, Validation Loss:4.8932276652286256e-05,Acc:98.8491%,lr:0.001\n",
      "Episode:17, Validation Loss:3.819733891812584e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:18, Validation Loss:3.5513357466018344e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:19, Validation Loss:5.3211242310452996e-05,Acc:98.8026%,lr:0.001\n",
      "Episode:20, Validation Loss:3.584277961837319e-05,Acc:99.1219%,lr:0.001\n",
      "Episode:21, Validation Loss:4.159557440294872e-05,Acc:98.9223%,lr:0.001\n",
      "Episode:22, Validation Loss:3.371371679699931e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:23, Validation Loss:3.7706687678684573e-05,Acc:99.0221%,lr:0.001\n",
      "Episode:24, Validation Loss:3.3514897332602576e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:25, Validation Loss:3.762914702006798e-05,Acc:98.9090%,lr:0.001\n",
      "Episode:26, Validation Loss:3.717533624252704e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:27, Validation Loss:3.0474406813269855e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:28, Validation Loss:4.704252513400128e-05,Acc:98.8292%,lr:0.001\n",
      "Episode:29, Validation Loss:3.0115377871659665e-05,Acc:99.1884%,lr:0.001\n",
      "Episode:30, Validation Loss:3.837119959425647e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:31, Validation Loss:3.583105841077598e-05,Acc:99.1751%,lr:0.001\n",
      "Episode:32, Validation Loss:4.197625275314679e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:33, Validation Loss:3.660807510943981e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:34, Validation Loss:2.978988112747955e-05,Acc:99.1485%,lr:0.001\n",
      "Episode:35, Validation Loss:2.7766592747087235e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:36, Validation Loss:3.8490176053163597e-05,Acc:98.9290%,lr:0.001\n",
      "Episode:37, Validation Loss:2.4268133954867173e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:38, Validation Loss:2.936887190027431e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:39, Validation Loss:2.9566586937035664e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:40, Validation Loss:4.188876028830397e-05,Acc:98.9223%,lr:0.001\n",
      "Episode:41, Validation Loss:2.3151825761056727e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:42, Validation Loss:2.4899538567249066e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:43, Validation Loss:2.6631583878497864e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:44, Validation Loss:2.5638400965101102e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:45, Validation Loss:3.732686810058647e-05,Acc:99.1086%,lr:0.001\n",
      "Episode:46, Validation Loss:2.8999023272806084e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:47, Validation Loss:3.207864464340437e-05,Acc:99.1352%,lr:0.001\n",
      "Episode:48, Validation Loss:2.6553942107691164e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:49, Validation Loss:2.5995852878716728e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:50, Validation Loss:2.463105243212876e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:51, Validation Loss:2.4938525432773317e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:52, Validation Loss:2.357223085531724e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:53, Validation Loss:2.5081336798127533e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:54, Validation Loss:2.0472434071299558e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:55, Validation Loss:2.1964897548590506e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:56, Validation Loss:2.6278605497778732e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:57, Validation Loss:2.2589093983220952e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:58, Validation Loss:2.2142763215376382e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:59, Validation Loss:2.7926085703174063e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:60, Validation Loss:2.5802434490475172e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:61, Validation Loss:1.905993586966194e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:62, Validation Loss:2.3774514155697323e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:63, Validation Loss:2.3702506260711454e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:64, Validation Loss:1.7614950141668747e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:65, Validation Loss:1.7374485310815382e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:66, Validation Loss:1.9574393267966826e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:67, Validation Loss:1.9854542836715418e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:68, Validation Loss:2.3102376138183778e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:69, Validation Loss:2.0953295302605567e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:70, Validation Loss:2.2242015796183685e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:71, Validation Loss:2.6121364549315867e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:72, Validation Loss:1.9809899853166745e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:73, Validation Loss:2.42992256435468e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:74, Validation Loss:2.1073355681712462e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:75, Validation Loss:2.0769836898782094e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:76, Validation Loss:1.847556546358208e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:77, Validation Loss:3.421712446682246e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:78, Validation Loss:2.7567294424775435e-05,Acc:99.1951%,lr:0.001\n",
      "Episode:79, Validation Loss:2.3688221158992108e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:80, Validation Loss:3.2801110324206476e-05,Acc:98.9955%,lr:0.001\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:81, Validation Loss:2.0851992721708532e-05,Acc:99.4678%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.7315586623668813e-05,Acc:99.5343%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.6218125568618555e-05,Acc:99.5543%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.5243072901119365e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.504024606076143e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.5450643464484752e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:87, Validation Loss:1.5707400740441994e-05,Acc:99.5809%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.5359582458020542e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.5479232626459093e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.5253795099213219e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.497663366828885e-05,Acc:99.5676%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.4272518270114211e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.6036583185037317e-05,Acc:99.5809%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.4311191545350318e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.5432344295556333e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.4665318249530015e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.5206829323311906e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.4091880939764076e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.5531996523534177e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.588409636818971e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.5314900968818587e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.480373182319632e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.5692403857229934e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.4199488720707416e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.4318597827408069e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.4676182017081227e-05,Acc:99.5609%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.3380822411601042e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.4058572837181822e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.427443785282638e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.4718237098558206e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.4638325012129885e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:112, Validation Loss:1.4110880800061415e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:113, Validation Loss:1.4412992252478055e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:114, Validation Loss:1.5139190193628491e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:115, Validation Loss:1.5315368705631857e-05,Acc:99.5875%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.455087284966431e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:117, Validation Loss:1.4302166817712777e-05,Acc:99.5676%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.4644328176681826e-05,Acc:99.5875%,lr:0.0001\n",
      "Episode:119, Validation Loss:1.5087602438257452e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:120, Validation Loss:1.469417180872942e-05,Acc:99.6009%,lr:0.0001\n",
      "Episode:121, Validation Loss:1.5330925423249466e-05,Acc:99.5875%,lr:0.0001\n",
      "Episode:122, Validation Loss:1.4746255243069206e-05,Acc:99.6142%,lr:0.0001\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:123, Validation Loss:1.4665597516194803e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:124, Validation Loss:1.4777453062374852e-05,Acc:99.6009%,lr:1e-05\n",
      "Episode:125, Validation Loss:1.4822682490430578e-05,Acc:99.6009%,lr:1e-05\n",
      "Episode:126, Validation Loss:1.4964557576730268e-05,Acc:99.6009%,lr:1e-05\n",
      "Episode:127, Validation Loss:1.4869834041394425e-05,Acc:99.6009%,lr:1e-05\n",
      "Episode:128, Validation Loss:1.4886155419949762e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:129, Validation Loss:1.47965220965449e-05,Acc:99.6142%,lr:1e-05\n",
      "Episode:130, Validation Loss:1.478697827057105e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:131, Validation Loss:1.4789719637651878e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:132, Validation Loss:1.4784473482471806e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:133, Validation Loss:1.475373364190961e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:134, Validation Loss:1.4735030767692727e-05,Acc:99.6009%,lr:1e-05\n",
      "Episode:135, Validation Loss:1.4720410236195642e-05,Acc:99.6009%,lr:1e-05\n",
      "Episode:136, Validation Loss:1.4700603956617355e-05,Acc:99.6075%,lr:1e-05\n",
      "Episode:137, Validation Loss:1.466097922310701e-05,Acc:99.6142%,lr:1e-05\n",
      "Episode:138, Validation Loss:1.4654469413374525e-05,Acc:99.6208%,lr:1e-05\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:1.4091880939764076e-05 Acc:0.99654071314529==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0028075273681537087,Acc:26.8693%,lr:0.001\n",
      "Episode:2, Validation Loss:0.0019316526487699653,Acc:52.3683%,lr:0.001\n",
      "Episode:3, Validation Loss:0.0004248305949015209,Acc:85.4710%,lr:0.001\n",
      "Episode:4, Validation Loss:0.0002929906639854853,Acc:90.6067%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0001430788066014132,Acc:96.0019%,lr:0.001\n",
      "Episode:6, Validation Loss:8.551981310028546e-05,Acc:97.6716%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0002541743167351382,Acc:92.9018%,lr:0.001\n",
      "Episode:8, Validation Loss:5.0777301887182114e-05,Acc:98.6163%,lr:0.001\n",
      "Episode:9, Validation Loss:7.796945955412003e-05,Acc:98.0109%,lr:0.001\n",
      "Episode:10, Validation Loss:3.989181974967183e-05,Acc:98.9622%,lr:0.001\n",
      "Episode:11, Validation Loss:3.4238298548987215e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:12, Validation Loss:4.048874039656942e-05,Acc:98.8026%,lr:0.001\n",
      "Episode:13, Validation Loss:4.9578663340396486e-05,Acc:98.5098%,lr:0.001\n",
      "Episode:14, Validation Loss:4.307930756750863e-05,Acc:98.6828%,lr:0.001\n",
      "Episode:15, Validation Loss:4.788412885495549e-05,Acc:98.6163%,lr:0.001\n",
      "Episode:16, Validation Loss:3.464884365581178e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:17, Validation Loss:3.445904182509072e-05,Acc:99.0487%,lr:0.001\n",
      "Episode:18, Validation Loss:2.645059020822038e-05,Acc:99.2084%,lr:0.001\n",
      "Episode:19, Validation Loss:6.267493030630317e-05,Acc:98.2770%,lr:0.001\n",
      "Episode:20, Validation Loss:4.4028713735154555e-05,Acc:98.6895%,lr:0.001\n",
      "Episode:21, Validation Loss:3.291624848507325e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:22, Validation Loss:2.4454280753392465e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:23, Validation Loss:3.6086107466911116e-05,Acc:98.8558%,lr:0.001\n",
      "Episode:24, Validation Loss:2.7829358944527612e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:25, Validation Loss:3.613151167283958e-05,Acc:98.9489%,lr:0.001\n",
      "Episode:26, Validation Loss:2.0947482497860074e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6770929239408774e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:28, Validation Loss:2.3050362156518697e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:29, Validation Loss:1.9548219708431397e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:30, Validation Loss:6.765430221188379e-05,Acc:98.3236%,lr:0.001\n",
      "Episode:31, Validation Loss:1.9441414970167063e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:32, Validation Loss:2.679734331213172e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:33, Validation Loss:3.103078351648026e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:34, Validation Loss:2.4712513573418168e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:35, Validation Loss:2.1918805290316888e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:36, Validation Loss:1.9416650073199337e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:37, Validation Loss:2.6086791522083225e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:38, Validation Loss:2.382233854880861e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:39, Validation Loss:1.966703610401551e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:40, Validation Loss:1.7682468581066416e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:41, Validation Loss:1.9711364598914053e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:42, Validation Loss:2.6850355095158175e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:43, Validation Loss:3.3180960818348e-05,Acc:99.0088%,lr:0.001\n",
      "Episode:44, Validation Loss:1.8618964388651328e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:45, Validation Loss:2.0874314848531856e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:46, Validation Loss:1.7492014291721528e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:47, Validation Loss:1.7152396319439002e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:48, Validation Loss:1.6171871729099954e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7150704425022586e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:50, Validation Loss:2.201096871084652e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:51, Validation Loss:1.5239193371361783e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:52, Validation Loss:1.661793648886349e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:53, Validation Loss:1.5137161661292357e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:54, Validation Loss:1.8589536869078637e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:55, Validation Loss:1.546714699367669e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:56, Validation Loss:1.8883138603098124e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:57, Validation Loss:1.5646266680857155e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:58, Validation Loss:1.8021127505464844e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:59, Validation Loss:1.9582014475384565e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:60, Validation Loss:1.5117143678066021e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:61, Validation Loss:1.4155797040542987e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:62, Validation Loss:2.0216282879901003e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:63, Validation Loss:1.4711592069858246e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:64, Validation Loss:1.95473355343719e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:65, Validation Loss:1.675041514251058e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:66, Validation Loss:1.6418389877886324e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:67, Validation Loss:1.972972761349928e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:68, Validation Loss:1.649351081399008e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:69, Validation Loss:1.6977827950911583e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:70, Validation Loss:2.2256987153524222e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:71, Validation Loss:1.5786178102751498e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:72, Validation Loss:1.5233540010379312e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:73, Validation Loss:1.4431351363835355e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:74, Validation Loss:1.4433868233354375e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:75, Validation Loss:1.3616998028654472e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:76, Validation Loss:1.9003177359561422e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:77, Validation Loss:1.2470866230570728e-05,Acc:99.6740%,lr:0.001\n",
      "Episode:78, Validation Loss:1.5847271240399105e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:79, Validation Loss:1.1976602522704894e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:80, Validation Loss:1.6255385565565043e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:81, Validation Loss:1.5858981853520508e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:82, Validation Loss:1.6392829094157456e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:83, Validation Loss:1.327984150625e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:84, Validation Loss:2.0105463702691606e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:85, Validation Loss:1.5287384017360233e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:86, Validation Loss:1.5199676627157421e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:87, Validation Loss:1.855038693536543e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:88, Validation Loss:1.29023843413658e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:89, Validation Loss:1.549081762379284e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:90, Validation Loss:1.3809996603047867e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:91, Validation Loss:1.3891675209893214e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:92, Validation Loss:2.2707097361210244e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:93, Validation Loss:1.2227861823324766e-05,Acc:99.6674%,lr:0.001\n",
      "Episode:94, Validation Loss:1.3203168417485218e-05,Acc:99.5410%,lr:0.001\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:95, Validation Loss:1.650470908197905e-05,Acc:99.5011%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.3082290869731576e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.187517129017626e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.132779134146992e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0608071829338556e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0535921931203342e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0947647733497868e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0099608890767773e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.063434383695615e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0530166218910781e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.0091113050514361e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.0336475565032304e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0365577598765073e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.895714734417761e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.56144997728131e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.787931772887691e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:111, Validation Loss:1.0219609792115779e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.665342969467994e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.8598730341968e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.61836799310085e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.801499083382436e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:116, Validation Loss:1.0153380719010043e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.517070306727724e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.547900788916227e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.831742346613901e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:120, Validation Loss:9.25525955874681e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:121, Validation Loss:9.731463433707756e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.706200689311323e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:123, Validation Loss:9.924954062643966e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.727187013821582e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:125, Validation Loss:9.687002136125692e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:126, Validation Loss:1.0119160252388818e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:127, Validation Loss:1.0183394621133788e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:128, Validation Loss:1.2094565071690948e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:129, Validation Loss:1.0601389658017289e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:130, Validation Loss:1.0357452751032734e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:131, Validation Loss:1.00546285258274e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.034866401379479e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:133, Validation Loss:1.0171254436094402e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:134, Validation Loss:1.0608846403236098e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:135, Validation Loss:1.0171830750795646e-05,Acc:99.7472%,lr:0.0001\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:136, Validation Loss:9.709664091602674e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:137, Validation Loss:9.70598446287536e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:138, Validation Loss:9.708308091633986e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:139, Validation Loss:9.664788618168341e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:140, Validation Loss:9.694460275354476e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:141, Validation Loss:9.728856139408425e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:142, Validation Loss:9.77039506545904e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:143, Validation Loss:9.779237983217973e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:144, Validation Loss:9.676984098936694e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:145, Validation Loss:9.61239853261228e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:146, Validation Loss:9.605421977362507e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:147, Validation Loss:9.642674384699136e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:148, Validation Loss:9.711227210475495e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:149, Validation Loss:9.714563633947216e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:150, Validation Loss:9.667051034400109e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:151, Validation Loss:9.680087970566757e-06,Acc:99.7339%,lr:1e-05\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:9.708308091633986e-06 Acc:0.9976716338477913==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.00368525374119684,Acc:19.8377%,lr:0.001\n",
      "Episode:2, Validation Loss:0.009118120742643558,Acc:10.2581%,lr:0.001\n",
      "Episode:3, Validation Loss:0.01133388119089026,Acc:13.1786%,lr:0.001\n",
      "Episode:4, Validation Loss:0.008810378059927234,Acc:13.8771%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0027815099882914575,Acc:43.7001%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0036512756994774268,Acc:42.4228%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0005497167074280638,Acc:86.8880%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0001364911233826861,Acc:95.8023%,lr:0.001\n",
      "Episode:9, Validation Loss:5.378454384364747e-05,Acc:98.5365%,lr:0.001\n",
      "Episode:10, Validation Loss:5.326805645704047e-05,Acc:98.6229%,lr:0.001\n",
      "Episode:11, Validation Loss:4.637100537540019e-05,Acc:98.8425%,lr:0.001\n",
      "Episode:12, Validation Loss:0.00011688804758505468,Acc:96.7336%,lr:0.001\n",
      "Episode:13, Validation Loss:4.07180293875054e-05,Acc:99.0021%,lr:0.001\n",
      "Episode:14, Validation Loss:4.3152654796299494e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:15, Validation Loss:2.9412577892274472e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:16, Validation Loss:3.992325907346097e-05,Acc:98.8225%,lr:0.001\n",
      "Episode:17, Validation Loss:3.810179595274929e-05,Acc:99.0687%,lr:0.001\n",
      "Episode:18, Validation Loss:3.759743657682791e-05,Acc:98.9622%,lr:0.001\n",
      "Episode:19, Validation Loss:2.566055568681555e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:20, Validation Loss:6.944908869034944e-05,Acc:98.1373%,lr:0.001\n",
      "Episode:21, Validation Loss:3.496483622585731e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:22, Validation Loss:2.5250761548652966e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:23, Validation Loss:2.91668740931369e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:24, Validation Loss:2.5137777566887983e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:25, Validation Loss:2.4889059825252667e-05,Acc:99.2084%,lr:0.001\n",
      "Episode:26, Validation Loss:2.6356430100738017e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:27, Validation Loss:2.1083874354350117e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:28, Validation Loss:2.155438484475334e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:29, Validation Loss:2.392947050768083e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:30, Validation Loss:2.212139868047118e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:31, Validation Loss:2.592483891284231e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:32, Validation Loss:1.686299452062512e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:33, Validation Loss:1.8244710937489326e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:34, Validation Loss:2.8020775038798543e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:35, Validation Loss:3.6904387852100694e-05,Acc:98.7759%,lr:0.001\n",
      "Episode:36, Validation Loss:1.8130702977953454e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:37, Validation Loss:2.8437596907865945e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:38, Validation Loss:2.5114072984884463e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:39, Validation Loss:1.981505858843245e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9200642248977446e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:41, Validation Loss:1.614688372858039e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:42, Validation Loss:1.8209887793889352e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:43, Validation Loss:1.7252540540003664e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:44, Validation Loss:2.2653748847330074e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:45, Validation Loss:2.8089242737032492e-05,Acc:99.0886%,lr:0.001\n",
      "Episode:46, Validation Loss:1.734547992844081e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:47, Validation Loss:1.710075961882888e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:48, Validation Loss:2.2079361721123865e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:49, Validation Loss:2.16814540891634e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:50, Validation Loss:2.348728874721081e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:51, Validation Loss:2.6440915531176974e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:52, Validation Loss:1.5944980342385218e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:53, Validation Loss:3.0459368605406568e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:54, Validation Loss:6.0445119534133915e-05,Acc:97.9577%,lr:0.001\n",
      "Episode:55, Validation Loss:1.805423310486488e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:56, Validation Loss:1.6659480464328012e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:57, Validation Loss:2.2070745252540703e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:58, Validation Loss:2.1665691367849635e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:59, Validation Loss:1.6475491314440443e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:60, Validation Loss:1.4351720650575781e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:61, Validation Loss:1.6040406737549944e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:62, Validation Loss:1.4972351920186775e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:63, Validation Loss:1.2627547778320033e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:64, Validation Loss:1.7863876520130168e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:65, Validation Loss:1.5488415341893685e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:66, Validation Loss:1.825986732642041e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:67, Validation Loss:1.413249148615002e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:68, Validation Loss:1.4355239100772104e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:69, Validation Loss:1.9943510349978707e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:70, Validation Loss:1.2591049003753338e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:71, Validation Loss:1.5194495680666132e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:72, Validation Loss:1.4087297342035636e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:73, Validation Loss:1.4886653360312467e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:74, Validation Loss:1.2209698152165819e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:75, Validation Loss:1.7133018682438717e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:76, Validation Loss:1.5661055639737095e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:77, Validation Loss:1.2377374814183885e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:78, Validation Loss:1.0573232886958877e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:79, Validation Loss:1.3944874285904174e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:80, Validation Loss:1.604731765041894e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:81, Validation Loss:1.5558454677950295e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:82, Validation Loss:2.3246627484863112e-05,Acc:99.1551%,lr:0.001\n",
      "Episode:83, Validation Loss:1.4245583875423982e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:84, Validation Loss:1.4672265344702337e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:85, Validation Loss:1.1265028520631482e-05,Acc:99.6807%,lr:0.001\n",
      "Episode:86, Validation Loss:1.209448626366042e-05,Acc:99.6541%,lr:0.001\n",
      "Episode:87, Validation Loss:1.0463749140326554e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:88, Validation Loss:1.074416264163022e-05,Acc:99.6541%,lr:0.001\n",
      "Episode:89, Validation Loss:1.6045894180367513e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:90, Validation Loss:1.189522750025388e-05,Acc:99.6341%,lr:0.001\n",
      "Episode:91, Validation Loss:1.0616334095476329e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:92, Validation Loss:1.799967629411726e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:93, Validation Loss:1.1892617789670595e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:94, Validation Loss:1.3938012504142259e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:95, Validation Loss:1.3651479918612817e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:96, Validation Loss:1.3353260511065525e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:97, Validation Loss:1.3023962952224355e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:98, Validation Loss:1.3124084187113442e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:99, Validation Loss:1.3609404608502215e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:100, Validation Loss:1.2079281734918234e-05,Acc:99.6607%,lr:0.001\n",
      "Episode:101, Validation Loss:1.011169972785408e-05,Acc:99.6807%,lr:0.001\n",
      "Episode:102, Validation Loss:1.1196362965915227e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:103, Validation Loss:1.2850947603741943e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:104, Validation Loss:1.609049974249288e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:105, Validation Loss:1.4249841662043504e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:106, Validation Loss:1.4541089346908934e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:107, Validation Loss:1.1350583962148463e-05,Acc:99.6408%,lr:0.001\n",
      "Episode:108, Validation Loss:1.3491735576060683e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:109, Validation Loss:1.213589687883743e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:110, Validation Loss:1.8899685811269245e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:111, Validation Loss:1.3191650208718223e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:112, Validation Loss:1.4100675284019917e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:113, Validation Loss:1.0964466928503912e-05,Acc:99.6740%,lr:0.001\n",
      "Episode:114, Validation Loss:1.1509435270933267e-05,Acc:99.6408%,lr:0.001\n",
      "Episode:115, Validation Loss:1.5554038268484736e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:116, Validation Loss:1.254220620891106e-05,Acc:99.6275%,lr:0.001\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:117, Validation Loss:1.290013917987971e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:118, Validation Loss:9.599672305779833e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.776078976843429e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:120, Validation Loss:8.735305393246528e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.626556739051484e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:122, Validation Loss:8.668197598209195e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:123, Validation Loss:8.555027980782674e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:124, Validation Loss:8.408762460069937e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:125, Validation Loss:8.025525931190619e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:126, Validation Loss:8.435510475626647e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:127, Validation Loss:8.698389716763615e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:128, Validation Loss:8.70779934604397e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:129, Validation Loss:8.28719642627915e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:130, Validation Loss:8.247279508278258e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:131, Validation Loss:8.083638752958856e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:132, Validation Loss:8.516831658314665e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:133, Validation Loss:8.38875857183334e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:134, Validation Loss:8.409047984290608e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:135, Validation Loss:8.720004662327139e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:136, Validation Loss:8.292558191353063e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:137, Validation Loss:7.877280017952848e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:138, Validation Loss:8.02707023092879e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:139, Validation Loss:8.064370437318528e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:140, Validation Loss:7.91411546141726e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:141, Validation Loss:8.112459568412872e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:142, Validation Loss:7.928940215375534e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:143, Validation Loss:8.270451532004717e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:144, Validation Loss:8.139474629813595e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:145, Validation Loss:7.656875579207026e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:146, Validation Loss:7.474226785398437e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:147, Validation Loss:7.90737024986717e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:148, Validation Loss:7.666531266736787e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:149, Validation Loss:7.475714720666663e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:150, Validation Loss:7.391324206817937e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:151, Validation Loss:8.000983781527734e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:152, Validation Loss:7.782288491944007e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:153, Validation Loss:7.880174230482823e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:154, Validation Loss:7.710220700996259e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:155, Validation Loss:7.70320704959218e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:156, Validation Loss:7.50305745185627e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:157, Validation Loss:7.942997985046124e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:158, Validation Loss:8.059048231149875e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:159, Validation Loss:7.740586094990444e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:160, Validation Loss:8.184042553669669e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:161, Validation Loss:8.057582104393243e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:162, Validation Loss:8.093735443288387e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:163, Validation Loss:7.777922421727505e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:164, Validation Loss:7.828213360597751e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:165, Validation Loss:8.024666338173664e-06,Acc:99.7672%,lr:0.0001\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:166, Validation Loss:8.017142804388101e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:167, Validation Loss:7.892858420170055e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:168, Validation Loss:7.896744997422506e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:169, Validation Loss:7.886361466307329e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:170, Validation Loss:7.823632086219267e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:171, Validation Loss:7.837208612668841e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:172, Validation Loss:7.795563772838203e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:173, Validation Loss:7.740564534302847e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:174, Validation Loss:7.77863091955228e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:175, Validation Loss:7.759266603091745e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:176, Validation Loss:7.720189033985185e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:177, Validation Loss:7.684664300654308e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:178, Validation Loss:7.671103092825448e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:179, Validation Loss:7.722315921469484e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:180, Validation Loss:7.741016394891412e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:181, Validation Loss:7.671744337413477e-06,Acc:99.7672%,lr:1e-05\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:7.740586094990444e-06 Acc:0.9978712080894092==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.005390720141574764,Acc:10.7637%,lr:0.001\n",
      "Episode:2, Validation Loss:0.008335607460421918,Acc:12.1408%,lr:0.001\n",
      "Episode:3, Validation Loss:0.00982708103673264,Acc:10.5442%,lr:0.001\n",
      "Episode:4, Validation Loss:0.015579867515239137,Acc:10.1783%,lr:0.001\n",
      "Episode:5, Validation Loss:0.011044717393319869,Acc:14.1166%,lr:0.001\n",
      "Episode:6, Validation Loss:0.008506071637322638,Acc:22.0396%,lr:0.001\n",
      "Episode:7, Validation Loss:0.008265686517322615,Acc:29.3640%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00011741205357994534,Acc:96.5607%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0006166408596805209,Acc:86.5753%,lr:0.001\n",
      "Episode:10, Validation Loss:5.291421348035748e-05,Acc:98.2637%,lr:0.001\n",
      "Episode:11, Validation Loss:5.097028305193983e-05,Acc:98.4899%,lr:0.001\n",
      "Episode:12, Validation Loss:2.8014071461679676e-05,Acc:99.1219%,lr:0.001\n",
      "Episode:13, Validation Loss:2.9416351074560042e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:14, Validation Loss:8.203598713782825e-05,Acc:97.9244%,lr:0.001\n",
      "Episode:15, Validation Loss:2.6952881492900366e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:16, Validation Loss:2.5424560175850756e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:17, Validation Loss:2.5417325357019806e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:18, Validation Loss:3.0573559459051026e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:19, Validation Loss:2.3242739436155686e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:20, Validation Loss:3.795686333790667e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:21, Validation Loss:3.654152135592214e-05,Acc:98.9090%,lr:0.001\n",
      "Episode:22, Validation Loss:2.177154511250972e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:23, Validation Loss:2.161704624362167e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:24, Validation Loss:2.7264891469384235e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:25, Validation Loss:2.682602875372826e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:26, Validation Loss:1.786501901972684e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:27, Validation Loss:1.994510565499293e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:28, Validation Loss:1.996973743949714e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:29, Validation Loss:1.6268530583971674e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:30, Validation Loss:1.836344960927289e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:31, Validation Loss:1.855526999741428e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:32, Validation Loss:2.449513930964178e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:33, Validation Loss:1.661987376001333e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:34, Validation Loss:1.725259585122163e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:35, Validation Loss:1.833193553557115e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:36, Validation Loss:2.0056405300973354e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:37, Validation Loss:2.2255798899422402e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:38, Validation Loss:1.6823005423885575e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:39, Validation Loss:2.3989886094525083e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:40, Validation Loss:1.5311115829025245e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:41, Validation Loss:1.8195235757766853e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:42, Validation Loss:1.5800861767411406e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:43, Validation Loss:1.7750977511017593e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:44, Validation Loss:2.5514731587105573e-05,Acc:99.1418%,lr:0.001\n",
      "Episode:45, Validation Loss:1.786659301187746e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:46, Validation Loss:2.176754585278437e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:47, Validation Loss:1.544712922729635e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:48, Validation Loss:1.3204192162921108e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:49, Validation Loss:1.386822269587099e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:50, Validation Loss:1.868924321562147e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:51, Validation Loss:1.743447789307753e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:52, Validation Loss:1.867205299711635e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:53, Validation Loss:1.792974197347869e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:54, Validation Loss:1.8970797512731838e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:55, Validation Loss:1.8447584213868395e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:56, Validation Loss:1.7206095721118624e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:57, Validation Loss:1.7605260812031614e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:58, Validation Loss:1.5644190721203903e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:59, Validation Loss:1.9174789435648026e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:60, Validation Loss:1.6939368052135493e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:61, Validation Loss:1.5471270041487728e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:62, Validation Loss:1.3576436868944107e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:63, Validation Loss:1.3712815954753888e-05,Acc:99.6142%,lr:0.001\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:64, Validation Loss:1.6071369000147985e-05,Acc:99.5077%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.1157234530933618e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:66, Validation Loss:9.837837453868128e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.017203348631286e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:68, Validation Loss:9.774641064949782e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.0121649613444351e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:70, Validation Loss:9.45166337423764e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:71, Validation Loss:9.386193990100725e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.0054749742739137e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:73, Validation Loss:9.825944968912119e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:74, Validation Loss:9.880614198819636e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:75, Validation Loss:9.954177716002464e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.0076200179636732e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:77, Validation Loss:9.7019590267405e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:78, Validation Loss:9.976243995528564e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:79, Validation Loss:9.599541423732276e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:80, Validation Loss:9.725593753355323e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:81, Validation Loss:9.467325827511777e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:82, Validation Loss:9.319098237760666e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:83, Validation Loss:9.891726580305206e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0387758179364538e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.66055215990142e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.0098262524956906e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.825324680940697e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.010725918652697e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:89, Validation Loss:9.875586175222491e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:90, Validation Loss:9.410534984124363e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:91, Validation Loss:9.39035404113207e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.459958616455798e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.52633146620135e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.296480727968355e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:95, Validation Loss:9.069501890361254e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.4640513600389e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.646914614537486e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0194052756724839e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.74336157214866e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.7154002025661e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.765642916435745e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.324838747600012e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.379606750858686e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.99318575498932e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.045985627454022e-05,Acc:99.7406%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.0008873610222982e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0082146468581735e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.052242351577931e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.0613644368720537e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.722799460362483e-06,Acc:99.7206%,lr:0.0001\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:111, Validation Loss:1.0573545795731036e-05,Acc:99.6940%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.0167451979599382e-05,Acc:99.7006%,lr:1e-05\n",
      "Episode:113, Validation Loss:9.860199883068698e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:114, Validation Loss:9.745436571483927e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:115, Validation Loss:9.65174015818591e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:116, Validation Loss:9.570224681485517e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:117, Validation Loss:9.607201802830285e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:118, Validation Loss:9.699137318218172e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:119, Validation Loss:9.657505798927285e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:120, Validation Loss:9.657825925573311e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:121, Validation Loss:9.636534235433751e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:122, Validation Loss:9.686647778790308e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:123, Validation Loss:9.639109343591683e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:124, Validation Loss:9.619058895421955e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:125, Validation Loss:9.58938510075386e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:126, Validation Loss:9.579094286790953e-06,Acc:99.7139%,lr:1e-05\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:9.467325827511777e-06 Acc:0.9975385843533795==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.003992810250597472,Acc:13.6908%,lr:0.001\n",
      "Episode:2, Validation Loss:0.009565591050818474,Acc:10.2182%,lr:0.001\n",
      "Episode:3, Validation Loss:0.00979628494408868,Acc:13.2850%,lr:0.001\n",
      "Episode:4, Validation Loss:0.014664958613295705,Acc:10.2448%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0063548644151124245,Acc:29.5436%,lr:0.001\n",
      "Episode:6, Validation Loss:0.004637284219233263,Acc:34.3135%,lr:0.001\n",
      "Episode:7, Validation Loss:0.0006489698963954514,Acc:84.0939%,lr:0.001\n",
      "Episode:8, Validation Loss:9.498102298009389e-05,Acc:97.0463%,lr:0.001\n",
      "Episode:9, Validation Loss:3.688787558711292e-05,Acc:98.8358%,lr:0.001\n",
      "Episode:10, Validation Loss:5.698119978628113e-05,Acc:98.5098%,lr:0.001\n",
      "Episode:11, Validation Loss:4.4386511858891716e-05,Acc:98.7693%,lr:0.001\n",
      "Episode:12, Validation Loss:3.480224534591631e-05,Acc:99.0820%,lr:0.001\n",
      "Episode:13, Validation Loss:5.312656840986556e-05,Acc:98.6695%,lr:0.001\n",
      "Episode:14, Validation Loss:2.78654348694022e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:15, Validation Loss:2.806779858866878e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:16, Validation Loss:2.707129012507809e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:17, Validation Loss:4.6322454052554474e-05,Acc:98.7959%,lr:0.001\n",
      "Episode:18, Validation Loss:3.273417182393598e-05,Acc:99.1551%,lr:0.001\n",
      "Episode:19, Validation Loss:3.5955852414062516e-05,Acc:98.9622%,lr:0.001\n",
      "Episode:20, Validation Loss:5.5064104483554567e-05,Acc:98.4699%,lr:0.001\n",
      "Episode:21, Validation Loss:2.923430340883023e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:22, Validation Loss:2.4916773456029353e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:23, Validation Loss:1.616968660297674e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:24, Validation Loss:2.18040429545391e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:25, Validation Loss:2.4074894681418273e-05,Acc:99.2217%,lr:0.001\n",
      "Episode:26, Validation Loss:2.7417506256347453e-05,Acc:99.1884%,lr:0.001\n",
      "Episode:27, Validation Loss:2.6181028269136156e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:28, Validation Loss:2.2013383105143452e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:29, Validation Loss:1.6967179635346347e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:30, Validation Loss:3.0244813618379555e-05,Acc:99.1219%,lr:0.001\n",
      "Episode:31, Validation Loss:2.8621843825686702e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:32, Validation Loss:2.461291840691526e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:33, Validation Loss:3.180116987001585e-05,Acc:99.1019%,lr:0.001\n",
      "Episode:34, Validation Loss:2.0415051726246686e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:35, Validation Loss:2.169073540757015e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:36, Validation Loss:2.5011069463995176e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:37, Validation Loss:1.6835633357525857e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:38, Validation Loss:1.580905424011648e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:39, Validation Loss:2.29794541354023e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:40, Validation Loss:2.8689536764155112e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:41, Validation Loss:1.851729443965915e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:42, Validation Loss:2.4620770214560694e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:43, Validation Loss:2.203616085638227e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:44, Validation Loss:2.0076809270072483e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:45, Validation Loss:1.955966728735971e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:46, Validation Loss:2.230998849696487e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:47, Validation Loss:1.5911630481459745e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:48, Validation Loss:1.5079214556332025e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:49, Validation Loss:2.0310662652377262e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8477528787229433e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:51, Validation Loss:1.8331674979618013e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:52, Validation Loss:1.478047837379838e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:53, Validation Loss:1.69617018576646e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:54, Validation Loss:1.430929119997579e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:55, Validation Loss:1.6737337903966685e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:56, Validation Loss:1.5418930357136725e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:57, Validation Loss:2.2662815364288834e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:58, Validation Loss:1.7875499961161197e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:59, Validation Loss:2.1849860592847843e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:60, Validation Loss:2.1519706306454663e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:61, Validation Loss:1.4862233279456303e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:62, Validation Loss:1.918362420619311e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:63, Validation Loss:1.618878509722424e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:64, Validation Loss:1.6510711503059004e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:65, Validation Loss:3.068931519731427e-05,Acc:99.0820%,lr:0.001\n",
      "Episode:66, Validation Loss:1.252564877800013e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:67, Validation Loss:1.3946412157707467e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:68, Validation Loss:1.8015983980396853e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:69, Validation Loss:1.2379374846760551e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:70, Validation Loss:1.5429340374441405e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:71, Validation Loss:1.730911318210765e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:72, Validation Loss:1.2269806452744808e-05,Acc:99.6408%,lr:0.001\n",
      "Episode:73, Validation Loss:1.3749627576136744e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:74, Validation Loss:2.63780848375418e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:75, Validation Loss:1.4433546836610374e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:76, Validation Loss:1.213185852487681e-05,Acc:99.6142%,lr:0.001\n",
      "Episode:77, Validation Loss:1.1274846006252225e-05,Acc:99.6940%,lr:0.001\n",
      "Episode:78, Validation Loss:1.1519929749753372e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:79, Validation Loss:1.9432407404341202e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:80, Validation Loss:1.488868083939662e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:81, Validation Loss:1.5902460714828912e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:82, Validation Loss:1.4670639123644694e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:83, Validation Loss:1.3671522932062683e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:84, Validation Loss:1.2392593933563797e-05,Acc:99.6408%,lr:0.001\n",
      "Episode:85, Validation Loss:1.3011633181828508e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:86, Validation Loss:1.6541842564775897e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:87, Validation Loss:1.2151933693490079e-05,Acc:99.6208%,lr:0.001\n",
      "Episode:88, Validation Loss:1.430909356033948e-05,Acc:99.6408%,lr:0.001\n",
      "Episode:89, Validation Loss:1.4023328144965716e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:90, Validation Loss:1.1849551927050483e-05,Acc:99.6408%,lr:0.001\n",
      "Episode:91, Validation Loss:1.525322239344891e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:92, Validation Loss:1.2981073850068943e-05,Acc:99.6009%,lr:0.001\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:93, Validation Loss:1.6521001558060924e-05,Acc:99.4678%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.379397912675584e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.792447565869885e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:96, Validation Loss:8.765852984344312e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:97, Validation Loss:8.601625861962856e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:98, Validation Loss:8.827980183101616e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:99, Validation Loss:8.713659144414588e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.298708950583251e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:101, Validation Loss:8.227610306347412e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:102, Validation Loss:8.098246800322174e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:103, Validation Loss:7.860421713222534e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:104, Validation Loss:7.6242747817965675e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:105, Validation Loss:8.434602975133586e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:106, Validation Loss:8.320702493766708e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:107, Validation Loss:8.292134768567967e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:108, Validation Loss:8.50954880809561e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:109, Validation Loss:8.282911983091125e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.027945297456458e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:111, Validation Loss:8.024150740351287e-06,Acc:99.7871%,lr:0.0001\n",
      "Episode:112, Validation Loss:7.484643641096491e-06,Acc:99.7938%,lr:0.0001\n",
      "Episode:113, Validation Loss:7.93471980396115e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:114, Validation Loss:8.011591422979726e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.204463204421488e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:116, Validation Loss:8.208648998170353e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:117, Validation Loss:7.720305759087007e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:118, Validation Loss:7.4813020520433665e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:119, Validation Loss:7.983759665346748e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:120, Validation Loss:7.876227695312492e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:121, Validation Loss:8.16728147339054e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:122, Validation Loss:7.511858572549484e-06,Acc:99.7938%,lr:0.0001\n",
      "Episode:123, Validation Loss:7.701003150801319e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:124, Validation Loss:7.66884921877702e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:125, Validation Loss:7.829612319307137e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:126, Validation Loss:7.835693896920116e-06,Acc:99.7672%,lr:0.0001\n",
      "Episode:127, Validation Loss:7.811475142082194e-06,Acc:99.7938%,lr:0.0001\n",
      "Episode:128, Validation Loss:8.490039173839787e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:129, Validation Loss:7.903798749846836e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:130, Validation Loss:7.993472600219441e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:131, Validation Loss:8.072697044761099e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:132, Validation Loss:8.373893840766813e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:133, Validation Loss:8.273969254218055e-06,Acc:99.7539%,lr:0.0001\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:134, Validation Loss:7.875261042329535e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:135, Validation Loss:7.74969892405834e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:136, Validation Loss:7.64377640049504e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:137, Validation Loss:7.587192250064268e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:138, Validation Loss:7.504519063569487e-06,Acc:99.7938%,lr:1e-05\n",
      "Episode:139, Validation Loss:7.527261019729974e-06,Acc:99.7938%,lr:1e-05\n",
      "Episode:140, Validation Loss:7.5554042534026386e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:141, Validation Loss:7.505439853624299e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:142, Validation Loss:7.4236699313811556e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:143, Validation Loss:7.414851354585268e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:144, Validation Loss:7.3880150517302075e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:145, Validation Loss:7.371406398697233e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:146, Validation Loss:7.410393961226472e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:147, Validation Loss:7.404943204104718e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:148, Validation Loss:7.42268556672703e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:149, Validation Loss:7.3577637264743935e-06,Acc:99.7871%,lr:1e-05\n",
      "Episode:150, Validation Loss:7.397030377544923e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:151, Validation Loss:7.407784893436673e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:152, Validation Loss:7.372549339730398e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:153, Validation Loss:7.398950417182582e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:154, Validation Loss:7.400673165686425e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:155, Validation Loss:7.4823474433563524e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:156, Validation Loss:7.457807586065426e-06,Acc:99.7805%,lr:1e-05\n",
      "Episode:157, Validation Loss:7.4738417985661235e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:158, Validation Loss:7.436316134296596e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:159, Validation Loss:7.52053685773049e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:160, Validation Loss:7.514534560562532e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:161, Validation Loss:7.481068237848231e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:162, Validation Loss:7.453684027117398e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:163, Validation Loss:7.448561381221019e-06,Acc:99.7738%,lr:1e-05\n",
      "Episode:164, Validation Loss:7.48824959639668e-06,Acc:99.7871%,lr:1e-05\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:7.527261019729974e-06 Acc:0.9979377328366152==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10163\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10163_s11.npy\n",
      "shape of top1_dig_csv: (10163, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10163_s11.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s11.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10163, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75163, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75163_s11.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75163_s11.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step10\n",
      "Step: 11\n",
      "global_data len: 75163\n",
      "validation rate: 0.1999920173489616\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.004063000524849762,Acc:15.3872%,lr:0.001\n",
      "Episode:2, Validation Loss:0.011139552411784385,Acc:9.9388%,lr:0.001\n",
      "Episode:3, Validation Loss:0.017820145996280526,Acc:9.9388%,lr:0.001\n",
      "Episode:4, Validation Loss:0.02790166964995347,Acc:9.9388%,lr:0.001\n",
      "Episode:5, Validation Loss:0.028753820665977686,Acc:10.0519%,lr:0.001\n",
      "Episode:6, Validation Loss:0.008736750367729508,Acc:24.8670%,lr:0.001\n",
      "Episode:7, Validation Loss:0.001359077893145989,Acc:82.4109%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0001640833097452049,Acc:95.6493%,lr:0.001\n",
      "Episode:9, Validation Loss:8.34340998380504e-05,Acc:97.5652%,lr:0.001\n",
      "Episode:10, Validation Loss:4.851354257327055e-05,Acc:98.6762%,lr:0.001\n",
      "Episode:11, Validation Loss:3.3019821939195894e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:12, Validation Loss:3.851499513065231e-05,Acc:99.0354%,lr:0.001\n",
      "Episode:13, Validation Loss:3.1433910321783295e-05,Acc:99.1485%,lr:0.001\n",
      "Episode:14, Validation Loss:4.265369414220534e-05,Acc:98.8225%,lr:0.001\n",
      "Episode:15, Validation Loss:2.8089786400922346e-05,Acc:99.0687%,lr:0.001\n",
      "Episode:16, Validation Loss:4.4622055927470934e-05,Acc:98.7959%,lr:0.001\n",
      "Episode:17, Validation Loss:2.6718189381261243e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:18, Validation Loss:2.5601564220560712e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:19, Validation Loss:3.3810841065334345e-05,Acc:98.9822%,lr:0.001\n",
      "Episode:20, Validation Loss:2.2720793478226584e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:21, Validation Loss:3.823109452888774e-05,Acc:98.8757%,lr:0.001\n",
      "Episode:22, Validation Loss:3.290643316791247e-05,Acc:99.1285%,lr:0.001\n",
      "Episode:23, Validation Loss:3.059808721943318e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:24, Validation Loss:3.316307684754583e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:25, Validation Loss:2.7577116309272096e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:26, Validation Loss:1.7394991414378605e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:27, Validation Loss:1.7305191863028846e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:28, Validation Loss:2.4089485690881908e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:29, Validation Loss:2.288723696804367e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:30, Validation Loss:2.4429722820438875e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:31, Validation Loss:1.9137565063400876e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:32, Validation Loss:3.807661406093135e-05,Acc:98.7693%,lr:0.001\n",
      "Episode:33, Validation Loss:2.4309012460948117e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:34, Validation Loss:2.6188538451403965e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:35, Validation Loss:2.1667491995044024e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:36, Validation Loss:1.6829219734481574e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:37, Validation Loss:1.986878010840366e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:38, Validation Loss:1.97324106180292e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:39, Validation Loss:2.6062822914590632e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:40, Validation Loss:2.0323166766953855e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:41, Validation Loss:1.7722791094013736e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:42, Validation Loss:2.9152230483030246e-05,Acc:99.1352%,lr:0.001\n",
      "Episode:43, Validation Loss:1.8898657310710443e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:44, Validation Loss:2.96922059464028e-05,Acc:99.0221%,lr:0.001\n",
      "Episode:45, Validation Loss:1.5172020398613665e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:46, Validation Loss:2.533198338489684e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:47, Validation Loss:1.545372983354514e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:48, Validation Loss:2.1780203153568103e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:49, Validation Loss:2.1913543801027102e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:50, Validation Loss:1.9773862681769433e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:51, Validation Loss:1.7741801053138886e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:52, Validation Loss:1.7342442535597506e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:53, Validation Loss:1.8941437122483894e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:54, Validation Loss:1.9509387051388263e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:55, Validation Loss:2.11900334801285e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:56, Validation Loss:1.4774113448169192e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:57, Validation Loss:1.4464799951644989e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:58, Validation Loss:1.872095461917953e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:59, Validation Loss:1.54517390324123e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:60, Validation Loss:1.937758579365453e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:61, Validation Loss:1.873539225656803e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:62, Validation Loss:1.5398537571095386e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:63, Validation Loss:1.4420450422684838e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:64, Validation Loss:1.6380690705842038e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:65, Validation Loss:1.2179019330517984e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:66, Validation Loss:1.2784231990177289e-05,Acc:99.6009%,lr:0.001\n",
      "Episode:67, Validation Loss:1.2754785759892946e-05,Acc:99.6674%,lr:0.001\n",
      "Episode:68, Validation Loss:2.5114260773516957e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:69, Validation Loss:1.550613766949487e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:70, Validation Loss:1.4782054782232954e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:71, Validation Loss:1.6491789397540213e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:72, Validation Loss:1.4917869425659772e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:73, Validation Loss:1.4256380715007443e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:74, Validation Loss:2.544500581035911e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:75, Validation Loss:1.5168853424798783e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:76, Validation Loss:1.984456299539971e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:77, Validation Loss:1.685451020418749e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:78, Validation Loss:1.3659775145341974e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:79, Validation Loss:4.625123364929191e-05,Acc:98.7759%,lr:0.001\n",
      "Episode:80, Validation Loss:1.68458899253104e-05,Acc:99.3813%,lr:0.001\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:81, Validation Loss:1.6656275170727842e-05,Acc:99.5277%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.0965409774894312e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:83, Validation Loss:9.699729695012115e-06,Acc:99.6541%,lr:0.0001\n",
      "Episode:84, Validation Loss:9.23662505297465e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.275966663059281e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.701111614171807e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:87, Validation Loss:8.872723488901415e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.058354023577345e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:89, Validation Loss:8.609016546597898e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:90, Validation Loss:8.835917815294448e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:91, Validation Loss:8.699214707355215e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:92, Validation Loss:8.787860080402517e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:93, Validation Loss:8.768415414755981e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:94, Validation Loss:8.579589437483698e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.747944184675607e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:96, Validation Loss:8.917430380062895e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:97, Validation Loss:8.829931990677682e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:98, Validation Loss:8.826712888634272e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:99, Validation Loss:8.599245659632786e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:100, Validation Loss:8.633227975138955e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:101, Validation Loss:8.49282107563286e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:102, Validation Loss:8.671037653451682e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.384807228978611e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:104, Validation Loss:8.088289727836038e-06,Acc:99.7805%,lr:0.0001\n",
      "Episode:105, Validation Loss:8.299940953364753e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:106, Validation Loss:8.510112824531083e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:107, Validation Loss:8.33975741745802e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:108, Validation Loss:8.57339319093361e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:109, Validation Loss:8.584808060966785e-06,Acc:99.7472%,lr:0.0001\n",
      "Episode:110, Validation Loss:8.234428718910137e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:111, Validation Loss:8.755733618119205e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:112, Validation Loss:8.33685168111226e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:113, Validation Loss:8.484555487104648e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:114, Validation Loss:8.65093486020743e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:115, Validation Loss:8.6112289488496e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:116, Validation Loss:8.677688544738032e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:117, Validation Loss:8.374958678518936e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:118, Validation Loss:8.492939024365658e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:119, Validation Loss:8.97288668349072e-06,Acc:99.7139%,lr:0.0001\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:120, Validation Loss:8.97181148359779e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:121, Validation Loss:8.69444276339029e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:122, Validation Loss:8.53781875727491e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:123, Validation Loss:8.399831611259646e-06,Acc:99.7672%,lr:1e-05\n",
      "Episode:124, Validation Loss:8.389461013459228e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:125, Validation Loss:8.370995980577405e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:126, Validation Loss:8.355149765810698e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:127, Validation Loss:8.378249734710503e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:128, Validation Loss:8.338876348942966e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:129, Validation Loss:8.399881385160217e-06,Acc:99.7472%,lr:1e-05\n",
      "Episode:130, Validation Loss:8.350980777626519e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:131, Validation Loss:8.291204840003326e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:132, Validation Loss:8.275719759009378e-06,Acc:99.7605%,lr:1e-05\n",
      "Episode:133, Validation Loss:8.259375278610972e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:134, Validation Loss:8.239900703705995e-06,Acc:99.7539%,lr:1e-05\n",
      "Episode:135, Validation Loss:8.257848264596476e-06,Acc:99.7539%,lr:1e-05\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:8.088289727836038e-06 Acc:0.9978046833422033==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.005462709419774273,Acc:10.2847%,lr:0.001\n",
      "Episode:2, Validation Loss:0.00428635633772139,Acc:20.6759%,lr:0.001\n",
      "Episode:3, Validation Loss:0.017377525901083872,Acc:9.9188%,lr:0.001\n",
      "Episode:4, Validation Loss:0.022304941581372823,Acc:9.9188%,lr:0.001\n",
      "Episode:5, Validation Loss:0.01324463455267191,Acc:10.9832%,lr:0.001\n",
      "Episode:6, Validation Loss:0.012125398517606613,Acc:12.2938%,lr:0.001\n",
      "Episode:7, Validation Loss:0.004348537368683056,Acc:43.5005%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0018672683633598258,Acc:67.7555%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0007493641939234264,Acc:85.0186%,lr:0.001\n",
      "Episode:10, Validation Loss:6.736663889839746e-05,Acc:98.3502%,lr:0.001\n",
      "Episode:11, Validation Loss:4.862136633282586e-05,Acc:98.7028%,lr:0.001\n",
      "Episode:12, Validation Loss:5.5869408556522364e-05,Acc:98.5631%,lr:0.001\n",
      "Episode:13, Validation Loss:0.0003676749190921286,Acc:90.5801%,lr:0.001\n",
      "Episode:14, Validation Loss:3.6291187399122996e-05,Acc:98.9156%,lr:0.001\n",
      "Episode:15, Validation Loss:4.763199073947003e-05,Acc:98.8159%,lr:0.001\n",
      "Episode:16, Validation Loss:3.6556541968281757e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:17, Validation Loss:3.132830000224267e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:18, Validation Loss:2.8175848425663868e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:19, Validation Loss:4.513770542114957e-05,Acc:98.9356%,lr:0.001\n",
      "Episode:20, Validation Loss:3.984672916500952e-05,Acc:98.9156%,lr:0.001\n",
      "Episode:21, Validation Loss:5.044017203683514e-05,Acc:98.6828%,lr:0.001\n",
      "Episode:22, Validation Loss:2.5249084337808274e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:23, Validation Loss:2.510339369131981e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:24, Validation Loss:2.429691245437398e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:25, Validation Loss:2.3521713854496217e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:26, Validation Loss:2.843960973435637e-05,Acc:99.1485%,lr:0.001\n",
      "Episode:27, Validation Loss:3.736250680197722e-05,Acc:98.9290%,lr:0.001\n",
      "Episode:28, Validation Loss:2.6050059792960876e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:29, Validation Loss:2.0873100108240533e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:30, Validation Loss:2.394027823603109e-05,Acc:99.2084%,lr:0.001\n",
      "Episode:31, Validation Loss:2.0881172603153845e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:32, Validation Loss:2.174837195808628e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:33, Validation Loss:2.5070849444247295e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:34, Validation Loss:2.489861870653424e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:35, Validation Loss:2.3641118863047344e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:36, Validation Loss:2.5221584610117597e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:37, Validation Loss:2.0822595932311268e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:38, Validation Loss:2.7652735092804558e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:39, Validation Loss:2.4960044609851632e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:40, Validation Loss:1.6744460706351728e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:41, Validation Loss:2.4077037429638273e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:42, Validation Loss:0.00018453312430088668,Acc:94.9574%,lr:0.001\n",
      "Episode:43, Validation Loss:1.919779255183264e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:44, Validation Loss:1.856123084601901e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:45, Validation Loss:2.1715788306998503e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:46, Validation Loss:2.1930682688987178e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:47, Validation Loss:2.0115087049189972e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:48, Validation Loss:1.6322077976608132e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:49, Validation Loss:2.413121937561489e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:50, Validation Loss:2.6201539422113285e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:51, Validation Loss:2.2710803816885057e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:52, Validation Loss:2.1913442441012994e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:53, Validation Loss:1.619792930700555e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:54, Validation Loss:1.734650424696969e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:55, Validation Loss:1.74741924008302e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:56, Validation Loss:1.55166200978732e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:57, Validation Loss:1.776034894442466e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:58, Validation Loss:1.9181583127767212e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:59, Validation Loss:1.5018552880260365e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:60, Validation Loss:2.0245833970713387e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:61, Validation Loss:2.592219140909973e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:62, Validation Loss:2.085277339827196e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:63, Validation Loss:3.61065188707301e-05,Acc:99.0154%,lr:0.001\n",
      "Episode:64, Validation Loss:1.5703810452265013e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:65, Validation Loss:1.881395494134154e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:66, Validation Loss:1.7037234398446673e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:67, Validation Loss:1.623101848806589e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:68, Validation Loss:2.2788070691942757e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:69, Validation Loss:2.0661498811502385e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:70, Validation Loss:1.725776820131808e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:71, Validation Loss:1.8110100966504022e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:72, Validation Loss:1.4111328803889053e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:73, Validation Loss:1.4931502254623296e-05,Acc:99.5942%,lr:0.001\n",
      "Episode:74, Validation Loss:1.999070334950578e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:75, Validation Loss:1.7904218301393126e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:76, Validation Loss:1.728068900895823e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:77, Validation Loss:1.917261261162866e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:78, Validation Loss:1.6113808115883797e-05,Acc:99.6275%,lr:0.001\n",
      "Episode:79, Validation Loss:1.7867527060516023e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:80, Validation Loss:1.850529263334318e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:81, Validation Loss:1.613579444119339e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:82, Validation Loss:1.434294613223957e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:83, Validation Loss:1.6302135517744386e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:84, Validation Loss:2.1016049821340162e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:85, Validation Loss:1.852179287886718e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:86, Validation Loss:1.4444675373122644e-05,Acc:99.6142%,lr:0.001\n",
      "Episode:87, Validation Loss:1.643856591086571e-05,Acc:99.5144%,lr:0.001\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:88, Validation Loss:1.749231694677588e-05,Acc:99.4345%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.2094638148791585e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.1028934313760533e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0326813712880658e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.839676834539792e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.0297470267598397e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0460184873669087e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0538707627801343e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.764538240976366e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.552271908546632e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0119721976452332e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.073005392863958e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.590281015475136e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.704679576605717e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:102, Validation Loss:9.76511334753563e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.407531605124426e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.66302023907135e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.0017813280018611e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.581280388721146e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.874910560544102e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.970551881068815e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.774632793823935e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.787625152649414e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.402735312451956e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:112, Validation Loss:9.70856287019023e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.815241946199907e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.897972008301627e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.928698404412072e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.648121308293461e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.483886704725145e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:118, Validation Loss:1.0015488721920002e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:119, Validation Loss:9.61604194805827e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:120, Validation Loss:9.241755505326884e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:121, Validation Loss:9.694044178866243e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:122, Validation Loss:9.362946612390671e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:123, Validation Loss:9.177826022052223e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:124, Validation Loss:9.046873096832653e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:125, Validation Loss:9.553047845476148e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:126, Validation Loss:9.668545924229205e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:127, Validation Loss:9.568872305942762e-06,Acc:99.7139%,lr:0.0001\n",
      "Episode:128, Validation Loss:9.620119675056153e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:129, Validation Loss:9.539251142895684e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:130, Validation Loss:9.931697818228084e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:131, Validation Loss:9.938241734737932e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:132, Validation Loss:1.0051419359977304e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:133, Validation Loss:9.591354000441108e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:134, Validation Loss:9.053279502003068e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:135, Validation Loss:9.120689270578765e-06,Acc:99.7406%,lr:0.0001\n",
      "Episode:136, Validation Loss:9.486907090646764e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:137, Validation Loss:9.508511736025482e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:138, Validation Loss:9.372036176981002e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:139, Validation Loss:9.730558039718657e-06,Acc:99.7006%,lr:0.0001\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:140, Validation Loss:9.53383578588277e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:141, Validation Loss:9.392652655156164e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:142, Validation Loss:9.356088455054689e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:143, Validation Loss:9.365589996059328e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:144, Validation Loss:9.37010866390098e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:145, Validation Loss:9.316983935088633e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:146, Validation Loss:9.334850155497134e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:147, Validation Loss:9.39868772704751e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:148, Validation Loss:9.428868445698142e-06,Acc:99.7139%,lr:1e-05\n",
      "Episode:149, Validation Loss:9.423875628597341e-06,Acc:99.7073%,lr:1e-05\n",
      "Episode:150, Validation Loss:9.351837622996036e-06,Acc:99.7272%,lr:1e-05\n",
      "Episode:151, Validation Loss:9.267349962141124e-06,Acc:99.7406%,lr:1e-05\n",
      "Episode:152, Validation Loss:9.272632702338514e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:153, Validation Loss:9.274420814421137e-06,Acc:99.7339%,lr:1e-05\n",
      "Episode:154, Validation Loss:9.286518032975324e-06,Acc:99.7206%,lr:1e-05\n",
      "Episode:155, Validation Loss:9.265073388963621e-06,Acc:99.7139%,lr:1e-05\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:1 Saved Loss:9.267349962141124e-06 Acc:0.9974055348589675==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0063088580989786895,Acc:9.5663%,lr:0.001\n",
      "Episode:2, Validation Loss:0.006824410710327165,Acc:10.6240%,lr:0.001\n",
      "Episode:3, Validation Loss:0.008956381524732101,Acc:10.9101%,lr:0.001\n",
      "Episode:4, Validation Loss:0.014245449576750913,Acc:10.1650%,lr:0.001\n",
      "Episode:5, Validation Loss:0.010439199041089458,Acc:14.5889%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0046374898695324,Acc:31.0737%,lr:0.001\n",
      "Episode:7, Validation Loss:0.002593277996686496,Acc:56.2134%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0003727136329490495,Acc:90.1144%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0032171913129716177,Acc:52.5080%,lr:0.001\n",
      "Episode:10, Validation Loss:8.032333647050141e-05,Acc:97.6583%,lr:0.001\n",
      "Episode:11, Validation Loss:0.0004295922653227172,Acc:88.4713%,lr:0.001\n",
      "Episode:12, Validation Loss:3.897277982791508e-05,Acc:98.9023%,lr:0.001\n",
      "Episode:13, Validation Loss:3.224294018069755e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:14, Validation Loss:8.47223437351074e-05,Acc:97.3856%,lr:0.001\n",
      "Episode:15, Validation Loss:9.376370655833692e-05,Acc:97.1860%,lr:0.001\n",
      "Episode:16, Validation Loss:3.3755535175582715e-05,Acc:98.9689%,lr:0.001\n",
      "Episode:17, Validation Loss:3.631622865082356e-05,Acc:98.8957%,lr:0.001\n",
      "Episode:18, Validation Loss:3.350086900752044e-05,Acc:98.9622%,lr:0.001\n",
      "Episode:19, Validation Loss:2.435774835071439e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:20, Validation Loss:3.453028862160879e-05,Acc:98.9290%,lr:0.001\n",
      "Episode:21, Validation Loss:2.4405869079368144e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:22, Validation Loss:2.8634182982416373e-05,Acc:99.1751%,lr:0.001\n",
      "Episode:23, Validation Loss:2.7321975062610685e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:24, Validation Loss:2.2556121372372434e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:25, Validation Loss:2.496256367880861e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:26, Validation Loss:2.7793374590619312e-05,Acc:99.1951%,lr:0.001\n",
      "Episode:27, Validation Loss:2.2033500651659928e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:28, Validation Loss:2.6007097272946835e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:29, Validation Loss:2.9993990457013544e-05,Acc:99.0420%,lr:0.001\n",
      "Episode:30, Validation Loss:2.2276138186458737e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:31, Validation Loss:2.0056252765304204e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:32, Validation Loss:1.8376098948710772e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:33, Validation Loss:2.016250863537478e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:34, Validation Loss:2.1980465201441916e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:35, Validation Loss:2.2310486096569584e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:36, Validation Loss:2.129222240354499e-05,Acc:99.2416%,lr:0.001\n",
      "Episode:37, Validation Loss:2.3585534604992906e-05,Acc:99.1751%,lr:0.001\n",
      "Episode:38, Validation Loss:1.912827909829421e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:39, Validation Loss:2.2935913627875048e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:40, Validation Loss:1.6696209002716417e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:41, Validation Loss:1.765987976464607e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:42, Validation Loss:1.8626222812717838e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:43, Validation Loss:2.3154792833841343e-05,Acc:99.2283%,lr:0.001\n",
      "Episode:44, Validation Loss:2.149239300436451e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:45, Validation Loss:1.9091626084268394e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:46, Validation Loss:2.188974024431543e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:47, Validation Loss:2.2908105731046122e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:48, Validation Loss:2.0643136478433144e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:49, Validation Loss:1.7172094578733304e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:50, Validation Loss:1.579009623109636e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:51, Validation Loss:1.5428052076890453e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:52, Validation Loss:1.4152048392832962e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:53, Validation Loss:2.467590349489955e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:54, Validation Loss:1.9129469737701986e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:55, Validation Loss:1.685215479200146e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:56, Validation Loss:1.8767771948507614e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:57, Validation Loss:1.7680266293131524e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:58, Validation Loss:1.764030947546738e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:59, Validation Loss:1.378663101329202e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:60, Validation Loss:1.6439278311918412e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:61, Validation Loss:2.2741193575075787e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:62, Validation Loss:1.7861396824210455e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:63, Validation Loss:1.556457611650403e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:64, Validation Loss:2.205104906877236e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:65, Validation Loss:1.6688858945727617e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:66, Validation Loss:1.475404388657382e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:67, Validation Loss:1.798597745103697e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:68, Validation Loss:1.6448243360440065e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:69, Validation Loss:1.4314303688106225e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:70, Validation Loss:1.6280320469793596e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:71, Validation Loss:1.6393439670526058e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:72, Validation Loss:1.7204747124891796e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:73, Validation Loss:1.868441907372752e-05,Acc:99.4013%,lr:0.001\n",
      "Episode:74, Validation Loss:1.7616748166711186e-05,Acc:99.4811%,lr:0.001\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:75, Validation Loss:2.1726674161863302e-05,Acc:99.3547%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.378332079720781e-05,Acc:99.5410%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.2200720882823392e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.0991482036371634e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.0687785006032591e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.0483479461850259e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.0753886945428701e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.0836606196208623e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0411995962438604e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0424117157964344e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.738159452194765e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.0224493194922623e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.823383955743924e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0560060019330769e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.0321141919988531e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0277223202066338e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.087283490457636e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.02184086511662e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.040913656917998e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0588782634526618e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0836354933655313e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0692985685509514e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0133988770174022e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0002467940780054e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0220286103799154e-05,Acc:99.6807%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.1203297948689776e-05,Acc:99.6541%,lr:0.0001\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:101, Validation Loss:1.0713562883581409e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:102, Validation Loss:1.0411299313698608e-05,Acc:99.6873%,lr:1e-05\n",
      "Episode:103, Validation Loss:1.0218267391488836e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:104, Validation Loss:1.017407188514181e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:105, Validation Loss:1.0161517539739156e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:106, Validation Loss:1.0127184375156037e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:107, Validation Loss:1.0132101853762245e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:108, Validation Loss:1.0146019401518453e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:109, Validation Loss:1.0116685017301022e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:110, Validation Loss:1.0199978909970218e-05,Acc:99.6541%,lr:1e-05\n",
      "Episode:111, Validation Loss:1.0201917513174031e-05,Acc:99.6607%,lr:1e-05\n",
      "Episode:112, Validation Loss:1.0072130073226706e-05,Acc:99.6541%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.0064294652942967e-05,Acc:99.6740%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.0040120955605204e-05,Acc:99.6807%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.0114793082453339e-05,Acc:99.6674%,lr:1e-05\n",
      "Episode:116, Validation Loss:1.014106897780986e-05,Acc:99.6740%,lr:1e-05\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:2 Saved Loss:1.0836354933655313e-05 Acc:0.9970729111229377==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0022768585557567116,Acc:30.7145%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005486863829342211,Acc:13.4912%,lr:0.001\n",
      "Episode:3, Validation Loss:0.007434671010153924,Acc:12.4667%,lr:0.001\n",
      "Episode:4, Validation Loss:0.005133858667275194,Acc:33.6615%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0031207461919221173,Acc:43.0482%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0014699510813647601,Acc:72.9178%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00017702169101754676,Acc:95.0905%,lr:0.001\n",
      "Episode:8, Validation Loss:4.998678757852224e-05,Acc:98.7294%,lr:0.001\n",
      "Episode:9, Validation Loss:4.791217410521599e-05,Acc:98.7693%,lr:0.001\n",
      "Episode:10, Validation Loss:6.026168665618196e-05,Acc:98.2770%,lr:0.001\n",
      "Episode:11, Validation Loss:4.9188104990974835e-05,Acc:98.8159%,lr:0.001\n",
      "Episode:12, Validation Loss:3.8347475527091313e-05,Acc:99.0620%,lr:0.001\n",
      "Episode:13, Validation Loss:3.650773600628079e-05,Acc:98.9888%,lr:0.001\n",
      "Episode:14, Validation Loss:3.0079862772486607e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:15, Validation Loss:3.2494627132599436e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:16, Validation Loss:3.6925470673079155e-05,Acc:98.9955%,lr:0.001\n",
      "Episode:17, Validation Loss:3.931391600097127e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:18, Validation Loss:3.724091400319493e-05,Acc:99.0620%,lr:0.001\n",
      "Episode:19, Validation Loss:2.8998195602617534e-05,Acc:99.1817%,lr:0.001\n",
      "Episode:20, Validation Loss:2.439420654410184e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:21, Validation Loss:2.1990980683345628e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:22, Validation Loss:2.298513596516624e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:23, Validation Loss:2.8669137503711894e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:24, Validation Loss:6.071728678492551e-05,Acc:98.2504%,lr:0.001\n",
      "Episode:25, Validation Loss:2.0131761731828714e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:26, Validation Loss:2.079340595203814e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:27, Validation Loss:3.1193467268463523e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:28, Validation Loss:2.214294202038904e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:29, Validation Loss:2.034459799749181e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:30, Validation Loss:2.070581909723108e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:31, Validation Loss:2.2068648723495837e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:32, Validation Loss:3.67033533987893e-05,Acc:98.8757%,lr:0.001\n",
      "Episode:33, Validation Loss:2.0157348413165103e-05,Acc:99.4745%,lr:0.001\n",
      "Episode:34, Validation Loss:2.4138939340894783e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:35, Validation Loss:1.9539211554023547e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:36, Validation Loss:2.3068656337989207e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:37, Validation Loss:2.314024067078898e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:38, Validation Loss:2.0581826246965593e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:39, Validation Loss:2.1502779617790625e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:40, Validation Loss:1.9612240762672346e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:41, Validation Loss:1.819271713799087e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:42, Validation Loss:1.7991747506143265e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:43, Validation Loss:2.8919149784965042e-05,Acc:99.1951%,lr:0.001\n",
      "Episode:44, Validation Loss:2.2647455635769547e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:45, Validation Loss:2.7617343967585185e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:46, Validation Loss:1.9574248259951533e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:47, Validation Loss:1.840295529433146e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:48, Validation Loss:1.5836207045191635e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:49, Validation Loss:1.8529494102457423e-05,Acc:99.4878%,lr:0.001\n",
      "Episode:50, Validation Loss:2.2395550319949734e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:51, Validation Loss:2.100911462171962e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:52, Validation Loss:2.133990717881288e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:53, Validation Loss:2.102450944831225e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:54, Validation Loss:1.5210802840319734e-05,Acc:99.5609%,lr:0.001\n",
      "Episode:55, Validation Loss:1.6343126226139234e-05,Acc:99.5476%,lr:0.001\n",
      "Episode:56, Validation Loss:1.3838867250486203e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:57, Validation Loss:1.7767212956602535e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:58, Validation Loss:1.6049771510687135e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:59, Validation Loss:1.5906046263371982e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:60, Validation Loss:1.652991945806746e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:61, Validation Loss:1.9986046519786705e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:62, Validation Loss:1.6589895203786923e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:63, Validation Loss:2.170950553502378e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:64, Validation Loss:1.603518146154148e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:65, Validation Loss:1.3429023094471303e-05,Acc:99.6474%,lr:0.001\n",
      "Episode:66, Validation Loss:1.5328695812719088e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:67, Validation Loss:1.8824260268497175e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:68, Validation Loss:2.2251970886077857e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:69, Validation Loss:1.7957522175976132e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:70, Validation Loss:2.003005736627918e-05,Acc:99.4412%,lr:0.001\n",
      "Episode:71, Validation Loss:1.6316475760302703e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:72, Validation Loss:1.6751082346662125e-05,Acc:99.5543%,lr:0.001\n",
      "Episode:73, Validation Loss:2.9009292541570395e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:74, Validation Loss:1.558123905848099e-05,Acc:99.6075%,lr:0.001\n",
      "Episode:75, Validation Loss:2.0145625253953933e-05,Acc:99.5144%,lr:0.001\n",
      "Episode:76, Validation Loss:1.706852806368253e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:77, Validation Loss:1.788068186797047e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:78, Validation Loss:1.5491190846729876e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:79, Validation Loss:1.485843900115313e-05,Acc:99.5676%,lr:0.001\n",
      "Episode:80, Validation Loss:1.859702223796891e-05,Acc:99.3481%,lr:0.001\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:81, Validation Loss:1.7743810781829373e-05,Acc:99.5144%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.125052462130222e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0671520394661194e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0709709669634336e-05,Acc:99.7073%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.0465012376675974e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:86, Validation Loss:1.026650929058733e-05,Acc:99.7406%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.960182847657369e-06,Acc:99.7272%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.902605898812128e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.0256245543651417e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0150349010629634e-05,Acc:99.7339%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0122729374847695e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:92, Validation Loss:1.0245800203682895e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.94396653873157e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.871007743075454e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0210693309352719e-05,Acc:99.7272%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.80413470706224e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0281264847439395e-05,Acc:99.7206%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0372042343252899e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.019515633246524e-05,Acc:99.7406%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0058671797545425e-05,Acc:99.7406%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.026327560565069e-05,Acc:99.7672%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.0930508582224795e-05,Acc:99.7139%,lr:0.0001\n",
      "Episode:103, Validation Loss:1.0462836110260597e-05,Acc:99.7539%,lr:0.0001\n",
      "Episode:104, Validation Loss:1.0741784251513116e-05,Acc:99.7472%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.063916642995013e-05,Acc:99.7539%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.925849117725758e-06,Acc:99.7539%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0144826953769962e-05,Acc:99.7805%,lr:0.0001\n",
      "Episode:108, Validation Loss:1.0241332881875284e-05,Acc:99.7672%,lr:0.0001\n",
      "Episode:109, Validation Loss:9.872953269862139e-06,Acc:99.7738%,lr:0.0001\n",
      "Episode:110, Validation Loss:9.911620907102349e-06,Acc:99.7605%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.982946457439452e-06,Acc:99.7605%,lr:0.0001\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:112, Validation Loss:1.0490558476833118e-05,Acc:99.7738%,lr:1e-05\n",
      "Episode:113, Validation Loss:1.032336837076297e-05,Acc:99.7672%,lr:1e-05\n",
      "Episode:114, Validation Loss:1.0279671803819132e-05,Acc:99.7738%,lr:1e-05\n",
      "Episode:115, Validation Loss:1.0201798867436245e-05,Acc:99.7672%,lr:1e-05\n",
      "Episode:116, Validation Loss:1.019195323055853e-05,Acc:99.7605%,lr:1e-05\n",
      "Episode:117, Validation Loss:1.0176332225847619e-05,Acc:99.7605%,lr:1e-05\n",
      "Episode:118, Validation Loss:1.0171686827010331e-05,Acc:99.7738%,lr:1e-05\n",
      "Episode:119, Validation Loss:1.0207303557254993e-05,Acc:99.7605%,lr:1e-05\n",
      "Episode:120, Validation Loss:1.0180276871359987e-05,Acc:99.7805%,lr:1e-05\n",
      "Episode:121, Validation Loss:1.0182493587298107e-05,Acc:99.7805%,lr:1e-05\n",
      "Episode:122, Validation Loss:1.0232814040457302e-05,Acc:99.7805%,lr:1e-05\n",
      "Episode:123, Validation Loss:1.021411912758627e-05,Acc:99.7672%,lr:1e-05\n",
      "Episode:124, Validation Loss:1.0157002078120444e-05,Acc:99.7672%,lr:1e-05\n",
      "Episode:125, Validation Loss:1.0130878431886582e-05,Acc:99.7805%,lr:1e-05\n",
      "Episode:126, Validation Loss:1.0081785497443474e-05,Acc:99.7805%,lr:1e-05\n",
      "Episode:127, Validation Loss:1.0127077446846533e-05,Acc:99.7672%,lr:1e-05\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:3 Saved Loss:1.0081785497443474e-05 Acc:0.9978046833422033==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.004162718841787219,Acc:11.7084%,lr:0.001\n",
      "Episode:2, Validation Loss:0.0034524942884551772,Acc:16.4316%,lr:0.001\n",
      "Episode:3, Validation Loss:0.00556718614775174,Acc:25.7916%,lr:0.001\n",
      "Episode:4, Validation Loss:0.0050953937820324945,Acc:30.7344%,lr:0.001\n",
      "Episode:5, Validation Loss:0.0013952071105881915,Acc:68.8598%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0007259076170746223,Acc:82.3842%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00019105989436414282,Acc:95.5961%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00016908992791648492,Acc:95.3499%,lr:0.001\n",
      "Episode:9, Validation Loss:5.361806460521905e-05,Acc:98.5032%,lr:0.001\n",
      "Episode:10, Validation Loss:4.218812653236785e-05,Acc:98.9489%,lr:0.001\n",
      "Episode:11, Validation Loss:2.8310184272332292e-05,Acc:99.1485%,lr:0.001\n",
      "Episode:12, Validation Loss:5.221768431543923e-05,Acc:98.7028%,lr:0.001\n",
      "Episode:13, Validation Loss:4.955128436494756e-05,Acc:98.8159%,lr:0.001\n",
      "Episode:14, Validation Loss:6.134656320874713e-05,Acc:98.2704%,lr:0.001\n",
      "Episode:15, Validation Loss:4.052240195812508e-05,Acc:98.9156%,lr:0.001\n",
      "Episode:16, Validation Loss:3.6834001624406555e-05,Acc:98.9955%,lr:0.001\n",
      "Episode:17, Validation Loss:4.4264749486540594e-05,Acc:98.7892%,lr:0.001\n",
      "Episode:18, Validation Loss:2.7986800661404726e-05,Acc:99.1618%,lr:0.001\n",
      "Episode:19, Validation Loss:2.4460045759084855e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:20, Validation Loss:2.17328349734543e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:21, Validation Loss:3.958786845191354e-05,Acc:99.0553%,lr:0.001\n",
      "Episode:22, Validation Loss:2.7672781266010367e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:23, Validation Loss:2.3299471738868693e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:24, Validation Loss:3.284732578198379e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:25, Validation Loss:3.21576936827688e-05,Acc:99.0287%,lr:0.001\n",
      "Episode:26, Validation Loss:3.893236580595747e-05,Acc:99.0221%,lr:0.001\n",
      "Episode:27, Validation Loss:3.9740089384592104e-05,Acc:98.9556%,lr:0.001\n",
      "Episode:28, Validation Loss:2.1165332057081587e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:29, Validation Loss:2.3894889519102336e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:30, Validation Loss:2.737272731035932e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:31, Validation Loss:3.0207037930676694e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:32, Validation Loss:2.303035455092217e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:33, Validation Loss:3.0543272021192384e-05,Acc:99.0354%,lr:0.001\n",
      "Episode:34, Validation Loss:2.5875384829137444e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:35, Validation Loss:2.0717970713152253e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:36, Validation Loss:2.1530246013153925e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:37, Validation Loss:2.442391221513134e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:38, Validation Loss:2.3741041126246145e-05,Acc:99.3348%,lr:0.001\n",
      "Episode:39, Validation Loss:1.9079098178588247e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:40, Validation Loss:2.2145422304890746e-05,Acc:99.3481%,lr:0.001\n",
      "Episode:41, Validation Loss:2.606212516613166e-05,Acc:99.2815%,lr:0.001\n",
      "Episode:42, Validation Loss:1.8834175706552087e-05,Acc:99.4345%,lr:0.001\n",
      "Episode:43, Validation Loss:1.6150282696632945e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:44, Validation Loss:1.839415813107767e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:45, Validation Loss:1.5181675559517438e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:46, Validation Loss:2.1514508167173696e-05,Acc:99.2882%,lr:0.001\n",
      "Episode:47, Validation Loss:1.9636353541774245e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:48, Validation Loss:4.5574318638399535e-05,Acc:98.5564%,lr:0.001\n",
      "Episode:49, Validation Loss:7.928607657258342e-05,Acc:97.3257%,lr:0.001\n",
      "Episode:50, Validation Loss:1.5992892093454875e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:51, Validation Loss:1.6517432706659543e-05,Acc:99.4478%,lr:0.001\n",
      "Episode:52, Validation Loss:1.935355238018715e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:53, Validation Loss:1.7166895510112355e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:54, Validation Loss:1.9695449837579126e-05,Acc:99.3747%,lr:0.001\n",
      "Episode:55, Validation Loss:2.4225540754562238e-05,Acc:99.1684%,lr:0.001\n",
      "Episode:56, Validation Loss:1.721114073614845e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:57, Validation Loss:1.8008467261771167e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:58, Validation Loss:2.721080772366579e-05,Acc:99.2549%,lr:0.001\n",
      "Episode:59, Validation Loss:1.7059632700170573e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:60, Validation Loss:1.863035298546874e-05,Acc:99.4146%,lr:0.001\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:61, Validation Loss:2.293990892241647e-05,Acc:99.3281%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.2406732106631887e-05,Acc:99.5742%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.112546680937261e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.0872576207303188e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.078361299998182e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.08200697064253e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.0747888381109672e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.1480867917470518e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.1087027944658127e-05,Acc:99.6208%,lr:0.0001\n",
      "Episode:70, Validation Loss:1.1347109841469313e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:71, Validation Loss:1.0923103523798021e-05,Acc:99.6940%,lr:0.0001\n",
      "Episode:72, Validation Loss:1.0557267879308888e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.0449374605122876e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:74, Validation Loss:1.0867399876533813e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:75, Validation Loss:1.0377427241147882e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:76, Validation Loss:1.0304344223714084e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:77, Validation Loss:1.1028724251946453e-05,Acc:99.5875%,lr:0.0001\n",
      "Episode:78, Validation Loss:1.1432357578518036e-05,Acc:99.5809%,lr:0.0001\n",
      "Episode:79, Validation Loss:1.044638770641863e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:80, Validation Loss:9.956220746042326e-06,Acc:99.6474%,lr:0.0001\n",
      "Episode:81, Validation Loss:1.072387270254696e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.0004233082676104e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:83, Validation Loss:9.867277116816592e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:84, Validation Loss:1.0255880506650731e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:85, Validation Loss:1.070102813176339e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:86, Validation Loss:9.979653743924916e-06,Acc:99.6408%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.99698079225348e-06,Acc:99.6541%,lr:0.0001\n",
      "Episode:88, Validation Loss:1.0536587865256911e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:89, Validation Loss:1.006079838299423e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:90, Validation Loss:1.0109861276522398e-05,Acc:99.6275%,lr:0.0001\n",
      "Episode:91, Validation Loss:1.0339917716416053e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.13392555017169e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:93, Validation Loss:1.002322352566162e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:94, Validation Loss:1.0003647908267028e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:95, Validation Loss:1.0250244865083928e-05,Acc:99.6142%,lr:0.0001\n",
      "Episode:96, Validation Loss:1.0462464606602532e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:97, Validation Loss:1.0239271807150758e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:98, Validation Loss:1.0219365592546337e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:99, Validation Loss:1.0570044538324392e-05,Acc:99.6408%,lr:0.0001\n",
      "Episode:100, Validation Loss:1.0006247365132506e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:101, Validation Loss:1.0156550976492865e-05,Acc:99.6474%,lr:0.0001\n",
      "Episode:102, Validation Loss:1.1234534769296694e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:103, Validation Loss:9.968758254902296e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.780025351029276e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:105, Validation Loss:1.015602196519674e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:106, Validation Loss:1.0047210998755859e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:107, Validation Loss:1.0343533778288553e-05,Acc:99.6807%,lr:0.0001\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:108, Validation Loss:9.992421636166584e-06,Acc:99.6674%,lr:1e-05\n",
      "Episode:109, Validation Loss:9.828851882421856e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:110, Validation Loss:9.806425607564476e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:111, Validation Loss:9.781639118931152e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:112, Validation Loss:9.811224967058889e-06,Acc:99.6674%,lr:1e-05\n",
      "Episode:113, Validation Loss:9.772415357647328e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:114, Validation Loss:9.784125939790733e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:115, Validation Loss:9.689558347703977e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:116, Validation Loss:9.675337246531435e-06,Acc:99.6740%,lr:1e-05\n",
      "Episode:117, Validation Loss:9.673512239651502e-06,Acc:99.6740%,lr:1e-05\n",
      "Episode:118, Validation Loss:9.59209527298927e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:119, Validation Loss:9.536356496673717e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:120, Validation Loss:9.669344149829306e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:121, Validation Loss:9.712694235594111e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:122, Validation Loss:9.606360300964993e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:123, Validation Loss:9.548483670953346e-06,Acc:99.6940%,lr:1e-05\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:4 Saved Loss:9.536356496673717e-06 Acc:0.9970063863757318==================\n",
      "======================================================\n",
      "start inference & gernerate Dig dataset...\n",
      "model num: 5\n",
      "Inference finished: 10240\n",
      "(10240, 3) (10240,)\n",
      "Top1 data num: 10163\n",
      "Save npy as: ./dataset_final/iterative_trained/digidx_10163_s12.npy\n",
      "shape of top1_dig_csv: (10163, 785)\n",
      "Save dig csv as: ./dataset_final/iterative_trained/digtop1_10163_s12.csv\n",
      "Dig csv finished\n",
      "Start pseudo_labeling...\n",
      "model num: 5\n",
      "Inference complete: (5000,)\n",
      "test csv shape: (5000, 785)\n",
      "Save test csv as: ./dataset_final/iterative_trained/test_pseu_s12.csv\n",
      "pseudo label finished\n",
      "start combining...\n",
      "shape of digtop1_csv: (10163, 785)\n",
      "shape of test_csv: (5000, 785)\n",
      "shape of new csv: (75163, 785)\n",
      "Save new csv as: ./dataset_final/iterative_trained/train_pseu_dig_75163_s12.csv\n",
      "===================All finished===================\n",
      "\n",
      "Set global data to: ./dataset_final/iterative_trained/train_pseu_dig_75163_s12.csv\n",
      "Set ensemble root to: ./Kmnist_saved_model/Step11\n",
      "Step: 12\n",
      "global_data len: 75163\n",
      "validation rate: 0.1999920173489616\n",
      "Fold: 5\n",
      "Episode:1, Validation Loss:0.003792914464284664,Acc:10.1783%,lr:0.001\n",
      "Episode:2, Validation Loss:0.005845117975004561,Acc:20.2701%,lr:0.001\n",
      "Episode:3, Validation Loss:0.008801355965915292,Acc:19.0859%,lr:0.001\n",
      "Episode:4, Validation Loss:0.010192608059309086,Acc:21.8933%,lr:0.001\n",
      "Episode:5, Validation Loss:0.009553896486283363,Acc:27.3217%,lr:0.001\n",
      "Episode:6, Validation Loss:0.0018396726261751014,Acc:67.8952%,lr:0.001\n",
      "Episode:7, Validation Loss:0.00303899664521027,Acc:58.3422%,lr:0.001\n",
      "Episode:8, Validation Loss:0.00040713755167057187,Acc:90.9726%,lr:0.001\n",
      "Episode:9, Validation Loss:9.697547034737656e-05,Acc:97.4255%,lr:0.001\n",
      "Episode:10, Validation Loss:0.00010872874785652815,Acc:96.9731%,lr:0.001\n",
      "Episode:11, Validation Loss:6.20787160817044e-05,Acc:98.4633%,lr:0.001\n",
      "Episode:12, Validation Loss:3.729013023782024e-05,Acc:98.9822%,lr:0.001\n",
      "Episode:13, Validation Loss:5.2852529840084894e-05,Acc:98.6895%,lr:0.001\n",
      "Episode:14, Validation Loss:4.268212736093059e-05,Acc:98.7560%,lr:0.001\n",
      "Episode:15, Validation Loss:4.4966114812816565e-05,Acc:98.8292%,lr:0.001\n",
      "Episode:16, Validation Loss:6.423129870131524e-05,Acc:98.3768%,lr:0.001\n",
      "Episode:17, Validation Loss:3.0783401948894e-05,Acc:99.0820%,lr:0.001\n",
      "Episode:18, Validation Loss:4.992314588086221e-05,Acc:98.5697%,lr:0.001\n",
      "Episode:19, Validation Loss:2.7738401063823473e-05,Acc:99.1152%,lr:0.001\n",
      "Episode:20, Validation Loss:4.591352686468371e-05,Acc:98.7959%,lr:0.001\n",
      "Episode:21, Validation Loss:2.9304900472788432e-05,Acc:99.1485%,lr:0.001\n",
      "Episode:22, Validation Loss:3.071473153063184e-05,Acc:99.0953%,lr:0.001\n",
      "Episode:23, Validation Loss:2.450113355252989e-05,Acc:99.2150%,lr:0.001\n",
      "Episode:24, Validation Loss:2.507578374390719e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:25, Validation Loss:2.207813517821476e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:26, Validation Loss:3.221853075627319e-05,Acc:98.9689%,lr:0.001\n",
      "Episode:27, Validation Loss:2.2902184224500657e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:28, Validation Loss:3.579170296901461e-05,Acc:98.8624%,lr:0.001\n",
      "Episode:29, Validation Loss:2.4042465424679612e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:30, Validation Loss:2.678509021228444e-05,Acc:99.0753%,lr:0.001\n",
      "Episode:31, Validation Loss:1.9039955091012912e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:32, Validation Loss:2.871974390703925e-05,Acc:99.0820%,lr:0.001\n",
      "Episode:33, Validation Loss:2.4817258150808953e-05,Acc:99.2483%,lr:0.001\n",
      "Episode:34, Validation Loss:1.9786180432701505e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:35, Validation Loss:3.2898831166854366e-05,Acc:98.9822%,lr:0.001\n",
      "Episode:36, Validation Loss:2.0548157653404065e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:37, Validation Loss:2.0969528486796553e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:38, Validation Loss:1.4991643655194667e-05,Acc:99.5077%,lr:0.001\n",
      "Episode:39, Validation Loss:1.754425552799037e-05,Acc:99.4678%,lr:0.001\n",
      "Episode:40, Validation Loss:2.6989287581292793e-05,Acc:99.1884%,lr:0.001\n",
      "Episode:41, Validation Loss:2.2313021459954258e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:42, Validation Loss:1.903996212301878e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:43, Validation Loss:1.4371332667119693e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:44, Validation Loss:2.992671596936132e-05,Acc:99.0820%,lr:0.001\n",
      "Episode:45, Validation Loss:1.9882255290328123e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:46, Validation Loss:1.9247838067502464e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:47, Validation Loss:1.5091842551928305e-05,Acc:99.5742%,lr:0.001\n",
      "Episode:48, Validation Loss:2.5147011581889614e-05,Acc:99.1618%,lr:0.001\n",
      "Episode:49, Validation Loss:1.925353039880821e-05,Acc:99.3614%,lr:0.001\n",
      "Episode:50, Validation Loss:1.8950646695843984e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:51, Validation Loss:1.517647094583459e-05,Acc:99.5343%,lr:0.001\n",
      "Episode:52, Validation Loss:1.528656285255156e-05,Acc:99.5011%,lr:0.001\n",
      "Episode:53, Validation Loss:1.918115154227927e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:54, Validation Loss:1.8228121506304993e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:55, Validation Loss:1.9386525579617656e-05,Acc:99.4079%,lr:0.001\n",
      "Episode:56, Validation Loss:2.2050408753524315e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:57, Validation Loss:2.000152706250374e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:58, Validation Loss:1.7751644281477148e-05,Acc:99.3614%,lr:0.001\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Episode:59, Validation Loss:1.8308868759597723e-05,Acc:99.4545%,lr:0.0001\n",
      "Episode:60, Validation Loss:1.1687863560144637e-05,Acc:99.5942%,lr:0.0001\n",
      "Episode:61, Validation Loss:1.1360598003175535e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:62, Validation Loss:1.1025198181162272e-05,Acc:99.6075%,lr:0.0001\n",
      "Episode:63, Validation Loss:1.0597935982817758e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:64, Validation Loss:1.0405409141399557e-05,Acc:99.6607%,lr:0.0001\n",
      "Episode:65, Validation Loss:1.0011011502641577e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:66, Validation Loss:1.0334422374208632e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:67, Validation Loss:1.011289978457368e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:68, Validation Loss:1.0300766171846874e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:69, Validation Loss:1.051823200658955e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:70, Validation Loss:9.819322027525745e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:71, Validation Loss:9.408945224172039e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:72, Validation Loss:9.400965988525982e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:73, Validation Loss:1.0090551233516849e-05,Acc:99.6674%,lr:0.0001\n",
      "Episode:74, Validation Loss:9.660277818738542e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:75, Validation Loss:9.645391929698409e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:76, Validation Loss:9.842179794937071e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:77, Validation Loss:9.998677890973801e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:78, Validation Loss:9.289597184161848e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:79, Validation Loss:9.692606830671073e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:80, Validation Loss:1.011922391217763e-05,Acc:99.6740%,lr:0.0001\n",
      "Episode:81, Validation Loss:9.693791677192955e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:82, Validation Loss:1.0289296071912981e-05,Acc:99.7006%,lr:0.0001\n",
      "Episode:83, Validation Loss:1.0000120722274868e-05,Acc:99.6873%,lr:0.0001\n",
      "Episode:84, Validation Loss:9.573428890855707e-06,Acc:99.6873%,lr:0.0001\n",
      "Episode:85, Validation Loss:9.183820481786326e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:86, Validation Loss:8.85401324192067e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:87, Validation Loss:9.498293209224225e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:88, Validation Loss:9.529206464627184e-06,Acc:99.7339%,lr:0.0001\n",
      "Episode:89, Validation Loss:9.638245769901804e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:90, Validation Loss:9.788969226088326e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:91, Validation Loss:9.75556794168381e-06,Acc:99.6541%,lr:0.0001\n",
      "Episode:92, Validation Loss:9.440316427340448e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:93, Validation Loss:9.187521980981234e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:94, Validation Loss:9.01461552016679e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:95, Validation Loss:8.860864862898774e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:96, Validation Loss:9.312919683520498e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:97, Validation Loss:9.228352285295074e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:98, Validation Loss:9.069553205417296e-06,Acc:99.6807%,lr:0.0001\n",
      "Episode:99, Validation Loss:9.112721729127492e-06,Acc:99.7073%,lr:0.0001\n",
      "Episode:100, Validation Loss:9.35755194868137e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:101, Validation Loss:9.009978082675354e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:102, Validation Loss:8.518168885615705e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:103, Validation Loss:8.672022947445789e-06,Acc:99.6541%,lr:0.0001\n",
      "Episode:104, Validation Loss:9.09516305829725e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:105, Validation Loss:9.627093906955968e-06,Acc:99.6940%,lr:0.0001\n",
      "Episode:106, Validation Loss:9.876832590518226e-06,Acc:99.7206%,lr:0.0001\n",
      "Episode:107, Validation Loss:9.257904181535445e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:108, Validation Loss:9.625790879366292e-06,Acc:99.7006%,lr:0.0001\n",
      "Episode:109, Validation Loss:1.0041606675946472e-05,Acc:99.6541%,lr:0.0001\n",
      "Episode:110, Validation Loss:1.1137461800528705e-05,Acc:99.6341%,lr:0.0001\n",
      "Episode:111, Validation Loss:9.801636532765871e-06,Acc:99.6541%,lr:0.0001\n",
      "Episode:112, Validation Loss:8.91108763468129e-06,Acc:99.6541%,lr:0.0001\n",
      "Episode:113, Validation Loss:9.46809127064399e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:114, Validation Loss:9.836309185244654e-06,Acc:99.6740%,lr:0.0001\n",
      "Episode:115, Validation Loss:9.341508194956851e-06,Acc:99.6674%,lr:0.0001\n",
      "Episode:116, Validation Loss:9.784449288148697e-06,Acc:99.6607%,lr:0.0001\n",
      "Episode:117, Validation Loss:9.74627587391126e-06,Acc:99.6341%,lr:0.0001\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Episode:118, Validation Loss:9.576985258123322e-06,Acc:99.6474%,lr:1e-05\n",
      "Episode:119, Validation Loss:9.345899636154878e-06,Acc:99.6740%,lr:1e-05\n",
      "Episode:120, Validation Loss:9.122536550640283e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:121, Validation Loss:9.067968959548868e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:122, Validation Loss:9.035183177014863e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:123, Validation Loss:8.97092111393841e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:124, Validation Loss:8.96109873379376e-06,Acc:99.6740%,lr:1e-05\n",
      "Episode:125, Validation Loss:8.891877929415869e-06,Acc:99.6807%,lr:1e-05\n",
      "Episode:126, Validation Loss:8.88226762465526e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:127, Validation Loss:8.82823440405387e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:128, Validation Loss:8.84348047429328e-06,Acc:99.6873%,lr:1e-05\n",
      "Episode:129, Validation Loss:8.793435887963436e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:130, Validation Loss:8.747342111767846e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:131, Validation Loss:8.894591540209216e-06,Acc:99.6940%,lr:1e-05\n",
      "Episode:132, Validation Loss:8.862098995417736e-06,Acc:99.7006%,lr:1e-05\n",
      "Episode:133, Validation Loss:8.788047326920021e-06,Acc:99.7006%,lr:1e-05\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "===================Best Fold:0 Saved Loss:9.529206464627184e-06 Acc:0.9973390101117616==================\n",
      "======================================================\n",
      "Episode:1, Validation Loss:0.0022618736181568757,Acc:26.4902%,lr:0.001\n",
      "Episode:2, Validation Loss:0.004705780899987822,Acc:16.9439%,lr:0.001\n",
      "Episode:3, Validation Loss:0.010672802681488963,Acc:15.1943%,lr:0.001\n",
      "Episode:4, Validation Loss:0.016069159220989362,Acc:10.3712%,lr:0.001\n",
      "Episode:5, Validation Loss:0.015602558645052502,Acc:10.4643%,lr:0.001\n",
      "Episode:6, Validation Loss:0.014910809342819303,Acc:11.2493%,lr:0.001\n",
      "Episode:7, Validation Loss:0.018362582396039814,Acc:12.5532%,lr:0.001\n",
      "Episode:8, Validation Loss:0.0005070102570093713,Acc:87.4667%,lr:0.001\n",
      "Episode:9, Validation Loss:0.0015049189519476167,Acc:70.6027%,lr:0.001\n",
      "Episode:10, Validation Loss:0.0003804454144770443,Acc:91.8175%,lr:0.001\n",
      "Episode:11, Validation Loss:0.00030031940042813955,Acc:93.0681%,lr:0.001\n",
      "Episode:12, Validation Loss:3.1556789017321586e-05,Acc:99.1551%,lr:0.001\n",
      "Episode:13, Validation Loss:8.909165895900363e-05,Acc:97.6982%,lr:0.001\n",
      "Episode:14, Validation Loss:4.748124188132398e-05,Acc:98.6096%,lr:0.001\n",
      "Episode:15, Validation Loss:3.961013977481781e-05,Acc:98.9356%,lr:0.001\n",
      "Episode:16, Validation Loss:4.673641454577129e-05,Acc:98.6961%,lr:0.001\n",
      "Episode:17, Validation Loss:2.3490779781877646e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:18, Validation Loss:2.4089083038845425e-05,Acc:99.3015%,lr:0.001\n",
      "Episode:19, Validation Loss:4.212819699033453e-05,Acc:98.6695%,lr:0.001\n",
      "Episode:20, Validation Loss:3.50180766265195e-05,Acc:99.0687%,lr:0.001\n",
      "Episode:21, Validation Loss:6.470352410278845e-05,Acc:98.1107%,lr:0.001\n",
      "Episode:22, Validation Loss:2.2114807553490213e-05,Acc:99.2616%,lr:0.001\n",
      "Episode:23, Validation Loss:3.340040970972366e-05,Acc:98.9622%,lr:0.001\n",
      "Episode:24, Validation Loss:2.4390615078760882e-05,Acc:99.2350%,lr:0.001\n",
      "Episode:25, Validation Loss:2.4767766831548782e-05,Acc:99.2682%,lr:0.001\n",
      "Episode:26, Validation Loss:2.1965708831417364e-05,Acc:99.3148%,lr:0.001\n",
      "Episode:27, Validation Loss:2.30845087715893e-05,Acc:99.2948%,lr:0.001\n",
      "Episode:28, Validation Loss:2.512550485796707e-05,Acc:99.3680%,lr:0.001\n",
      "Episode:29, Validation Loss:3.8255198881973795e-05,Acc:98.7094%,lr:0.001\n",
      "Episode:30, Validation Loss:1.960321154322489e-05,Acc:99.4146%,lr:0.001\n",
      "Episode:31, Validation Loss:2.5936348107011475e-05,Acc:99.2749%,lr:0.001\n",
      "Episode:32, Validation Loss:2.655209563305763e-05,Acc:99.1086%,lr:0.001\n",
      "Episode:33, Validation Loss:2.094720635997323e-05,Acc:99.3281%,lr:0.001\n",
      "Episode:34, Validation Loss:1.772775321191711e-05,Acc:99.4611%,lr:0.001\n",
      "Episode:35, Validation Loss:2.511943571027636e-05,Acc:99.3081%,lr:0.001\n",
      "Episode:36, Validation Loss:1.7597282242412545e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:37, Validation Loss:2.3397270955855127e-05,Acc:99.3214%,lr:0.001\n",
      "Episode:38, Validation Loss:2.1861544564889746e-05,Acc:99.3414%,lr:0.001\n",
      "Episode:39, Validation Loss:1.9781406041474626e-05,Acc:99.4212%,lr:0.001\n",
      "Episode:40, Validation Loss:1.6143837445051254e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:41, Validation Loss:1.877799035139687e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:42, Validation Loss:2.053762036298876e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:43, Validation Loss:3.8974028241291775e-05,Acc:98.7693%,lr:0.001\n",
      "Episode:44, Validation Loss:2.19491852284818e-05,Acc:99.3547%,lr:0.001\n",
      "Episode:45, Validation Loss:2.1224519985808757e-05,Acc:99.3813%,lr:0.001\n",
      "Episode:46, Validation Loss:1.700663039641194e-05,Acc:99.4944%,lr:0.001\n",
      "Episode:47, Validation Loss:1.6083939221775344e-05,Acc:99.5410%,lr:0.001\n",
      "Episode:48, Validation Loss:1.6003837395100563e-05,Acc:99.5210%,lr:0.001\n",
      "Episode:49, Validation Loss:1.9122699402994366e-05,Acc:99.4545%,lr:0.001\n",
      "Episode:50, Validation Loss:1.863443966510846e-05,Acc:99.3946%,lr:0.001\n",
      "Episode:51, Validation Loss:3.00674988953134e-05,Acc:98.9822%,lr:0.001\n",
      "Episode:52, Validation Loss:1.919626954946907e-05,Acc:99.5277%,lr:0.001\n",
      "Episode:53, Validation Loss:2.7077989055497047e-05,Acc:99.2017%,lr:0.001\n",
      "Episode:54, Validation Loss:1.7029681590451657e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:55, Validation Loss:2.0171098060164444e-05,Acc:99.3880%,lr:0.001\n",
      "Episode:56, Validation Loss:1.7639569380083194e-05,Acc:99.4811%,lr:0.001\n",
      "Episode:57, Validation Loss:1.4581090463112253e-05,Acc:99.5875%,lr:0.001\n",
      "Episode:58, Validation Loss:1.8558069974870012e-05,Acc:99.4279%,lr:0.001\n",
      "Episode:59, Validation Loss:1.4551481474418948e-05,Acc:99.5809%,lr:0.001\n",
      "Episode:60, Validation Loss:1.7516878844913394e-05,Acc:99.5077%,lr:0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b985f2a644de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                     \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                     \u001b[0mdata_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "num_workers = 8\n",
    "k = 5\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    epochs = 300\n",
    "    ensemble_models = []\n",
    "    lr = 1e-3\n",
    "    val_period = 1\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    step = 2\n",
    "    dir_name = \"Kmnist_saved_model/Step2\"\n",
    "    \n",
    "    while True:\n",
    "        step += 1\n",
    "        ensemble_root = dir_name\n",
    "        dig_csv_name = Infer_and_gen_dig_dataset(step,ensemble_root)\n",
    "        pseu_csv_name = pseudo_labeling(step,ensemble_root)\n",
    "        new_csv_name = combine_csv(step,dig_csv_name,pseu_csv_name)\n",
    "        global_data = pd.read_csv(new_csv_name)\n",
    "        print(\"Set global data to:\",new_csv_name)\n",
    "        print(\"Set ensemble root to:\",ensemble_root)\n",
    "        \n",
    "        print(\"Step:\",step)\n",
    "        indices_len = len(global_data)\n",
    "        vr = (indices_len//k)/indices_len\n",
    "        print(\"global_data len:\",indices_len)\n",
    "        print(\"validation rate:\",vr)\n",
    "        train_loaders, val_loaders = get_kfold_dataset_loader(k, vr, indices_len, batch_size, num_workers, global_data)\n",
    "        \n",
    "        print(\"Fold:\",len(train_loaders))\n",
    "        dir_name = \"./Kmnist_saved_model/Step{}\".format(step)\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "        \n",
    "        for fold in range(0,len(train_loaders)):\n",
    "            train_loader = train_loaders[fold]\n",
    "            val_loader = val_loaders[fold]\n",
    "            model = get_model()\n",
    "            max_acc = 0\n",
    "            min_loss = 10000\n",
    "            best_model_dict = None\n",
    "            data_num = 0\n",
    "            loss_avg = 0\n",
    "            optimizer = torch.optim.Adam(model.parameters(),lr=lr,betas=(0.9,0.99))\n",
    "            lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=15,factor=0.1)\n",
    "\n",
    "            for ep in range(0,epochs+1):\n",
    "                model.train()\n",
    "                for idx, data in enumerate(train_loader):\n",
    "                    img, target = data\n",
    "                    img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "\n",
    "                    pred = model(img)\n",
    "                    loss = criterion(pred,target)\n",
    "                    loss_avg += loss.item()\n",
    "                    data_num += img.size(0)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                ###Validation\n",
    "                if ep!=0 and ep%val_period == 0:\n",
    "                    model.eval()\n",
    "                    acc = 0\n",
    "                    val_loss = 0\n",
    "                    data_num  = 0\n",
    "                    with torch.no_grad():\n",
    "                        for idx, data in enumerate(val_loader):\n",
    "                            img, target = data\n",
    "                            img, target = img.to(device), target.to(device,dtype=torch.long)\n",
    "                            pred = model(img)\n",
    "                            val_loss += criterion(pred, target).item()\n",
    "                            _,pred_class = torch.max(pred.data, 1)\n",
    "                            acc += (pred_class == target).sum().item()\n",
    "                            data_num += img.size(0)\n",
    "\n",
    "                    acc /= data_num\n",
    "                    val_loss /= data_num\n",
    "\n",
    "                    ###Plateau\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                    if optimizer.param_groups[0]['lr'] < 1e-5:\n",
    "                        break                    \n",
    "\n",
    "                    if acc >= max_acc:\n",
    "                        max_acc = acc\n",
    "                        min_loss = val_loss\n",
    "                        best_model_dict = model.state_dict()                    \n",
    "\n",
    "                    print(\"Episode:{}, Validation Loss:{},Acc:{:.4f}%,lr:{}\"\n",
    "                          .format(ep,val_loss,acc*100,optimizer.param_groups[0]['lr']))\n",
    "            print(\"===================Best Fold:{} Saved Loss:{} Acc:{}==================\".format(fold,min_loss,max_acc))\n",
    "            path = \"{}/S{}_Fold{}_loss{:.4f}_acc{:.3f}\".format(dir_name,step,fold,min_loss*1e3,max_acc*1e2)\n",
    "            torch.save(best_model_dict,path)\n",
    "            print(\"======================================================\")\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "#         step += 1\n",
    "#         ensemble_root = dir_name\n",
    "#         dig_csv_name = Infer_and_gen_dig_dataset(step,ensemble_root)\n",
    "#         pseu_csv_name = pseudo_labeling(step,ensemble_root)\n",
    "#         new_csv_name = combine_csv(step,dig_csv_name,pseu_csv_name)\n",
    "#         global_data = pd.read_csv(new_csv_name)\n",
    "#         print(\"Set global data to:\",new_csv_name)\n",
    "#         print(\"Set ensemble root to:\",ensemble_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "###Confusion matrix\n",
    "print(classification_report(labels, result,digits=4))\n",
    "plt.figure(figsize=(10,10))\n",
    "confusion_mat = confusion_matrix(labels, result)\n",
    "sn.heatmap(confusion_mat, annot=True, cmap='YlGnBu',fmt=\"d\",linewidths=.5, linecolor='w')\n",
    "plt.title('Confusion matrix of Real World validation result')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = pd.read_csv(\"./dataset/train.csv\")\n",
    "global_data_test = pd.read_csv(\"./dataset/train_test_psuedo_65k.csv\")\n",
    "\n",
    "train_digtop1= pd.read_csv(\"./dataset/digtop1_9548.csv\")\n",
    "plt.hist(train_digtop1 ,density=0,label=True,rwidth=0.3)\n",
    "plt.xticks(range(0,10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
